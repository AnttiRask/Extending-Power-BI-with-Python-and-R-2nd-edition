2024-10-05 12:21:15,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-05 12:21:15,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-05 12:21:15,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-05 12:21:15,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-05 12:22:02,042:INFO:PyCaret ClassificationExperiment
2024-10-05 12:22:02,042:INFO:Logging name: clf-default-name
2024-10-05 12:22:02,043:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-10-05 12:22:02,043:INFO:version 3.3.1
2024-10-05 12:22:02,043:INFO:Initializing setup()
2024-10-05 12:22:02,043:INFO:self.USI: 8b69
2024-10-05 12:22:02,044:INFO:self._variable_keys: {'html_param', 'exp_id', 'USI', 'fold_generator', 'y_train', 'pipeline', 'target_param', 'logging_param', '_available_plots', 'data', 'X_test', 'y', 'fix_imbalance', 'seed', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_name_log', 'log_plots_param', 'fold_shuffle_param', 'idx', 'gpu_param', 'is_multiclass', 'X_train', 'y_test', 'memory', 'X', '_ml_usecase', 'n_jobs_param'}
2024-10-05 12:22:02,044:INFO:Checking environment
2024-10-05 12:22:02,044:INFO:python_version: 3.9.20
2024-10-05 12:22:02,044:INFO:python_build: ('main', 'Sep 30 2024 17:43:23')
2024-10-05 12:22:02,044:INFO:machine: AMD64
2024-10-05 12:22:02,087:INFO:platform: Windows-10-10.0.19045-SP0
2024-10-05 12:22:02,089:INFO:Memory: svmem(total=17048907776, available=8278900736, percent=51.4, used=8770007040, free=8278900736)
2024-10-05 12:22:02,090:INFO:Physical Core: 2
2024-10-05 12:22:02,090:INFO:Logical Core: 4
2024-10-05 12:22:02,090:INFO:Checking libraries
2024-10-05 12:22:02,090:INFO:System:
2024-10-05 12:22:02,090:INFO:    python: 3.9.20 | packaged by conda-forge | (main, Sep 30 2024, 17:43:23) [MSC v.1929 64 bit (AMD64)]
2024-10-05 12:22:02,090:INFO:executable: C:\PROGRA~3\MINICO~1\envs\PYCARE~1\python.exe
2024-10-05 12:22:02,090:INFO:   machine: Windows-10-10.0.19045-SP0
2024-10-05 12:22:02,090:INFO:PyCaret required dependencies:
2024-10-05 12:22:02,448:INFO:                 pip: 24.2
2024-10-05 12:22:02,448:INFO:          setuptools: 75.1.0
2024-10-05 12:22:02,448:INFO:             pycaret: 3.3.1
2024-10-05 12:22:02,448:INFO:             IPython: 8.18.1
2024-10-05 12:22:02,448:INFO:          ipywidgets: 8.1.5
2024-10-05 12:22:02,448:INFO:                tqdm: 4.66.5
2024-10-05 12:22:02,448:INFO:               numpy: 1.26.4
2024-10-05 12:22:02,448:INFO:              pandas: 2.1.4
2024-10-05 12:22:02,448:INFO:              jinja2: 3.1.4
2024-10-05 12:22:02,448:INFO:               scipy: 1.11.4
2024-10-05 12:22:02,448:INFO:              joblib: 1.3.2
2024-10-05 12:22:02,448:INFO:             sklearn: 1.4.2
2024-10-05 12:22:02,448:INFO:                pyod: 2.0.2
2024-10-05 12:22:02,448:INFO:            imblearn: 0.12.4
2024-10-05 12:22:02,463:INFO:   category_encoders: 2.6.4
2024-10-05 12:22:02,463:INFO:            lightgbm: 4.5.0
2024-10-05 12:22:02,463:INFO:               numba: 0.60.0
2024-10-05 12:22:02,463:INFO:            requests: 2.32.3
2024-10-05 12:22:02,463:INFO:          matplotlib: 3.9.2
2024-10-05 12:22:02,463:INFO:          scikitplot: 0.3.7
2024-10-05 12:22:02,463:INFO:         yellowbrick: 1.5
2024-10-05 12:22:02,463:INFO:              plotly: 5.24.1
2024-10-05 12:22:02,463:INFO:    plotly-resampler: Not installed
2024-10-05 12:22:02,463:INFO:             kaleido: 0.2.1
2024-10-05 12:22:02,463:INFO:           schemdraw: 0.15
2024-10-05 12:22:02,466:INFO:         statsmodels: 0.14.4
2024-10-05 12:22:02,466:INFO:              sktime: 0.26.0
2024-10-05 12:22:02,466:INFO:               tbats: 1.1.3
2024-10-05 12:22:02,466:INFO:            pmdarima: 2.0.4
2024-10-05 12:22:02,466:INFO:              psutil: 6.0.0
2024-10-05 12:22:02,466:INFO:          markupsafe: 2.1.5
2024-10-05 12:22:02,466:INFO:             pickle5: Not installed
2024-10-05 12:22:02,466:INFO:         cloudpickle: 3.0.0
2024-10-05 12:22:02,466:INFO:         deprecation: 2.1.0
2024-10-05 12:22:02,466:INFO:              xxhash: 3.5.0
2024-10-05 12:22:02,466:INFO:           wurlitzer: 3.1.1
2024-10-05 12:22:02,467:INFO:PyCaret optional dependencies:
2024-10-05 12:22:02,514:INFO:                shap: Not installed
2024-10-05 12:22:02,514:INFO:           interpret: Not installed
2024-10-05 12:22:02,514:INFO:                umap: 0.5.6
2024-10-05 12:22:02,514:INFO:     ydata_profiling: Not installed
2024-10-05 12:22:02,514:INFO:  explainerdashboard: Not installed
2024-10-05 12:22:02,514:INFO:             autoviz: Not installed
2024-10-05 12:22:02,514:INFO:           fairlearn: Not installed
2024-10-05 12:22:02,514:INFO:          deepchecks: Not installed
2024-10-05 12:22:02,514:INFO:             xgboost: Not installed
2024-10-05 12:22:02,514:INFO:            catboost: Not installed
2024-10-05 12:22:02,514:INFO:              kmodes: Not installed
2024-10-05 12:22:02,514:INFO:             mlxtend: Not installed
2024-10-05 12:22:02,514:INFO:       statsforecast: Not installed
2024-10-05 12:22:02,514:INFO:        tune_sklearn: Not installed
2024-10-05 12:22:02,514:INFO:                 ray: Not installed
2024-10-05 12:22:02,514:INFO:            hyperopt: Not installed
2024-10-05 12:22:02,514:INFO:              optuna: Not installed
2024-10-05 12:22:02,514:INFO:               skopt: Not installed
2024-10-05 12:22:02,514:INFO:              mlflow: Not installed
2024-10-05 12:22:02,514:INFO:              gradio: Not installed
2024-10-05 12:22:02,514:INFO:             fastapi: Not installed
2024-10-05 12:22:02,514:INFO:             uvicorn: Not installed
2024-10-05 12:22:02,514:INFO:              m2cgen: Not installed
2024-10-05 12:22:02,514:INFO:           evidently: Not installed
2024-10-05 12:22:02,514:INFO:               fugue: Not installed
2024-10-05 12:22:02,514:INFO:           streamlit: Not installed
2024-10-05 12:22:02,514:INFO:             prophet: Not installed
2024-10-05 12:22:02,514:INFO:None
2024-10-05 12:22:02,514:INFO:Set up data.
2024-10-05 12:22:02,530:INFO:Set up folding strategy.
2024-10-05 12:22:02,530:INFO:Set up train/test split.
2024-10-05 12:22:02,530:INFO:Set up index.
2024-10-05 12:22:02,530:INFO:Assigning column types.
2024-10-05 12:22:02,546:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-10-05 12:22:02,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-05 12:22:02,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-05 12:22:02,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:02,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:02,839:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-05 12:22:02,841:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-05 12:22:02,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:02,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:02,907:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-10-05 12:22:03,022:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-05 12:22:03,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:03,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:03,192:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-05 12:22:03,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:03,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:03,232:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-10-05 12:22:03,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:03,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:03,552:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:03,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:03,568:INFO:Preparing preprocessing pipeline...
2024-10-05 12:22:03,568:INFO:Set up simple imputation.
2024-10-05 12:22:03,584:INFO:Set up encoding of ordinal features.
2024-10-05 12:22:03,584:INFO:Set up encoding of categorical features.
2024-10-05 12:22:03,717:INFO:Finished creating preprocessing pipeline.
2024-10-05 12:22:03,780:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\antti\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                                                        {'col': 'Pclass',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 1.0    0
2.0    1
3.0    2
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-10-05 12:22:03,780:INFO:Creating final display dataframe.
2024-10-05 12:22:04,278:INFO:Setup _display_container:                     Description             Value
0                    Session id              5614
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (844, 8)
4        Transformed data shape         (844, 10)
5   Transformed train set shape         (590, 10)
6    Transformed test set shape         (254, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              8b69
2024-10-05 12:22:04,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:04,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:04,628:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:04,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-05 12:22:04,628:INFO:setup() successfully completed in 2.59s...............
2024-10-05 12:22:08,067:INFO:Initializing compare_models()
2024-10-05 12:22:08,067:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-10-05 12:22:08,067:INFO:Checking exceptions
2024-10-05 12:22:08,078:INFO:Preparing display monitor
2024-10-05 12:22:08,090:INFO:Initializing Logistic Regression
2024-10-05 12:22:08,091:INFO:Total runtime is 1.64945920308431e-05 minutes
2024-10-05 12:22:08,092:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:08,092:INFO:Initializing create_model()
2024-10-05 12:22:08,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:08,092:INFO:Checking exceptions
2024-10-05 12:22:08,092:INFO:Importing libraries
2024-10-05 12:22:08,092:INFO:Copying training dataset
2024-10-05 12:22:08,102:INFO:Defining folds
2024-10-05 12:22:08,102:INFO:Declaring metric variables
2024-10-05 12:22:08,103:INFO:Importing untrained model
2024-10-05 12:22:08,103:INFO:Logistic Regression Imported successfully
2024-10-05 12:22:08,104:INFO:Starting cross validation
2024-10-05 12:22:08,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:16,332:INFO:Calculating mean and std
2024-10-05 12:22:16,334:INFO:Creating metrics dataframe
2024-10-05 12:22:16,338:INFO:Uploading results into container
2024-10-05 12:22:16,338:INFO:Uploading model into container now
2024-10-05 12:22:16,339:INFO:_master_model_container: 1
2024-10-05 12:22:16,339:INFO:_display_container: 2
2024-10-05 12:22:16,340:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5614, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-10-05 12:22:16,340:INFO:create_model() successfully completed......................................
2024-10-05 12:22:16,421:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:16,421:INFO:Creating metrics dataframe
2024-10-05 12:22:16,425:INFO:Initializing K Neighbors Classifier
2024-10-05 12:22:16,425:INFO:Total runtime is 0.13892839749654134 minutes
2024-10-05 12:22:16,425:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:16,425:INFO:Initializing create_model()
2024-10-05 12:22:16,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:16,425:INFO:Checking exceptions
2024-10-05 12:22:16,426:INFO:Importing libraries
2024-10-05 12:22:16,426:INFO:Copying training dataset
2024-10-05 12:22:16,430:INFO:Defining folds
2024-10-05 12:22:16,430:INFO:Declaring metric variables
2024-10-05 12:22:16,430:INFO:Importing untrained model
2024-10-05 12:22:16,430:INFO:K Neighbors Classifier Imported successfully
2024-10-05 12:22:16,430:INFO:Starting cross validation
2024-10-05 12:22:16,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:16,862:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:16,862:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:16,862:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:16,862:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,109:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,125:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,125:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,156:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,310:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,341:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,373:INFO:Calculating mean and std
2024-10-05 12:22:17,375:INFO:Creating metrics dataframe
2024-10-05 12:22:17,377:INFO:Uploading results into container
2024-10-05 12:22:17,377:INFO:Uploading model into container now
2024-10-05 12:22:17,377:INFO:_master_model_container: 2
2024-10-05 12:22:17,377:INFO:_display_container: 2
2024-10-05 12:22:17,377:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-10-05 12:22:17,377:INFO:create_model() successfully completed......................................
2024-10-05 12:22:17,454:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:17,454:INFO:Creating metrics dataframe
2024-10-05 12:22:17,458:INFO:Initializing Naive Bayes
2024-10-05 12:22:17,459:INFO:Total runtime is 0.15615695317586265 minutes
2024-10-05 12:22:17,459:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:17,459:INFO:Initializing create_model()
2024-10-05 12:22:17,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:17,459:INFO:Checking exceptions
2024-10-05 12:22:17,459:INFO:Importing libraries
2024-10-05 12:22:17,460:INFO:Copying training dataset
2024-10-05 12:22:17,468:INFO:Defining folds
2024-10-05 12:22:17,468:INFO:Declaring metric variables
2024-10-05 12:22:17,469:INFO:Importing untrained model
2024-10-05 12:22:17,469:INFO:Naive Bayes Imported successfully
2024-10-05 12:22:17,469:INFO:Starting cross validation
2024-10-05 12:22:17,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:17,694:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,710:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,710:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,726:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,944:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,944:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,944:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:17,960:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,127:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,127:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,158:INFO:Calculating mean and std
2024-10-05 12:22:18,158:INFO:Creating metrics dataframe
2024-10-05 12:22:18,158:INFO:Uploading results into container
2024-10-05 12:22:18,158:INFO:Uploading model into container now
2024-10-05 12:22:18,158:INFO:_master_model_container: 3
2024-10-05 12:22:18,158:INFO:_display_container: 2
2024-10-05 12:22:18,158:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-10-05 12:22:18,158:INFO:create_model() successfully completed......................................
2024-10-05 12:22:18,236:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:18,236:INFO:Creating metrics dataframe
2024-10-05 12:22:18,240:INFO:Initializing Decision Tree Classifier
2024-10-05 12:22:18,240:INFO:Total runtime is 0.16917473475138348 minutes
2024-10-05 12:22:18,241:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:18,241:INFO:Initializing create_model()
2024-10-05 12:22:18,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:18,241:INFO:Checking exceptions
2024-10-05 12:22:18,241:INFO:Importing libraries
2024-10-05 12:22:18,241:INFO:Copying training dataset
2024-10-05 12:22:18,247:INFO:Defining folds
2024-10-05 12:22:18,247:INFO:Declaring metric variables
2024-10-05 12:22:18,247:INFO:Importing untrained model
2024-10-05 12:22:18,247:INFO:Decision Tree Classifier Imported successfully
2024-10-05 12:22:18,247:INFO:Starting cross validation
2024-10-05 12:22:18,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:18,476:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,491:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,491:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,507:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,706:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,745:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,752:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,780:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,944:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,946:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:18,993:INFO:Calculating mean and std
2024-10-05 12:22:18,993:INFO:Creating metrics dataframe
2024-10-05 12:22:18,993:INFO:Uploading results into container
2024-10-05 12:22:18,993:INFO:Uploading model into container now
2024-10-05 12:22:18,993:INFO:_master_model_container: 4
2024-10-05 12:22:18,993:INFO:_display_container: 2
2024-10-05 12:22:18,993:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5614, splitter='best')
2024-10-05 12:22:18,993:INFO:create_model() successfully completed......................................
2024-10-05 12:22:19,163:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:19,163:INFO:Creating metrics dataframe
2024-10-05 12:22:19,163:INFO:Initializing SVM - Linear Kernel
2024-10-05 12:22:19,163:INFO:Total runtime is 0.18455174763997398 minutes
2024-10-05 12:22:19,163:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:19,163:INFO:Initializing create_model()
2024-10-05 12:22:19,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:19,163:INFO:Checking exceptions
2024-10-05 12:22:19,163:INFO:Importing libraries
2024-10-05 12:22:19,163:INFO:Copying training dataset
2024-10-05 12:22:19,163:INFO:Defining folds
2024-10-05 12:22:19,163:INFO:Declaring metric variables
2024-10-05 12:22:19,163:INFO:Importing untrained model
2024-10-05 12:22:19,163:INFO:SVM - Linear Kernel Imported successfully
2024-10-05 12:22:19,178:INFO:Starting cross validation
2024-10-05 12:22:19,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:19,713:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:19,880:INFO:Calculating mean and std
2024-10-05 12:22:19,880:INFO:Creating metrics dataframe
2024-10-05 12:22:19,880:INFO:Uploading results into container
2024-10-05 12:22:19,880:INFO:Uploading model into container now
2024-10-05 12:22:19,880:INFO:_master_model_container: 5
2024-10-05 12:22:19,880:INFO:_display_container: 2
2024-10-05 12:22:19,880:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5614, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-10-05 12:22:19,880:INFO:create_model() successfully completed......................................
2024-10-05 12:22:19,958:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:19,958:INFO:Creating metrics dataframe
2024-10-05 12:22:19,965:INFO:Initializing Ridge Classifier
2024-10-05 12:22:19,965:INFO:Total runtime is 0.19792837699254356 minutes
2024-10-05 12:22:19,966:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:19,966:INFO:Initializing create_model()
2024-10-05 12:22:19,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:19,966:INFO:Checking exceptions
2024-10-05 12:22:19,966:INFO:Importing libraries
2024-10-05 12:22:19,966:INFO:Copying training dataset
2024-10-05 12:22:19,973:INFO:Defining folds
2024-10-05 12:22:19,973:INFO:Declaring metric variables
2024-10-05 12:22:19,974:INFO:Importing untrained model
2024-10-05 12:22:19,974:INFO:Ridge Classifier Imported successfully
2024-10-05 12:22:19,975:INFO:Starting cross validation
2024-10-05 12:22:19,976:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:20,952:INFO:Calculating mean and std
2024-10-05 12:22:20,952:INFO:Creating metrics dataframe
2024-10-05 12:22:20,952:INFO:Uploading results into container
2024-10-05 12:22:20,952:INFO:Uploading model into container now
2024-10-05 12:22:20,952:INFO:_master_model_container: 6
2024-10-05 12:22:20,952:INFO:_display_container: 2
2024-10-05 12:22:20,952:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5614, solver='auto',
                tol=0.0001)
2024-10-05 12:22:20,952:INFO:create_model() successfully completed......................................
2024-10-05 12:22:21,031:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:21,031:INFO:Creating metrics dataframe
2024-10-05 12:22:21,035:INFO:Initializing Random Forest Classifier
2024-10-05 12:22:21,035:INFO:Total runtime is 0.21575431426366173 minutes
2024-10-05 12:22:21,035:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:21,036:INFO:Initializing create_model()
2024-10-05 12:22:21,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:21,036:INFO:Checking exceptions
2024-10-05 12:22:21,036:INFO:Importing libraries
2024-10-05 12:22:21,036:INFO:Copying training dataset
2024-10-05 12:22:21,041:INFO:Defining folds
2024-10-05 12:22:21,041:INFO:Declaring metric variables
2024-10-05 12:22:21,042:INFO:Importing untrained model
2024-10-05 12:22:21,042:INFO:Random Forest Classifier Imported successfully
2024-10-05 12:22:21,043:INFO:Starting cross validation
2024-10-05 12:22:21,045:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:21,748:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:21,748:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:21,764:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:21,811:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:22,408:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:22,423:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:22,439:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:22,640:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:22,989:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:23,004:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:23,035:INFO:Calculating mean and std
2024-10-05 12:22:23,035:INFO:Creating metrics dataframe
2024-10-05 12:22:23,035:INFO:Uploading results into container
2024-10-05 12:22:23,035:INFO:Uploading model into container now
2024-10-05 12:22:23,035:INFO:_master_model_container: 7
2024-10-05 12:22:23,035:INFO:_display_container: 2
2024-10-05 12:22:23,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5614, verbose=0,
                       warm_start=False)
2024-10-05 12:22:23,035:INFO:create_model() successfully completed......................................
2024-10-05 12:22:23,120:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:23,121:INFO:Creating metrics dataframe
2024-10-05 12:22:23,125:INFO:Initializing Quadratic Discriminant Analysis
2024-10-05 12:22:23,125:INFO:Total runtime is 0.25059128999710084 minutes
2024-10-05 12:22:23,125:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:23,126:INFO:Initializing create_model()
2024-10-05 12:22:23,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:23,126:INFO:Checking exceptions
2024-10-05 12:22:23,126:INFO:Importing libraries
2024-10-05 12:22:23,126:INFO:Copying training dataset
2024-10-05 12:22:23,133:INFO:Defining folds
2024-10-05 12:22:23,133:INFO:Declaring metric variables
2024-10-05 12:22:23,133:INFO:Importing untrained model
2024-10-05 12:22:23,133:INFO:Quadratic Discriminant Analysis Imported successfully
2024-10-05 12:22:23,134:INFO:Starting cross validation
2024-10-05 12:22:23,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:23,286:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-05 12:22:23,523:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-05 12:22:23,523:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-05 12:22:23,523:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-05 12:22:23,531:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-05 12:22:23,692:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-05 12:22:23,692:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-05 12:22:23,777:INFO:Calculating mean and std
2024-10-05 12:22:23,777:INFO:Creating metrics dataframe
2024-10-05 12:22:23,777:INFO:Uploading results into container
2024-10-05 12:22:23,777:INFO:Uploading model into container now
2024-10-05 12:22:23,777:INFO:_master_model_container: 8
2024-10-05 12:22:23,777:INFO:_display_container: 2
2024-10-05 12:22:23,777:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-10-05 12:22:23,777:INFO:create_model() successfully completed......................................
2024-10-05 12:22:23,857:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:23,858:INFO:Creating metrics dataframe
2024-10-05 12:22:23,862:INFO:Initializing Ada Boost Classifier
2024-10-05 12:22:23,862:INFO:Total runtime is 0.26288183530171716 minutes
2024-10-05 12:22:23,863:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:23,863:INFO:Initializing create_model()
2024-10-05 12:22:23,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:23,864:INFO:Checking exceptions
2024-10-05 12:22:23,864:INFO:Importing libraries
2024-10-05 12:22:23,864:INFO:Copying training dataset
2024-10-05 12:22:23,872:INFO:Defining folds
2024-10-05 12:22:23,872:INFO:Declaring metric variables
2024-10-05 12:22:23,872:INFO:Importing untrained model
2024-10-05 12:22:23,872:INFO:Ada Boost Classifier Imported successfully
2024-10-05 12:22:23,872:INFO:Starting cross validation
2024-10-05 12:22:23,879:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:24,037:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-05 12:22:24,526:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-05 12:22:24,526:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-05 12:22:24,526:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-05 12:22:24,526:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-05 12:22:24,983:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-05 12:22:24,985:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-05 12:22:25,234:INFO:Calculating mean and std
2024-10-05 12:22:25,234:INFO:Creating metrics dataframe
2024-10-05 12:22:25,234:INFO:Uploading results into container
2024-10-05 12:22:25,234:INFO:Uploading model into container now
2024-10-05 12:22:25,234:INFO:_master_model_container: 9
2024-10-05 12:22:25,234:INFO:_display_container: 2
2024-10-05 12:22:25,234:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5614)
2024-10-05 12:22:25,234:INFO:create_model() successfully completed......................................
2024-10-05 12:22:25,315:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:25,316:INFO:Creating metrics dataframe
2024-10-05 12:22:25,319:INFO:Initializing Gradient Boosting Classifier
2024-10-05 12:22:25,319:INFO:Total runtime is 0.28714922666549686 minutes
2024-10-05 12:22:25,320:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:25,320:INFO:Initializing create_model()
2024-10-05 12:22:25,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:25,320:INFO:Checking exceptions
2024-10-05 12:22:25,320:INFO:Importing libraries
2024-10-05 12:22:25,320:INFO:Copying training dataset
2024-10-05 12:22:25,325:INFO:Defining folds
2024-10-05 12:22:25,326:INFO:Declaring metric variables
2024-10-05 12:22:25,326:INFO:Importing untrained model
2024-10-05 12:22:25,326:INFO:Gradient Boosting Classifier Imported successfully
2024-10-05 12:22:25,327:INFO:Starting cross validation
2024-10-05 12:22:25,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:26,766:INFO:Calculating mean and std
2024-10-05 12:22:26,766:INFO:Creating metrics dataframe
2024-10-05 12:22:26,766:INFO:Uploading results into container
2024-10-05 12:22:26,766:INFO:Uploading model into container now
2024-10-05 12:22:26,766:INFO:_master_model_container: 10
2024-10-05 12:22:26,766:INFO:_display_container: 2
2024-10-05 12:22:26,766:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-05 12:22:26,766:INFO:create_model() successfully completed......................................
2024-10-05 12:22:26,848:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:26,848:INFO:Creating metrics dataframe
2024-10-05 12:22:26,852:INFO:Initializing Linear Discriminant Analysis
2024-10-05 12:22:26,852:INFO:Total runtime is 0.3127121686935425 minutes
2024-10-05 12:22:26,852:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:26,853:INFO:Initializing create_model()
2024-10-05 12:22:26,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:26,853:INFO:Checking exceptions
2024-10-05 12:22:26,853:INFO:Importing libraries
2024-10-05 12:22:26,853:INFO:Copying training dataset
2024-10-05 12:22:26,858:INFO:Defining folds
2024-10-05 12:22:26,859:INFO:Declaring metric variables
2024-10-05 12:22:26,859:INFO:Importing untrained model
2024-10-05 12:22:26,859:INFO:Linear Discriminant Analysis Imported successfully
2024-10-05 12:22:26,860:INFO:Starting cross validation
2024-10-05 12:22:26,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:27,526:INFO:Calculating mean and std
2024-10-05 12:22:27,526:INFO:Creating metrics dataframe
2024-10-05 12:22:27,526:INFO:Uploading results into container
2024-10-05 12:22:27,526:INFO:Uploading model into container now
2024-10-05 12:22:27,526:INFO:_master_model_container: 11
2024-10-05 12:22:27,526:INFO:_display_container: 2
2024-10-05 12:22:27,526:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-10-05 12:22:27,526:INFO:create_model() successfully completed......................................
2024-10-05 12:22:27,612:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:27,613:INFO:Creating metrics dataframe
2024-10-05 12:22:27,618:INFO:Initializing Extra Trees Classifier
2024-10-05 12:22:27,618:INFO:Total runtime is 0.3254725933074952 minutes
2024-10-05 12:22:27,619:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:27,619:INFO:Initializing create_model()
2024-10-05 12:22:27,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:27,619:INFO:Checking exceptions
2024-10-05 12:22:27,619:INFO:Importing libraries
2024-10-05 12:22:27,619:INFO:Copying training dataset
2024-10-05 12:22:27,625:INFO:Defining folds
2024-10-05 12:22:27,625:INFO:Declaring metric variables
2024-10-05 12:22:27,625:INFO:Importing untrained model
2024-10-05 12:22:27,626:INFO:Extra Trees Classifier Imported successfully
2024-10-05 12:22:27,626:INFO:Starting cross validation
2024-10-05 12:22:27,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:28,253:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:28,253:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:28,253:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:28,331:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:28,877:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:28,893:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:28,940:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:29,033:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:29,360:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:29,376:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:29,407:INFO:Calculating mean and std
2024-10-05 12:22:29,407:INFO:Creating metrics dataframe
2024-10-05 12:22:29,407:INFO:Uploading results into container
2024-10-05 12:22:29,407:INFO:Uploading model into container now
2024-10-05 12:22:29,407:INFO:_master_model_container: 12
2024-10-05 12:22:29,407:INFO:_display_container: 2
2024-10-05 12:22:29,407:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5614, verbose=0,
                     warm_start=False)
2024-10-05 12:22:29,407:INFO:create_model() successfully completed......................................
2024-10-05 12:22:29,496:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:29,496:INFO:Creating metrics dataframe
2024-10-05 12:22:29,500:INFO:Initializing Light Gradient Boosting Machine
2024-10-05 12:22:29,500:INFO:Total runtime is 0.3568468848864238 minutes
2024-10-05 12:22:29,500:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:29,500:INFO:Initializing create_model()
2024-10-05 12:22:29,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:29,501:INFO:Checking exceptions
2024-10-05 12:22:29,501:INFO:Importing libraries
2024-10-05 12:22:29,501:INFO:Copying training dataset
2024-10-05 12:22:29,506:INFO:Defining folds
2024-10-05 12:22:29,506:INFO:Declaring metric variables
2024-10-05 12:22:29,507:INFO:Importing untrained model
2024-10-05 12:22:29,507:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-05 12:22:29,508:INFO:Starting cross validation
2024-10-05 12:22:29,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:29,982:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:29,982:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:29,982:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:30,027:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:30,428:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:30,444:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:30,460:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:30,543:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:30,777:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:30,808:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:30,840:INFO:Calculating mean and std
2024-10-05 12:22:30,840:INFO:Creating metrics dataframe
2024-10-05 12:22:30,840:INFO:Uploading results into container
2024-10-05 12:22:30,840:INFO:Uploading model into container now
2024-10-05 12:22:30,840:INFO:_master_model_container: 13
2024-10-05 12:22:30,840:INFO:_display_container: 2
2024-10-05 12:22:30,840:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5614, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-10-05 12:22:30,840:INFO:create_model() successfully completed......................................
2024-10-05 12:22:30,937:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:30,938:INFO:Creating metrics dataframe
2024-10-05 12:22:30,943:INFO:Initializing Dummy Classifier
2024-10-05 12:22:30,943:INFO:Total runtime is 0.3808857083320618 minutes
2024-10-05 12:22:30,943:INFO:SubProcess create_model() called ==================================
2024-10-05 12:22:30,943:INFO:Initializing create_model()
2024-10-05 12:22:30,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AED51A0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:30,943:INFO:Checking exceptions
2024-10-05 12:22:30,943:INFO:Importing libraries
2024-10-05 12:22:30,943:INFO:Copying training dataset
2024-10-05 12:22:30,943:INFO:Defining folds
2024-10-05 12:22:30,943:INFO:Declaring metric variables
2024-10-05 12:22:30,943:INFO:Importing untrained model
2024-10-05 12:22:30,943:INFO:Dummy Classifier Imported successfully
2024-10-05 12:22:30,943:INFO:Starting cross validation
2024-10-05 12:22:30,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-05 12:22:31,158:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:31,174:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:31,174:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:31,190:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:31,190:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:31,190:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:31,205:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:31,205:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:31,403:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:31,419:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:31,419:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:31,419:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:31,434:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:31,434:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:31,434:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:31,450:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:31,584:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:31,593:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:31,604:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-10-05 12:22:31,609:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-05 12:22:31,625:INFO:Calculating mean and std
2024-10-05 12:22:31,625:INFO:Creating metrics dataframe
2024-10-05 12:22:31,625:INFO:Uploading results into container
2024-10-05 12:22:31,625:INFO:Uploading model into container now
2024-10-05 12:22:31,625:INFO:_master_model_container: 14
2024-10-05 12:22:31,625:INFO:_display_container: 2
2024-10-05 12:22:31,625:INFO:DummyClassifier(constant=None, random_state=5614, strategy='prior')
2024-10-05 12:22:31,625:INFO:create_model() successfully completed......................................
2024-10-05 12:22:31,705:INFO:SubProcess create_model() end ==================================
2024-10-05 12:22:31,705:INFO:Creating metrics dataframe
2024-10-05 12:22:31,726:WARNING:C:\PROGRA~3\MINICO~1\envs\PYCARE~1\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-10-05 12:22:31,726:INFO:Initializing create_model()
2024-10-05 12:22:31,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-05 12:22:31,726:INFO:Checking exceptions
2024-10-05 12:22:31,726:INFO:Importing libraries
2024-10-05 12:22:31,726:INFO:Copying training dataset
2024-10-05 12:22:31,747:INFO:Defining folds
2024-10-05 12:22:31,747:INFO:Declaring metric variables
2024-10-05 12:22:31,747:INFO:Importing untrained model
2024-10-05 12:22:31,747:INFO:Declaring custom model
2024-10-05 12:22:31,751:INFO:Gradient Boosting Classifier Imported successfully
2024-10-05 12:22:31,754:INFO:Cross validation set to False
2024-10-05 12:22:31,754:INFO:Fitting Model
2024-10-05 12:22:32,077:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-05 12:22:32,093:INFO:create_model() successfully completed......................................
2024-10-05 12:22:32,193:INFO:_master_model_container: 14
2024-10-05 12:22:32,193:INFO:_display_container: 2
2024-10-05 12:22:32,194:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-05 12:22:32,194:INFO:compare_models() successfully completed......................................
2024-10-05 12:22:51,571:INFO:Initializing save_model()
2024-10-05 12:22:51,572:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=C:/R/Extending-Power-BI-with-Python-and-R-2nd-edition/Ch17 - Using Machine Learning Without Premium or Embedded Capacity/titanic-model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\antti\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                                                        {'col': 'Pclass',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 1.0    0
2.0    1
3.0    2
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-10-05 12:22:51,572:INFO:Adding model into prep_pipe
2024-10-05 12:22:51,588:INFO:C:/R/Extending-Power-BI-with-Python-and-R-2nd-edition/Ch17 - Using Machine Learning Without Premium or Embedded Capacity/titanic-model.pkl saved in current working directory
2024-10-05 12:22:51,635:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=['Sex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=5614, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-10-05 12:22:51,635:INFO:save_model() successfully completed......................................
2024-10-05 12:24:11,746:INFO:Initializing predict_model()
2024-10-05 12:24:11,746:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AED3A00F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002AED52E8F70>)
2024-10-05 12:24:11,746:INFO:Checking exceptions
2024-10-05 12:24:11,746:INFO:Preloading libraries
2024-10-05 12:24:11,748:INFO:Set up data.
2024-10-05 12:24:11,769:INFO:Set up index.
2024-10-05 12:25:25,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-05 12:25:25,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-05 12:25:25,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-05 12:25:25,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-05 12:25:28,143:INFO:Initializing load_model()
2024-10-05 12:25:28,159:INFO:load_model(model_name=C:\<your-path>\Ch17 - Using Machine Learning Without Premium or Embedded Capacity\Python\titanic-model, platform=None, authentication=None, verbose=True)
2024-10-05 12:26:01,831:INFO:Initializing load_model()
2024-10-05 12:26:01,831:INFO:load_model(model_name=C:/R/Extending-Power-BI-with-Python-and-R-2nd-edition/Ch17 - Using Machine Learning Without Premium or Embedded Capacity/Python/titanic-model, platform=None, authentication=None, verbose=True)
2024-10-05 12:26:17,304:INFO:Initializing load_model()
2024-10-05 12:26:17,304:INFO:load_model(model_name=C:/R/Extending-Power-BI-with-Python-and-R-2nd-edition/Ch17 - Using Machine Learning Without Premium or Embedded Capacity/Python/titanic-model.pkl, platform=None, authentication=None, verbose=True)
2024-10-05 12:26:43,091:INFO:Initializing load_model()
2024-10-05 12:26:43,091:INFO:load_model(model_name=C:/R/Extending-Power-BI-with-Python-and-R-2nd-edition/Ch17 - Using Machine Learning Without Premium or Embedded Capacity/titanic-model, platform=None, authentication=None, verbose=True)
2024-10-05 12:26:43,371:INFO:Initializing predict_model()
2024-10-05 12:26:43,371:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F05888430>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Sex', 'Embarked'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerWrapper(include=['Sex', 'Pclass'],...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'Pclass',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 1.0    0
2.0    1
3.0    2
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=5614))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025F7D030B80>)
2024-10-05 12:26:43,371:INFO:Checking exceptions
2024-10-05 12:26:43,371:INFO:Preloading libraries
2024-10-05 12:26:43,371:INFO:Set up data.
2024-10-05 12:26:43,371:INFO:Set up index.
