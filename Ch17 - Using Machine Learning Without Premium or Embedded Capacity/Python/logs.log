2023-01-27 10:35:08,520:INFO:PyCaret Supervised Module
2023-01-27 10:35:08,521:INFO:ML Usecase: classification
2023-01-27 10:35:08,521:INFO:version 2.3.10
2023-01-27 10:35:08,521:INFO:Initializing setup()
2023-01-27 10:35:08,521:INFO:setup(target=Survived, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree', 'ks': 'KS Statistic Plot'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=['Sex', 'Embarked'], categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features={'Pclass': [1, 2, 3]}, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=1, use_gpu=False, custom_pipeline=None, html=True, session_id=5614, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=True, verbose=False, profile=False, profile_kwargs=None, display=None)
2023-01-27 10:35:08,521:INFO:Checking environment
2023-01-27 10:35:08,521:INFO:python_version: 3.8.16
2023-01-27 10:35:08,522:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-01-27 10:35:08,522:INFO:machine: AMD64
2023-01-27 10:35:08,522:INFO:platform: Windows-10-10.0.19045-SP0
2023-01-27 10:35:08,522:INFO:Memory: svmem(total=33942257664, available=18048487424, percent=46.8, used=15893770240, free=18048487424)
2023-01-27 10:35:08,522:INFO:Physical Core: 6
2023-01-27 10:35:08,522:INFO:Logical Core: 12
2023-01-27 10:35:08,522:INFO:Checking libraries
2023-01-27 10:35:08,522:INFO:pd==1.5.3
2023-01-27 10:35:08,522:INFO:numpy==1.20.3
2023-01-27 10:35:08,522:INFO:sklearn==0.23.2
2023-01-27 10:35:08,522:INFO:lightgbm==3.3.5
2023-01-27 10:35:08,523:WARNING:catboost not found
2023-01-27 10:35:08,524:WARNING:xgboost not found
2023-01-27 10:35:08,524:INFO:mlflow==2.1.1
2023-01-27 10:35:08,524:INFO:Checking Exceptions
2023-01-27 10:35:08,525:INFO:Declaring global variables
2023-01-27 10:35:08,525:INFO:USI: 09cb
2023-01-27 10:35:08,525:INFO:pycaret_globals: {'experiment__', 'fix_imbalance_param', 'seed', 'imputation_regressor', 'imputation_classifier', 'dashboard_logger', 'gpu_param', 'fold_groups_param_full', 'master_model_container', 'X_train', 'transform_target_param', 'stratify_param', '_all_models_internal', 'fold_generator', 'X', 'create_model_container', 'iterative_imputation_iters_param', '_available_plots', 'fold_param', 'y_train', 'y', 'logging_param', 'X_test', 'transform_target_method_param', 'html_param', 'display_container', 'log_plots_param', '_all_models', '_ml_usecase', 'target_param', '_all_metrics', 'y_test', 'data_before_preprocess', 'fold_shuffle_param', 'fix_imbalance_method_param', 'fold_groups_param', 'exp_name_log', '_gpu_n_jobs_param', 'prep_pipe', 'USI', '_internal_pipeline', 'pycaret_globals', 'n_jobs_param'}
2023-01-27 10:35:08,525:INFO:Preparing display monitor
2023-01-27 10:35:08,526:INFO:Importing libraries
2023-01-27 10:35:08,526:INFO:Copying data for preprocessing
2023-01-27 10:35:08,526:INFO:Declaring preprocessing parameters
2023-01-27 10:35:08,527:INFO:Creating preprocessing pipeline
2023-01-27 10:35:08,531:INFO:Preprocessing pipeline created successfully
2023-01-27 10:35:08,531:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-27 10:35:08,531:INFO:Creating global containers
2023-01-27 10:35:08,532:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-27 10:35:08,733:WARNING:Couldn't import xgboost.XGBClassifier
2023-01-27 10:35:08,734:WARNING:Couldn't import catboost.CatBoostClassifier
2023-01-27 10:35:08,806:WARNING:Couldn't import xgboost.XGBClassifier
2023-01-27 10:35:08,807:WARNING:Couldn't import catboost.CatBoostClassifier
2023-01-27 10:35:08,807:INFO:Creating grid variables
2023-01-27 10:35:08,809:INFO:create_model_container: 0
2023-01-27 10:35:08,809:INFO:master_model_container: 0
2023-01-27 10:35:08,809:INFO:display_container: 1
2023-01-27 10:35:08,814:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=['Sex', 'Embarked'],
                                      display_types=False, features_todrop=[],
                                      id_columns=[],
                                      ml_usecase='classification',
                                      numerical_features=[], target='Survived',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_available',
                                fill_value_categorical=None,
                                fill_value_numerical...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='Survived')),
                ('fix_perfect', Remove_100(target='Survived')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-01-27 10:35:08,814:INFO:setup() succesfully completed......................................
2023-01-27 10:35:12,676:INFO:Initializing compare_models()
2023-01-27 10:35:12,677:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-01-27 10:35:12,677:INFO:Checking exceptions
2023-01-27 10:35:12,678:INFO:Preparing display monitor
2023-01-27 10:35:12,678:INFO:Preparing display monitor
2023-01-27 10:35:12,709:INFO:Initializing Logistic Regression
2023-01-27 10:35:12,709:INFO:Total runtime is 0.0 minutes
2023-01-27 10:35:12,718:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:12,718:INFO:Initializing create_model()
2023-01-27 10:35:12,719:INFO:create_model(estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:12,719:INFO:Checking exceptions
2023-01-27 10:35:12,719:INFO:Importing libraries
2023-01-27 10:35:12,719:INFO:Copying training dataset
2023-01-27 10:35:12,719:INFO:Defining folds
2023-01-27 10:35:12,720:INFO:Declaring metric variables
2023-01-27 10:35:12,729:INFO:Importing untrained model
2023-01-27 10:35:12,737:INFO:Logistic Regression Imported succesfully
2023-01-27 10:35:12,753:INFO:Starting cross validation
2023-01-27 10:35:12,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:13,417:INFO:Calculating mean and std
2023-01-27 10:35:13,418:INFO:Creating metrics dataframe
2023-01-27 10:35:13,422:INFO:Uploading results into container
2023-01-27 10:35:13,422:INFO:Uploading model into container now
2023-01-27 10:35:13,422:INFO:create_model_container: 1
2023-01-27 10:35:13,422:INFO:master_model_container: 1
2023-01-27 10:35:13,422:INFO:display_container: 2
2023-01-27 10:35:13,423:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5614, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-01-27 10:35:13,423:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:13,498:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:13,498:INFO:Creating metrics dataframe
2023-01-27 10:35:13,510:INFO:Initializing K Neighbors Classifier
2023-01-27 10:35:13,510:INFO:Total runtime is 0.013348019123077393 minutes
2023-01-27 10:35:13,519:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:13,520:INFO:Initializing create_model()
2023-01-27 10:35:13,520:INFO:create_model(estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:13,520:INFO:Checking exceptions
2023-01-27 10:35:13,520:INFO:Importing libraries
2023-01-27 10:35:13,520:INFO:Copying training dataset
2023-01-27 10:35:13,521:INFO:Defining folds
2023-01-27 10:35:13,521:INFO:Declaring metric variables
2023-01-27 10:35:13,530:INFO:Importing untrained model
2023-01-27 10:35:13,537:INFO:K Neighbors Classifier Imported succesfully
2023-01-27 10:35:13,552:INFO:Starting cross validation
2023-01-27 10:35:13,553:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:13,695:INFO:Calculating mean and std
2023-01-27 10:35:13,696:INFO:Creating metrics dataframe
2023-01-27 10:35:13,700:INFO:Uploading results into container
2023-01-27 10:35:13,700:INFO:Uploading model into container now
2023-01-27 10:35:13,701:INFO:create_model_container: 2
2023-01-27 10:35:13,701:INFO:master_model_container: 2
2023-01-27 10:35:13,701:INFO:display_container: 2
2023-01-27 10:35:13,701:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2023-01-27 10:35:13,701:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:13,780:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:13,780:INFO:Creating metrics dataframe
2023-01-27 10:35:13,796:INFO:Initializing Naive Bayes
2023-01-27 10:35:13,796:INFO:Total runtime is 0.018114479382832845 minutes
2023-01-27 10:35:13,805:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:13,805:INFO:Initializing create_model()
2023-01-27 10:35:13,805:INFO:create_model(estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:13,805:INFO:Checking exceptions
2023-01-27 10:35:13,805:INFO:Importing libraries
2023-01-27 10:35:13,805:INFO:Copying training dataset
2023-01-27 10:35:13,806:INFO:Defining folds
2023-01-27 10:35:13,806:INFO:Declaring metric variables
2023-01-27 10:35:13,815:INFO:Importing untrained model
2023-01-27 10:35:13,823:INFO:Naive Bayes Imported succesfully
2023-01-27 10:35:13,839:INFO:Starting cross validation
2023-01-27 10:35:13,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:13,950:INFO:Calculating mean and std
2023-01-27 10:35:13,951:INFO:Creating metrics dataframe
2023-01-27 10:35:13,955:INFO:Uploading results into container
2023-01-27 10:35:13,955:INFO:Uploading model into container now
2023-01-27 10:35:13,955:INFO:create_model_container: 3
2023-01-27 10:35:13,956:INFO:master_model_container: 3
2023-01-27 10:35:13,956:INFO:display_container: 2
2023-01-27 10:35:13,956:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-01-27 10:35:13,956:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:14,034:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:14,035:INFO:Creating metrics dataframe
2023-01-27 10:35:14,048:INFO:Initializing Decision Tree Classifier
2023-01-27 10:35:14,049:INFO:Total runtime is 0.022332374254862467 minutes
2023-01-27 10:35:14,058:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:14,058:INFO:Initializing create_model()
2023-01-27 10:35:14,058:INFO:create_model(estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:14,058:INFO:Checking exceptions
2023-01-27 10:35:14,059:INFO:Importing libraries
2023-01-27 10:35:14,059:INFO:Copying training dataset
2023-01-27 10:35:14,059:INFO:Defining folds
2023-01-27 10:35:14,060:INFO:Declaring metric variables
2023-01-27 10:35:14,068:INFO:Importing untrained model
2023-01-27 10:35:14,077:INFO:Decision Tree Classifier Imported succesfully
2023-01-27 10:35:14,099:INFO:Starting cross validation
2023-01-27 10:35:14,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:14,217:INFO:Calculating mean and std
2023-01-27 10:35:14,217:INFO:Creating metrics dataframe
2023-01-27 10:35:14,222:INFO:Uploading results into container
2023-01-27 10:35:14,222:INFO:Uploading model into container now
2023-01-27 10:35:14,222:INFO:create_model_container: 4
2023-01-27 10:35:14,222:INFO:master_model_container: 4
2023-01-27 10:35:14,222:INFO:display_container: 2
2023-01-27 10:35:14,222:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=5614, splitter='best')
2023-01-27 10:35:14,222:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:14,300:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:14,301:INFO:Creating metrics dataframe
2023-01-27 10:35:14,319:INFO:Initializing SVM - Linear Kernel
2023-01-27 10:35:14,319:INFO:Total runtime is 0.026841731866200765 minutes
2023-01-27 10:35:14,329:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:14,329:INFO:Initializing create_model()
2023-01-27 10:35:14,329:INFO:create_model(estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:14,329:INFO:Checking exceptions
2023-01-27 10:35:14,329:INFO:Importing libraries
2023-01-27 10:35:14,330:INFO:Copying training dataset
2023-01-27 10:35:14,330:INFO:Defining folds
2023-01-27 10:35:14,330:INFO:Declaring metric variables
2023-01-27 10:35:14,338:INFO:Importing untrained model
2023-01-27 10:35:14,346:INFO:SVM - Linear Kernel Imported succesfully
2023-01-27 10:35:14,362:INFO:Starting cross validation
2023-01-27 10:35:14,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:14,460:INFO:Calculating mean and std
2023-01-27 10:35:14,462:INFO:Creating metrics dataframe
2023-01-27 10:35:14,466:INFO:Uploading results into container
2023-01-27 10:35:14,467:INFO:Uploading model into container now
2023-01-27 10:35:14,467:INFO:create_model_container: 5
2023-01-27 10:35:14,467:INFO:master_model_container: 5
2023-01-27 10:35:14,467:INFO:display_container: 2
2023-01-27 10:35:14,467:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=5614, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-01-27 10:35:14,467:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:14,541:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:14,541:INFO:Creating metrics dataframe
2023-01-27 10:35:14,555:INFO:Initializing Ridge Classifier
2023-01-27 10:35:14,555:INFO:Total runtime is 0.03077505032221476 minutes
2023-01-27 10:35:14,563:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:14,564:INFO:Initializing create_model()
2023-01-27 10:35:14,564:INFO:create_model(estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:14,564:INFO:Checking exceptions
2023-01-27 10:35:14,564:INFO:Importing libraries
2023-01-27 10:35:14,564:INFO:Copying training dataset
2023-01-27 10:35:14,565:INFO:Defining folds
2023-01-27 10:35:14,565:INFO:Declaring metric variables
2023-01-27 10:35:14,573:INFO:Importing untrained model
2023-01-27 10:35:14,580:INFO:Ridge Classifier Imported succesfully
2023-01-27 10:35:14,595:INFO:Starting cross validation
2023-01-27 10:35:14,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:14,688:INFO:Calculating mean and std
2023-01-27 10:35:14,688:INFO:Creating metrics dataframe
2023-01-27 10:35:14,693:INFO:Uploading results into container
2023-01-27 10:35:14,693:INFO:Uploading model into container now
2023-01-27 10:35:14,693:INFO:create_model_container: 6
2023-01-27 10:35:14,693:INFO:master_model_container: 6
2023-01-27 10:35:14,693:INFO:display_container: 2
2023-01-27 10:35:14,694:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize=False, random_state=5614,
                solver='auto', tol=0.001)
2023-01-27 10:35:14,694:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:14,771:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:14,772:INFO:Creating metrics dataframe
2023-01-27 10:35:14,789:INFO:Initializing Random Forest Classifier
2023-01-27 10:35:14,789:INFO:Total runtime is 0.03467507759730021 minutes
2023-01-27 10:35:14,800:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:14,801:INFO:Initializing create_model()
2023-01-27 10:35:14,801:INFO:create_model(estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:14,801:INFO:Checking exceptions
2023-01-27 10:35:14,801:INFO:Importing libraries
2023-01-27 10:35:14,801:INFO:Copying training dataset
2023-01-27 10:35:14,802:INFO:Defining folds
2023-01-27 10:35:14,802:INFO:Declaring metric variables
2023-01-27 10:35:14,810:INFO:Importing untrained model
2023-01-27 10:35:14,819:INFO:Random Forest Classifier Imported succesfully
2023-01-27 10:35:14,836:INFO:Starting cross validation
2023-01-27 10:35:14,837:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:16,729:INFO:Calculating mean and std
2023-01-27 10:35:16,730:INFO:Creating metrics dataframe
2023-01-27 10:35:16,735:INFO:Uploading results into container
2023-01-27 10:35:16,735:INFO:Uploading model into container now
2023-01-27 10:35:16,735:INFO:create_model_container: 7
2023-01-27 10:35:16,735:INFO:master_model_container: 7
2023-01-27 10:35:16,735:INFO:display_container: 2
2023-01-27 10:35:16,736:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=5614, verbose=0,
                       warm_start=False)
2023-01-27 10:35:16,736:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:16,815:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:16,815:INFO:Creating metrics dataframe
2023-01-27 10:35:16,832:INFO:Initializing Quadratic Discriminant Analysis
2023-01-27 10:35:16,832:INFO:Total runtime is 0.06871285438537597 minutes
2023-01-27 10:35:16,841:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:16,842:INFO:Initializing create_model()
2023-01-27 10:35:16,842:INFO:create_model(estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:16,842:INFO:Checking exceptions
2023-01-27 10:35:16,842:INFO:Importing libraries
2023-01-27 10:35:16,842:INFO:Copying training dataset
2023-01-27 10:35:16,843:INFO:Defining folds
2023-01-27 10:35:16,843:INFO:Declaring metric variables
2023-01-27 10:35:16,851:INFO:Importing untrained model
2023-01-27 10:35:16,859:INFO:Quadratic Discriminant Analysis Imported succesfully
2023-01-27 10:35:16,876:INFO:Starting cross validation
2023-01-27 10:35:16,877:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:16,993:INFO:Calculating mean and std
2023-01-27 10:35:16,994:INFO:Creating metrics dataframe
2023-01-27 10:35:16,999:INFO:Uploading results into container
2023-01-27 10:35:17,000:INFO:Uploading model into container now
2023-01-27 10:35:17,000:INFO:create_model_container: 8
2023-01-27 10:35:17,000:INFO:master_model_container: 8
2023-01-27 10:35:17,000:INFO:display_container: 2
2023-01-27 10:35:17,001:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-01-27 10:35:17,001:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:17,086:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:17,086:INFO:Creating metrics dataframe
2023-01-27 10:35:17,102:INFO:Initializing Ada Boost Classifier
2023-01-27 10:35:17,102:INFO:Total runtime is 0.07321292161941528 minutes
2023-01-27 10:35:17,111:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:17,111:INFO:Initializing create_model()
2023-01-27 10:35:17,111:INFO:create_model(estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:17,112:INFO:Checking exceptions
2023-01-27 10:35:17,112:INFO:Importing libraries
2023-01-27 10:35:17,112:INFO:Copying training dataset
2023-01-27 10:35:17,113:INFO:Defining folds
2023-01-27 10:35:17,113:INFO:Declaring metric variables
2023-01-27 10:35:17,121:INFO:Importing untrained model
2023-01-27 10:35:17,129:INFO:Ada Boost Classifier Imported succesfully
2023-01-27 10:35:17,147:INFO:Starting cross validation
2023-01-27 10:35:17,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:18,042:INFO:Calculating mean and std
2023-01-27 10:35:18,043:INFO:Creating metrics dataframe
2023-01-27 10:35:18,048:INFO:Uploading results into container
2023-01-27 10:35:18,048:INFO:Uploading model into container now
2023-01-27 10:35:18,048:INFO:create_model_container: 9
2023-01-27 10:35:18,049:INFO:master_model_container: 9
2023-01-27 10:35:18,049:INFO:display_container: 2
2023-01-27 10:35:18,050:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5614)
2023-01-27 10:35:18,050:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:18,134:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:18,134:INFO:Creating metrics dataframe
2023-01-27 10:35:18,151:INFO:Initializing Gradient Boosting Classifier
2023-01-27 10:35:18,151:INFO:Total runtime is 0.09070654312769572 minutes
2023-01-27 10:35:18,161:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:18,161:INFO:Initializing create_model()
2023-01-27 10:35:18,161:INFO:create_model(estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:18,162:INFO:Checking exceptions
2023-01-27 10:35:18,162:INFO:Importing libraries
2023-01-27 10:35:18,162:INFO:Copying training dataset
2023-01-27 10:35:18,162:INFO:Defining folds
2023-01-27 10:35:18,163:INFO:Declaring metric variables
2023-01-27 10:35:18,170:INFO:Importing untrained model
2023-01-27 10:35:18,178:INFO:Gradient Boosting Classifier Imported succesfully
2023-01-27 10:35:18,193:INFO:Starting cross validation
2023-01-27 10:35:18,193:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:19,058:INFO:Calculating mean and std
2023-01-27 10:35:19,059:INFO:Creating metrics dataframe
2023-01-27 10:35:19,063:INFO:Uploading results into container
2023-01-27 10:35:19,063:INFO:Uploading model into container now
2023-01-27 10:35:19,064:INFO:create_model_container: 10
2023-01-27 10:35:19,064:INFO:master_model_container: 10
2023-01-27 10:35:19,064:INFO:display_container: 2
2023-01-27 10:35:19,065:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=100,
                           n_iter_no_change=None, presort='deprecated',
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-01-27 10:35:19,065:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:19,143:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:19,143:INFO:Creating metrics dataframe
2023-01-27 10:35:19,159:INFO:Initializing Linear Discriminant Analysis
2023-01-27 10:35:19,159:INFO:Total runtime is 0.10750199556350708 minutes
2023-01-27 10:35:19,167:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:19,168:INFO:Initializing create_model()
2023-01-27 10:35:19,168:INFO:create_model(estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:19,168:INFO:Checking exceptions
2023-01-27 10:35:19,168:INFO:Importing libraries
2023-01-27 10:35:19,168:INFO:Copying training dataset
2023-01-27 10:35:19,169:INFO:Defining folds
2023-01-27 10:35:19,169:INFO:Declaring metric variables
2023-01-27 10:35:19,176:INFO:Importing untrained model
2023-01-27 10:35:19,184:INFO:Linear Discriminant Analysis Imported succesfully
2023-01-27 10:35:19,199:INFO:Starting cross validation
2023-01-27 10:35:19,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:19,308:INFO:Calculating mean and std
2023-01-27 10:35:19,309:INFO:Creating metrics dataframe
2023-01-27 10:35:19,314:INFO:Uploading results into container
2023-01-27 10:35:19,314:INFO:Uploading model into container now
2023-01-27 10:35:19,315:INFO:create_model_container: 11
2023-01-27 10:35:19,315:INFO:master_model_container: 11
2023-01-27 10:35:19,315:INFO:display_container: 2
2023-01-27 10:35:19,315:INFO:LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
                           solver='svd', store_covariance=False, tol=0.0001)
2023-01-27 10:35:19,315:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:19,397:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:19,397:INFO:Creating metrics dataframe
2023-01-27 10:35:19,416:INFO:Initializing Extra Trees Classifier
2023-01-27 10:35:19,416:INFO:Total runtime is 0.11178672313690186 minutes
2023-01-27 10:35:19,425:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:19,425:INFO:Initializing create_model()
2023-01-27 10:35:19,426:INFO:create_model(estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:19,426:INFO:Checking exceptions
2023-01-27 10:35:19,426:INFO:Importing libraries
2023-01-27 10:35:19,426:INFO:Copying training dataset
2023-01-27 10:35:19,427:INFO:Defining folds
2023-01-27 10:35:19,427:INFO:Declaring metric variables
2023-01-27 10:35:19,435:INFO:Importing untrained model
2023-01-27 10:35:19,443:INFO:Extra Trees Classifier Imported succesfully
2023-01-27 10:35:19,460:INFO:Starting cross validation
2023-01-27 10:35:19,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:21,107:INFO:Calculating mean and std
2023-01-27 10:35:21,108:INFO:Creating metrics dataframe
2023-01-27 10:35:21,113:INFO:Uploading results into container
2023-01-27 10:35:21,114:INFO:Uploading model into container now
2023-01-27 10:35:21,114:INFO:create_model_container: 12
2023-01-27 10:35:21,114:INFO:master_model_container: 12
2023-01-27 10:35:21,114:INFO:display_container: 2
2023-01-27 10:35:21,114:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_impurity_split=None,
                     min_samples_leaf=1, min_samples_split=2,
                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=5614, verbose=0,
                     warm_start=False)
2023-01-27 10:35:21,114:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:21,193:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:21,193:INFO:Creating metrics dataframe
2023-01-27 10:35:21,211:INFO:Initializing Light Gradient Boosting Machine
2023-01-27 10:35:21,211:INFO:Total runtime is 0.14170025587081908 minutes
2023-01-27 10:35:21,220:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:21,221:INFO:Initializing create_model()
2023-01-27 10:35:21,221:INFO:create_model(estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:21,221:INFO:Checking exceptions
2023-01-27 10:35:21,221:INFO:Importing libraries
2023-01-27 10:35:21,221:INFO:Copying training dataset
2023-01-27 10:35:21,222:INFO:Defining folds
2023-01-27 10:35:21,222:INFO:Declaring metric variables
2023-01-27 10:35:21,231:INFO:Importing untrained model
2023-01-27 10:35:21,239:INFO:Light Gradient Boosting Machine Imported succesfully
2023-01-27 10:35:21,255:INFO:Starting cross validation
2023-01-27 10:35:21,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:21,614:INFO:Calculating mean and std
2023-01-27 10:35:21,615:INFO:Creating metrics dataframe
2023-01-27 10:35:21,619:INFO:Uploading results into container
2023-01-27 10:35:21,619:INFO:Uploading model into container now
2023-01-27 10:35:21,620:INFO:create_model_container: 13
2023-01-27 10:35:21,620:INFO:master_model_container: 13
2023-01-27 10:35:21,620:INFO:display_container: 2
2023-01-27 10:35:21,620:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=5614, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-01-27 10:35:21,620:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:21,701:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:21,701:INFO:Creating metrics dataframe
2023-01-27 10:35:21,722:INFO:Initializing Dummy Classifier
2023-01-27 10:35:21,722:INFO:Total runtime is 0.15021723906199136 minutes
2023-01-27 10:35:21,730:INFO:SubProcess create_model() called ==================================
2023-01-27 10:35:21,731:INFO:Initializing create_model()
2023-01-27 10:35:21,731:INFO:create_model(estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000001E413F13310>, return_train_score=False, kwargs={})
2023-01-27 10:35:21,731:INFO:Checking exceptions
2023-01-27 10:35:21,731:INFO:Importing libraries
2023-01-27 10:35:21,732:INFO:Copying training dataset
2023-01-27 10:35:21,732:INFO:Defining folds
2023-01-27 10:35:21,733:INFO:Declaring metric variables
2023-01-27 10:35:21,741:INFO:Importing untrained model
2023-01-27 10:35:21,749:INFO:Dummy Classifier Imported succesfully
2023-01-27 10:35:21,766:INFO:Starting cross validation
2023-01-27 10:35:21,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-01-27 10:35:21,841:INFO:Calculating mean and std
2023-01-27 10:35:21,842:INFO:Creating metrics dataframe
2023-01-27 10:35:21,846:INFO:Uploading results into container
2023-01-27 10:35:21,846:INFO:Uploading model into container now
2023-01-27 10:35:21,847:INFO:create_model_container: 14
2023-01-27 10:35:21,847:INFO:master_model_container: 14
2023-01-27 10:35:21,847:INFO:display_container: 2
2023-01-27 10:35:21,847:INFO:DummyClassifier(constant=None, random_state=5614, strategy='prior')
2023-01-27 10:35:21,847:INFO:create_model() succesfully completed......................................
2023-01-27 10:35:21,929:INFO:SubProcess create_model() end ==================================
2023-01-27 10:35:21,929:INFO:Creating metrics dataframe
2023-01-27 10:35:21,966:INFO:Initializing create_model()
2023-01-27 10:35:21,966:INFO:create_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=100,
                           n_iter_no_change=None, presort='deprecated',
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-01-27 10:35:21,966:INFO:Checking exceptions
2023-01-27 10:35:21,967:INFO:Importing libraries
2023-01-27 10:35:21,967:INFO:Copying training dataset
2023-01-27 10:35:21,968:INFO:Defining folds
2023-01-27 10:35:21,968:INFO:Declaring metric variables
2023-01-27 10:35:21,968:INFO:Importing untrained model
2023-01-27 10:35:21,968:INFO:Declaring custom model
2023-01-27 10:35:21,969:INFO:Gradient Boosting Classifier Imported succesfully
2023-01-27 10:35:21,969:INFO:Cross validation set to False
2023-01-27 10:35:21,969:INFO:Fitting Model
2023-01-27 10:35:22,066:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=100,
                           n_iter_no_change=None, presort='deprecated',
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-01-27 10:35:22,066:INFO:create_models() succesfully completed......................................
2023-01-27 10:35:22,196:INFO:create_model_container: 14
2023-01-27 10:35:22,196:INFO:master_model_container: 14
2023-01-27 10:35:22,196:INFO:display_container: 2
2023-01-27 10:35:22,197:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=100,
                           n_iter_no_change=None, presort='deprecated',
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-01-27 10:35:22,197:INFO:compare_models() succesfully completed......................................
2023-01-27 10:36:22,773:INFO:Initializing save_model()
2023-01-27 10:36:22,774:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=100,
                           n_iter_no_change=None, presort='deprecated',
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=C:\Users\LucaZavarella\OneDrive\MVP\PacktBook\Code\Extending-Power-BI-with-Python-and-R\Chapter13\Python\titanic-model, prep_pipe_=Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=['Sex', 'Embarked'],
                                      display_types=False, features_todrop=[],
                                      id_columns=[],
                                      ml_usecase='classification',
                                      numerical_features=[], target='Survived',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_available',
                                fill_value_categorical=None,
                                fill_value_numerical...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='Survived')),
                ('fix_perfect', Remove_100(target='Survived')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False), verbose=True, kwargs={})
2023-01-27 10:36:22,774:INFO:Adding model into prep_pipe
2023-01-27 10:36:22,792:INFO:C:\Users\LucaZavarella\OneDrive\MVP\PacktBook\Code\Extending-Power-BI-with-Python-and-R\Chapter13\Python\titanic-model.pkl saved in current working directory
2023-01-27 10:36:22,802:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=['Sex', 'Embarked'],
                                      display_types=False, features_todrop=[],
                                      id_columns=[],
                                      ml_usecase='classification',
                                      numerical_features=[], target='Survived',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_available',
                                fill_value_categorical=None,
                                fill_value_numerical...
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_impurity_split=None,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            presort='deprecated',
                                            random_state=5614, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False)]],
         verbose=False)
2023-01-27 10:36:22,802:INFO:save_model() successfully completed......................................
2023-01-27 10:37:22,781:INFO:Initializing predict_model()
2023-01-27 10:37:22,781:INFO:predict_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=100,
                           n_iter_no_change=None, presort='deprecated',
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, drift_report=False, raw_score=False, round=4, verbose=False, ml_usecase=MLUsecase.CLASSIFICATION, display=None, drift_kwargs=None)
2023-01-27 10:37:22,782:INFO:Checking exceptions
2023-01-27 10:37:22,783:INFO:Preloading libraries
2023-08-07 14:17:31,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-07 14:17:31,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-07 14:17:31,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-07 14:17:31,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-07 14:19:48,009:INFO:PyCaret ClassificationExperiment
2023-08-07 14:19:48,010:INFO:Logging name: clf-default-name
2023-08-07 14:19:48,010:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-07 14:19:48,011:INFO:version 3.0.4
2023-08-07 14:19:48,011:INFO:Initializing setup()
2023-08-07 14:19:48,011:INFO:self.USI: 1e9d
2023-08-07 14:19:48,011:INFO:self._variable_keys: {'idx', 'memory', 'fold_generator', 'log_plots_param', 'X_test', 'html_param', 'X', 'target_param', 'data', '_available_plots', 'fix_imbalance', 'gpu_param', 'X_train', 'exp_id', 'gpu_n_jobs_param', 'pipeline', 'y_test', 'n_jobs_param', 'y', 'exp_name_log', 'fold_groups_param', 'USI', 'y_train', 'fold_shuffle_param', '_ml_usecase', 'seed', 'logging_param', 'is_multiclass'}
2023-08-07 14:19:48,012:INFO:Checking environment
2023-08-07 14:19:48,012:INFO:python_version: 3.9.17
2023-08-07 14:19:48,012:INFO:python_build: ('main', 'Jul  5 2023 20:47:11')
2023-08-07 14:19:48,012:INFO:machine: AMD64
2023-08-07 14:19:48,013:INFO:platform: Windows-10-10.0.20348-SP0
2023-08-07 14:19:48,013:INFO:Memory: svmem(total=34358562816, available=27030958080, percent=21.3, used=7327604736, free=27030958080)
2023-08-07 14:19:48,013:INFO:Physical Core: 8
2023-08-07 14:19:48,014:INFO:Logical Core: 8
2023-08-07 14:19:48,014:INFO:Checking libraries
2023-08-07 14:19:48,014:INFO:System:
2023-08-07 14:19:48,014:INFO:    python: 3.9.17 (main, Jul  5 2023, 20:47:11) [MSC v.1916 64 bit (AMD64)]
2023-08-07 14:19:48,014:INFO:executable: c:\ProgramData\Miniconda3\envs\pycaret_env\python.exe
2023-08-07 14:19:48,015:INFO:   machine: Windows-10-10.0.20348-SP0
2023-08-07 14:19:48,015:INFO:PyCaret required dependencies:
2023-08-07 14:19:48,042:INFO:                 pip: 23.2.1
2023-08-07 14:19:48,042:INFO:          setuptools: 68.0.0
2023-08-07 14:19:48,042:INFO:             pycaret: 3.0.4
2023-08-07 14:19:48,043:INFO:             IPython: 8.12.0
2023-08-07 14:19:48,043:INFO:          ipywidgets: 8.1.0
2023-08-07 14:19:48,043:INFO:                tqdm: 4.65.0
2023-08-07 14:19:48,043:INFO:               numpy: 1.23.5
2023-08-07 14:19:48,043:INFO:              pandas: 1.5.3
2023-08-07 14:19:48,044:INFO:              jinja2: 3.1.2
2023-08-07 14:19:48,044:INFO:               scipy: 1.11.1
2023-08-07 14:19:48,044:INFO:              joblib: 1.3.1
2023-08-07 14:19:48,044:INFO:             sklearn: 1.2.2
2023-08-07 14:19:48,045:INFO:                pyod: 1.1.0
2023-08-07 14:19:48,045:INFO:            imblearn: 0.11.0
2023-08-07 14:19:48,045:INFO:   category_encoders: 2.6.1
2023-08-07 14:19:48,045:INFO:            lightgbm: 4.0.0
2023-08-07 14:19:48,045:INFO:               numba: 0.57.1
2023-08-07 14:19:48,046:INFO:            requests: 2.31.0
2023-08-07 14:19:48,046:INFO:          matplotlib: 3.7.2
2023-08-07 14:19:48,046:INFO:          scikitplot: 0.3.7
2023-08-07 14:19:48,046:INFO:         yellowbrick: 1.5
2023-08-07 14:19:48,047:INFO:              plotly: 5.15.0
2023-08-07 14:19:48,047:INFO:    plotly-resampler: Not installed
2023-08-07 14:19:48,047:INFO:             kaleido: 0.2.1
2023-08-07 14:19:48,047:INFO:           schemdraw: 0.15
2023-08-07 14:19:48,047:INFO:         statsmodels: 0.14.0
2023-08-07 14:19:48,048:INFO:              sktime: 0.21.0
2023-08-07 14:19:48,048:INFO:               tbats: 1.1.3
2023-08-07 14:19:48,048:INFO:            pmdarima: 2.0.3
2023-08-07 14:19:48,048:INFO:              psutil: 5.9.0
2023-08-07 14:19:48,049:INFO:          markupsafe: 2.1.3
2023-08-07 14:19:48,049:INFO:             pickle5: Not installed
2023-08-07 14:19:48,049:INFO:         cloudpickle: 2.2.1
2023-08-07 14:19:48,049:INFO:         deprecation: 2.1.0
2023-08-07 14:19:48,049:INFO:              xxhash: 3.3.0
2023-08-07 14:19:48,050:INFO:           wurlitzer: Not installed
2023-08-07 14:19:48,050:INFO:PyCaret optional dependencies:
2023-08-07 14:19:48,067:INFO:                shap: Not installed
2023-08-07 14:19:48,067:INFO:           interpret: Not installed
2023-08-07 14:19:48,067:INFO:                umap: Not installed
2023-08-07 14:19:48,067:INFO:    pandas_profiling: Not installed
2023-08-07 14:19:48,067:INFO:  explainerdashboard: Not installed
2023-08-07 14:19:48,067:INFO:             autoviz: Not installed
2023-08-07 14:19:48,067:INFO:           fairlearn: Not installed
2023-08-07 14:19:48,067:INFO:          deepchecks: Not installed
2023-08-07 14:19:48,067:INFO:             xgboost: Not installed
2023-08-07 14:19:48,067:INFO:            catboost: Not installed
2023-08-07 14:19:48,067:INFO:              kmodes: Not installed
2023-08-07 14:19:48,067:INFO:             mlxtend: Not installed
2023-08-07 14:19:48,067:INFO:       statsforecast: Not installed
2023-08-07 14:19:48,067:INFO:        tune_sklearn: Not installed
2023-08-07 14:19:48,067:INFO:                 ray: Not installed
2023-08-07 14:19:48,067:INFO:            hyperopt: Not installed
2023-08-07 14:19:48,067:INFO:              optuna: Not installed
2023-08-07 14:19:48,067:INFO:               skopt: Not installed
2023-08-07 14:19:48,068:INFO:              mlflow: Not installed
2023-08-07 14:19:48,068:INFO:              gradio: Not installed
2023-08-07 14:19:48,068:INFO:             fastapi: Not installed
2023-08-07 14:19:48,068:INFO:             uvicorn: Not installed
2023-08-07 14:19:48,068:INFO:              m2cgen: Not installed
2023-08-07 14:19:48,068:INFO:           evidently: Not installed
2023-08-07 14:19:48,068:INFO:               fugue: Not installed
2023-08-07 14:19:48,068:INFO:           streamlit: Not installed
2023-08-07 14:19:48,068:INFO:             prophet: Not installed
2023-08-07 14:19:48,068:INFO:None
2023-08-07 14:19:48,068:INFO:Set up data.
2023-08-07 14:19:48,075:INFO:Set up train/test split.
2023-08-07 14:19:48,080:INFO:Set up index.
2023-08-07 14:19:48,080:INFO:Set up folding strategy.
2023-08-07 14:19:48,080:INFO:Assigning column types.
2023-08-07 14:19:48,085:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-07 14:19:48,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-07 14:19:48,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 14:19:48,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,238:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-07 14:19:48,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 14:19:48,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,271:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-07 14:19:48,330:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 14:19:48,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,418:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 14:19:48,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,451:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-07 14:19:48,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:48,636:INFO:Preparing preprocessing pipeline...
2023-08-07 14:19:48,637:INFO:Set up simple imputation.
2023-08-07 14:19:48,640:INFO:Set up encoding of ordinal features.
2023-08-07 14:19:48,643:INFO:Set up encoding of categorical features.
2023-08-07 14:19:48,721:INFO:Finished creating preprocessing pipeline.
2023-08-07 14:19:48,772:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lucazav\AppData\Local\Temp\5\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('c...
                                                                        {'col': 'Sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-07 14:19:48,772:INFO:Creating final display dataframe.
2023-08-07 14:19:48,990:INFO:Setup _display_container:                     Description             Value
0                    Session id              5614
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (844, 8)
4        Transformed data shape         (844, 10)
5   Transformed train set shape         (590, 10)
6    Transformed test set shape         (254, 10)
7              Ordinal features                 2
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                 1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              1e9d
2023-08-07 14:19:49,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:49,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:49,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:49,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 14:19:49,172:INFO:setup() successfully completed in 1.17s...............
2023-08-07 14:20:01,648:INFO:Initializing compare_models()
2023-08-07 14:20:01,649:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-07 14:20:01,649:INFO:Checking exceptions
2023-08-07 14:20:01,654:INFO:Preparing display monitor
2023-08-07 14:20:01,684:INFO:Initializing Logistic Regression
2023-08-07 14:20:01,684:INFO:Total runtime is 0.0 minutes
2023-08-07 14:20:01,688:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:01,689:INFO:Initializing create_model()
2023-08-07 14:20:01,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:01,689:INFO:Checking exceptions
2023-08-07 14:20:01,690:INFO:Importing libraries
2023-08-07 14:20:01,690:INFO:Copying training dataset
2023-08-07 14:20:01,694:INFO:Defining folds
2023-08-07 14:20:01,694:INFO:Declaring metric variables
2023-08-07 14:20:01,698:INFO:Importing untrained model
2023-08-07 14:20:01,702:INFO:Logistic Regression Imported successfully
2023-08-07 14:20:01,710:INFO:Starting cross validation
2023-08-07 14:20:01,712:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:04,130:INFO:Calculating mean and std
2023-08-07 14:20:04,131:INFO:Creating metrics dataframe
2023-08-07 14:20:04,136:INFO:Uploading results into container
2023-08-07 14:20:04,137:INFO:Uploading model into container now
2023-08-07 14:20:04,137:INFO:_master_model_container: 1
2023-08-07 14:20:04,138:INFO:_display_container: 2
2023-08-07 14:20:04,138:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5614, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-07 14:20:04,138:INFO:create_model() successfully completed......................................
2023-08-07 14:20:04,299:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:04,299:INFO:Creating metrics dataframe
2023-08-07 14:20:04,310:INFO:Initializing K Neighbors Classifier
2023-08-07 14:20:04,310:INFO:Total runtime is 0.04376708269119263 minutes
2023-08-07 14:20:04,314:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:04,315:INFO:Initializing create_model()
2023-08-07 14:20:04,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:04,315:INFO:Checking exceptions
2023-08-07 14:20:04,315:INFO:Importing libraries
2023-08-07 14:20:04,315:INFO:Copying training dataset
2023-08-07 14:20:04,319:INFO:Defining folds
2023-08-07 14:20:04,320:INFO:Declaring metric variables
2023-08-07 14:20:04,324:INFO:Importing untrained model
2023-08-07 14:20:04,328:INFO:K Neighbors Classifier Imported successfully
2023-08-07 14:20:04,336:INFO:Starting cross validation
2023-08-07 14:20:04,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:06,284:INFO:Calculating mean and std
2023-08-07 14:20:06,285:INFO:Creating metrics dataframe
2023-08-07 14:20:06,290:INFO:Uploading results into container
2023-08-07 14:20:06,291:INFO:Uploading model into container now
2023-08-07 14:20:06,292:INFO:_master_model_container: 2
2023-08-07 14:20:06,292:INFO:_display_container: 2
2023-08-07 14:20:06,292:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-07 14:20:06,292:INFO:create_model() successfully completed......................................
2023-08-07 14:20:06,452:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:06,452:INFO:Creating metrics dataframe
2023-08-07 14:20:06,465:INFO:Initializing Naive Bayes
2023-08-07 14:20:06,465:INFO:Total runtime is 0.07968413829803467 minutes
2023-08-07 14:20:06,470:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:06,470:INFO:Initializing create_model()
2023-08-07 14:20:06,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:06,470:INFO:Checking exceptions
2023-08-07 14:20:06,471:INFO:Importing libraries
2023-08-07 14:20:06,471:INFO:Copying training dataset
2023-08-07 14:20:06,475:INFO:Defining folds
2023-08-07 14:20:06,476:INFO:Declaring metric variables
2023-08-07 14:20:06,480:INFO:Importing untrained model
2023-08-07 14:20:06,484:INFO:Naive Bayes Imported successfully
2023-08-07 14:20:06,491:INFO:Starting cross validation
2023-08-07 14:20:06,494:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:08,372:INFO:Calculating mean and std
2023-08-07 14:20:08,373:INFO:Creating metrics dataframe
2023-08-07 14:20:08,378:INFO:Uploading results into container
2023-08-07 14:20:08,379:INFO:Uploading model into container now
2023-08-07 14:20:08,379:INFO:_master_model_container: 3
2023-08-07 14:20:08,379:INFO:_display_container: 2
2023-08-07 14:20:08,380:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-07 14:20:08,380:INFO:create_model() successfully completed......................................
2023-08-07 14:20:08,541:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:08,541:INFO:Creating metrics dataframe
2023-08-07 14:20:08,553:INFO:Initializing Decision Tree Classifier
2023-08-07 14:20:08,553:INFO:Total runtime is 0.11448442935943604 minutes
2023-08-07 14:20:08,559:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:08,559:INFO:Initializing create_model()
2023-08-07 14:20:08,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:08,560:INFO:Checking exceptions
2023-08-07 14:20:08,560:INFO:Importing libraries
2023-08-07 14:20:08,560:INFO:Copying training dataset
2023-08-07 14:20:08,565:INFO:Defining folds
2023-08-07 14:20:08,565:INFO:Declaring metric variables
2023-08-07 14:20:08,569:INFO:Importing untrained model
2023-08-07 14:20:08,574:INFO:Decision Tree Classifier Imported successfully
2023-08-07 14:20:08,581:INFO:Starting cross validation
2023-08-07 14:20:08,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:10,475:INFO:Calculating mean and std
2023-08-07 14:20:10,476:INFO:Creating metrics dataframe
2023-08-07 14:20:10,482:INFO:Uploading results into container
2023-08-07 14:20:10,483:INFO:Uploading model into container now
2023-08-07 14:20:10,483:INFO:_master_model_container: 4
2023-08-07 14:20:10,484:INFO:_display_container: 2
2023-08-07 14:20:10,484:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5614, splitter='best')
2023-08-07 14:20:10,484:INFO:create_model() successfully completed......................................
2023-08-07 14:20:10,664:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:10,664:INFO:Creating metrics dataframe
2023-08-07 14:20:10,676:INFO:Initializing SVM - Linear Kernel
2023-08-07 14:20:10,677:INFO:Total runtime is 0.1498848040898641 minutes
2023-08-07 14:20:10,682:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:10,683:INFO:Initializing create_model()
2023-08-07 14:20:10,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:10,683:INFO:Checking exceptions
2023-08-07 14:20:10,683:INFO:Importing libraries
2023-08-07 14:20:10,683:INFO:Copying training dataset
2023-08-07 14:20:10,688:INFO:Defining folds
2023-08-07 14:20:10,688:INFO:Declaring metric variables
2023-08-07 14:20:10,693:INFO:Importing untrained model
2023-08-07 14:20:10,697:INFO:SVM - Linear Kernel Imported successfully
2023-08-07 14:20:10,705:INFO:Starting cross validation
2023-08-07 14:20:10,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:10,852:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 14:20:10,998:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 14:20:11,152:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 14:20:11,157:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:11,298:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 14:20:11,439:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 14:20:11,579:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 14:20:11,733:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 14:20:11,881:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 14:20:12,025:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 14:20:12,173:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 14:20:12,182:INFO:Calculating mean and std
2023-08-07 14:20:12,184:INFO:Creating metrics dataframe
2023-08-07 14:20:12,192:INFO:Uploading results into container
2023-08-07 14:20:12,193:INFO:Uploading model into container now
2023-08-07 14:20:12,194:INFO:_master_model_container: 5
2023-08-07 14:20:12,194:INFO:_display_container: 2
2023-08-07 14:20:12,194:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=5614, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-07 14:20:12,194:INFO:create_model() successfully completed......................................
2023-08-07 14:20:12,367:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:12,368:INFO:Creating metrics dataframe
2023-08-07 14:20:12,381:INFO:Initializing Ridge Classifier
2023-08-07 14:20:12,382:INFO:Total runtime is 0.1783017635345459 minutes
2023-08-07 14:20:12,386:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:12,386:INFO:Initializing create_model()
2023-08-07 14:20:12,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:12,387:INFO:Checking exceptions
2023-08-07 14:20:12,387:INFO:Importing libraries
2023-08-07 14:20:12,387:INFO:Copying training dataset
2023-08-07 14:20:12,392:INFO:Defining folds
2023-08-07 14:20:12,392:INFO:Declaring metric variables
2023-08-07 14:20:12,396:INFO:Importing untrained model
2023-08-07 14:20:12,402:INFO:Ridge Classifier Imported successfully
2023-08-07 14:20:12,410:INFO:Starting cross validation
2023-08-07 14:20:12,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:12,552:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 14:20:12,700:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 14:20:12,848:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 14:20:12,987:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 14:20:13,123:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 14:20:13,260:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 14:20:13,400:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 14:20:13,543:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 14:20:13,682:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 14:20:13,822:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 14:20:13,831:INFO:Calculating mean and std
2023-08-07 14:20:13,832:INFO:Creating metrics dataframe
2023-08-07 14:20:13,838:INFO:Uploading results into container
2023-08-07 14:20:13,839:INFO:Uploading model into container now
2023-08-07 14:20:13,840:INFO:_master_model_container: 6
2023-08-07 14:20:13,840:INFO:_display_container: 2
2023-08-07 14:20:13,840:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5614, solver='auto',
                tol=0.0001)
2023-08-07 14:20:13,840:INFO:create_model() successfully completed......................................
2023-08-07 14:20:14,006:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:14,007:INFO:Creating metrics dataframe
2023-08-07 14:20:14,020:INFO:Initializing Random Forest Classifier
2023-08-07 14:20:14,020:INFO:Total runtime is 0.20560206969579062 minutes
2023-08-07 14:20:14,025:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:14,026:INFO:Initializing create_model()
2023-08-07 14:20:14,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:14,026:INFO:Checking exceptions
2023-08-07 14:20:14,026:INFO:Importing libraries
2023-08-07 14:20:14,026:INFO:Copying training dataset
2023-08-07 14:20:14,031:INFO:Defining folds
2023-08-07 14:20:14,032:INFO:Declaring metric variables
2023-08-07 14:20:14,036:INFO:Importing untrained model
2023-08-07 14:20:14,044:INFO:Random Forest Classifier Imported successfully
2023-08-07 14:20:14,051:INFO:Starting cross validation
2023-08-07 14:20:14,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:20,362:INFO:Calculating mean and std
2023-08-07 14:20:20,363:INFO:Creating metrics dataframe
2023-08-07 14:20:20,372:INFO:Uploading results into container
2023-08-07 14:20:20,373:INFO:Uploading model into container now
2023-08-07 14:20:20,373:INFO:_master_model_container: 7
2023-08-07 14:20:20,373:INFO:_display_container: 2
2023-08-07 14:20:20,374:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=1, oob_score=False,
                       random_state=5614, verbose=0, warm_start=False)
2023-08-07 14:20:20,374:INFO:create_model() successfully completed......................................
2023-08-07 14:20:20,530:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:20,530:INFO:Creating metrics dataframe
2023-08-07 14:20:20,544:INFO:Initializing Quadratic Discriminant Analysis
2023-08-07 14:20:20,544:INFO:Total runtime is 0.3143363992373149 minutes
2023-08-07 14:20:20,548:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:20,548:INFO:Initializing create_model()
2023-08-07 14:20:20,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:20,549:INFO:Checking exceptions
2023-08-07 14:20:20,549:INFO:Importing libraries
2023-08-07 14:20:20,549:INFO:Copying training dataset
2023-08-07 14:20:20,554:INFO:Defining folds
2023-08-07 14:20:20,554:INFO:Declaring metric variables
2023-08-07 14:20:20,559:INFO:Importing untrained model
2023-08-07 14:20:20,563:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-07 14:20:20,571:INFO:Starting cross validation
2023-08-07 14:20:20,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:20,659:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 14:20:20,866:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 14:20:21,058:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 14:20:21,249:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 14:20:21,447:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 14:20:21,646:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 14:20:21,835:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 14:20:22,032:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 14:20:22,228:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 14:20:22,420:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 14:20:22,530:INFO:Calculating mean and std
2023-08-07 14:20:22,531:INFO:Creating metrics dataframe
2023-08-07 14:20:22,540:INFO:Uploading results into container
2023-08-07 14:20:22,541:INFO:Uploading model into container now
2023-08-07 14:20:22,541:INFO:_master_model_container: 8
2023-08-07 14:20:22,541:INFO:_display_container: 2
2023-08-07 14:20:22,542:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-07 14:20:22,542:INFO:create_model() successfully completed......................................
2023-08-07 14:20:22,700:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:22,700:INFO:Creating metrics dataframe
2023-08-07 14:20:22,714:INFO:Initializing Ada Boost Classifier
2023-08-07 14:20:22,714:INFO:Total runtime is 0.350504728158315 minutes
2023-08-07 14:20:22,719:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:22,719:INFO:Initializing create_model()
2023-08-07 14:20:22,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:22,719:INFO:Checking exceptions
2023-08-07 14:20:22,720:INFO:Importing libraries
2023-08-07 14:20:22,720:INFO:Copying training dataset
2023-08-07 14:20:22,726:INFO:Defining folds
2023-08-07 14:20:22,727:INFO:Declaring metric variables
2023-08-07 14:20:22,731:INFO:Importing untrained model
2023-08-07 14:20:22,736:INFO:Ada Boost Classifier Imported successfully
2023-08-07 14:20:22,743:INFO:Starting cross validation
2023-08-07 14:20:22,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:26,388:INFO:Calculating mean and std
2023-08-07 14:20:26,390:INFO:Creating metrics dataframe
2023-08-07 14:20:26,400:INFO:Uploading results into container
2023-08-07 14:20:26,401:INFO:Uploading model into container now
2023-08-07 14:20:26,401:INFO:_master_model_container: 9
2023-08-07 14:20:26,402:INFO:_display_container: 2
2023-08-07 14:20:26,402:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5614)
2023-08-07 14:20:26,402:INFO:create_model() successfully completed......................................
2023-08-07 14:20:26,571:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:26,571:INFO:Creating metrics dataframe
2023-08-07 14:20:26,585:INFO:Initializing Gradient Boosting Classifier
2023-08-07 14:20:26,586:INFO:Total runtime is 0.415038537979126 minutes
2023-08-07 14:20:26,591:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:26,592:INFO:Initializing create_model()
2023-08-07 14:20:26,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:26,592:INFO:Checking exceptions
2023-08-07 14:20:26,592:INFO:Importing libraries
2023-08-07 14:20:26,592:INFO:Copying training dataset
2023-08-07 14:20:26,597:INFO:Defining folds
2023-08-07 14:20:26,598:INFO:Declaring metric variables
2023-08-07 14:20:26,602:INFO:Importing untrained model
2023-08-07 14:20:26,606:INFO:Gradient Boosting Classifier Imported successfully
2023-08-07 14:20:26,614:INFO:Starting cross validation
2023-08-07 14:20:26,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:31,328:INFO:Calculating mean and std
2023-08-07 14:20:31,330:INFO:Creating metrics dataframe
2023-08-07 14:20:31,344:INFO:Uploading results into container
2023-08-07 14:20:31,345:INFO:Uploading model into container now
2023-08-07 14:20:31,345:INFO:_master_model_container: 10
2023-08-07 14:20:31,345:INFO:_display_container: 2
2023-08-07 14:20:31,346:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 14:20:31,346:INFO:create_model() successfully completed......................................
2023-08-07 14:20:31,512:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:31,512:INFO:Creating metrics dataframe
2023-08-07 14:20:31,530:INFO:Initializing Linear Discriminant Analysis
2023-08-07 14:20:31,530:INFO:Total runtime is 0.4974391500155131 minutes
2023-08-07 14:20:31,534:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:31,535:INFO:Initializing create_model()
2023-08-07 14:20:31,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:31,535:INFO:Checking exceptions
2023-08-07 14:20:31,536:INFO:Importing libraries
2023-08-07 14:20:31,536:INFO:Copying training dataset
2023-08-07 14:20:31,540:INFO:Defining folds
2023-08-07 14:20:31,541:INFO:Declaring metric variables
2023-08-07 14:20:31,545:INFO:Importing untrained model
2023-08-07 14:20:31,549:INFO:Linear Discriminant Analysis Imported successfully
2023-08-07 14:20:31,557:INFO:Starting cross validation
2023-08-07 14:20:31,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:33,512:INFO:Calculating mean and std
2023-08-07 14:20:33,513:INFO:Creating metrics dataframe
2023-08-07 14:20:33,530:INFO:Uploading results into container
2023-08-07 14:20:33,532:INFO:Uploading model into container now
2023-08-07 14:20:33,533:INFO:_master_model_container: 11
2023-08-07 14:20:33,533:INFO:_display_container: 2
2023-08-07 14:20:33,533:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-07 14:20:33,533:INFO:create_model() successfully completed......................................
2023-08-07 14:20:33,694:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:33,695:INFO:Creating metrics dataframe
2023-08-07 14:20:33,709:INFO:Initializing Extra Trees Classifier
2023-08-07 14:20:33,710:INFO:Total runtime is 0.5337728341420491 minutes
2023-08-07 14:20:33,714:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:33,715:INFO:Initializing create_model()
2023-08-07 14:20:33,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:33,715:INFO:Checking exceptions
2023-08-07 14:20:33,715:INFO:Importing libraries
2023-08-07 14:20:33,715:INFO:Copying training dataset
2023-08-07 14:20:33,720:INFO:Defining folds
2023-08-07 14:20:33,720:INFO:Declaring metric variables
2023-08-07 14:20:33,724:INFO:Importing untrained model
2023-08-07 14:20:33,728:INFO:Extra Trees Classifier Imported successfully
2023-08-07 14:20:33,735:INFO:Starting cross validation
2023-08-07 14:20:33,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:39,730:INFO:Calculating mean and std
2023-08-07 14:20:39,731:INFO:Creating metrics dataframe
2023-08-07 14:20:39,748:INFO:Uploading results into container
2023-08-07 14:20:39,749:INFO:Uploading model into container now
2023-08-07 14:20:39,749:INFO:_master_model_container: 12
2023-08-07 14:20:39,749:INFO:_display_container: 2
2023-08-07 14:20:39,750:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=1, oob_score=False,
                     random_state=5614, verbose=0, warm_start=False)
2023-08-07 14:20:39,750:INFO:create_model() successfully completed......................................
2023-08-07 14:20:39,899:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:39,900:INFO:Creating metrics dataframe
2023-08-07 14:20:39,916:INFO:Initializing Light Gradient Boosting Machine
2023-08-07 14:20:39,916:INFO:Total runtime is 0.6372007052103679 minutes
2023-08-07 14:20:39,920:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:39,921:INFO:Initializing create_model()
2023-08-07 14:20:39,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:39,921:INFO:Checking exceptions
2023-08-07 14:20:39,921:INFO:Importing libraries
2023-08-07 14:20:39,921:INFO:Copying training dataset
2023-08-07 14:20:39,929:INFO:Defining folds
2023-08-07 14:20:39,929:INFO:Declaring metric variables
2023-08-07 14:20:39,934:INFO:Importing untrained model
2023-08-07 14:20:39,938:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-07 14:20:39,946:INFO:Starting cross validation
2023-08-07 14:20:39,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:40,043:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 14:20:40,043:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000169 seconds.
2023-08-07 14:20:40,043:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 14:20:40,044:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 14:20:40,044:INFO:[LightGBM] [Info] Total Bins 194
2023-08-07 14:20:40,044:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 14:20:40,044:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 14:20:40,044:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 14:20:40,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,356:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 14:20:40,356:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.
2023-08-07 14:20:40,356:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 14:20:40,356:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 14:20:40,357:INFO:[LightGBM] [Info] Total Bins 188
2023-08-07 14:20:40,357:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 14:20:40,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 14:20:40,357:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 14:20:40,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,614:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 14:20:40,615:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.
2023-08-07 14:20:40,615:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 14:20:40,615:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 14:20:40,615:INFO:[LightGBM] [Info] Total Bins 192
2023-08-07 14:20:40,615:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 14:20:40,615:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 14:20:40,615:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 14:20:40,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,872:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 14:20:40,873:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.
2023-08-07 14:20:40,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 14:20:40,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 14:20:40,873:INFO:[LightGBM] [Info] Total Bins 193
2023-08-07 14:20:40,873:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 14:20:40,873:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 14:20:40,874:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 14:20:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,131:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 14:20:41,131:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.
2023-08-07 14:20:41,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 14:20:41,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 14:20:41,131:INFO:[LightGBM] [Info] Total Bins 188
2023-08-07 14:20:41,131:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 14:20:41,131:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 14:20:41,131:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 14:20:41,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,391:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 14:20:41,391:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.
2023-08-07 14:20:41,391:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 14:20:41,391:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 14:20:41,391:INFO:[LightGBM] [Info] Total Bins 189
2023-08-07 14:20:41,391:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 14:20:41,391:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 14:20:41,391:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 14:20:41,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,652:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 14:20:41,652:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.
2023-08-07 14:20:41,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 14:20:41,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 14:20:41,652:INFO:[LightGBM] [Info] Total Bins 188
2023-08-07 14:20:41,653:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 14:20:41,653:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 14:20:41,653:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 14:20:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,909:INFO:[LightGBM] [Info] Number of positive: 200, number of negative: 331
2023-08-07 14:20:41,909:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.
2023-08-07 14:20:41,910:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 14:20:41,910:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 14:20:41,910:INFO:[LightGBM] [Info] Total Bins 191
2023-08-07 14:20:41,910:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 14:20:41,910:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376648 -> initscore=-0.503801
2023-08-07 14:20:41,910:INFO:[LightGBM] [Info] Start training from score -0.503801
2023-08-07 14:20:41,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:41,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,181:INFO:[LightGBM] [Info] Number of positive: 200, number of negative: 331
2023-08-07 14:20:42,182:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.
2023-08-07 14:20:42,182:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 14:20:42,182:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 14:20:42,182:INFO:[LightGBM] [Info] Total Bins 192
2023-08-07 14:20:42,182:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 14:20:42,182:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376648 -> initscore=-0.503801
2023-08-07 14:20:42,182:INFO:[LightGBM] [Info] Start training from score -0.503801
2023-08-07 14:20:42,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,438:INFO:[LightGBM] [Info] Number of positive: 200, number of negative: 331
2023-08-07 14:20:42,439:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.
2023-08-07 14:20:42,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 14:20:42,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 14:20:42,439:INFO:[LightGBM] [Info] Total Bins 189
2023-08-07 14:20:42,439:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 14:20:42,439:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376648 -> initscore=-0.503801
2023-08-07 14:20:42,439:INFO:[LightGBM] [Info] Start training from score -0.503801
2023-08-07 14:20:42,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 14:20:42,618:INFO:Calculating mean and std
2023-08-07 14:20:42,619:INFO:Creating metrics dataframe
2023-08-07 14:20:42,635:INFO:Uploading results into container
2023-08-07 14:20:42,635:INFO:Uploading model into container now
2023-08-07 14:20:42,635:INFO:_master_model_container: 13
2023-08-07 14:20:42,635:INFO:_display_container: 2
2023-08-07 14:20:42,638:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=5614, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-07 14:20:42,638:INFO:create_model() successfully completed......................................
2023-08-07 14:20:42,807:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:42,807:INFO:Creating metrics dataframe
2023-08-07 14:20:42,824:INFO:Initializing Dummy Classifier
2023-08-07 14:20:42,824:INFO:Total runtime is 0.6856677889823913 minutes
2023-08-07 14:20:42,828:INFO:SubProcess create_model() called ==================================
2023-08-07 14:20:42,829:INFO:Initializing create_model()
2023-08-07 14:20:42,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C55630D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:42,829:INFO:Checking exceptions
2023-08-07 14:20:42,829:INFO:Importing libraries
2023-08-07 14:20:42,829:INFO:Copying training dataset
2023-08-07 14:20:42,834:INFO:Defining folds
2023-08-07 14:20:42,834:INFO:Declaring metric variables
2023-08-07 14:20:42,839:INFO:Importing untrained model
2023-08-07 14:20:42,843:INFO:Dummy Classifier Imported successfully
2023-08-07 14:20:42,851:INFO:Starting cross validation
2023-08-07 14:20:42,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 14:20:43,042:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:43,245:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:43,432:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:43,624:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:43,816:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:44,018:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:44,217:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:44,415:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:44,614:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:44,806:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 14:20:44,822:INFO:Calculating mean and std
2023-08-07 14:20:44,824:INFO:Creating metrics dataframe
2023-08-07 14:20:44,841:INFO:Uploading results into container
2023-08-07 14:20:44,841:INFO:Uploading model into container now
2023-08-07 14:20:44,842:INFO:_master_model_container: 14
2023-08-07 14:20:44,842:INFO:_display_container: 2
2023-08-07 14:20:44,842:INFO:DummyClassifier(constant=None, random_state=5614, strategy='prior')
2023-08-07 14:20:44,842:INFO:create_model() successfully completed......................................
2023-08-07 14:20:45,006:INFO:SubProcess create_model() end ==================================
2023-08-07 14:20:45,007:INFO:Creating metrics dataframe
2023-08-07 14:20:45,034:INFO:Initializing create_model()
2023-08-07 14:20:45,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-07 14:20:45,035:INFO:Checking exceptions
2023-08-07 14:20:45,037:INFO:Importing libraries
2023-08-07 14:20:45,037:INFO:Copying training dataset
2023-08-07 14:20:45,041:INFO:Defining folds
2023-08-07 14:20:45,041:INFO:Declaring metric variables
2023-08-07 14:20:45,041:INFO:Importing untrained model
2023-08-07 14:20:45,041:INFO:Declaring custom model
2023-08-07 14:20:45,042:INFO:Gradient Boosting Classifier Imported successfully
2023-08-07 14:20:45,043:INFO:Cross validation set to False
2023-08-07 14:20:45,043:INFO:Fitting Model
2023-08-07 14:20:45,336:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 14:20:45,336:INFO:create_model() successfully completed......................................
2023-08-07 14:20:45,546:INFO:_master_model_container: 14
2023-08-07 14:20:45,546:INFO:_display_container: 2
2023-08-07 14:20:45,547:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 14:20:45,547:INFO:compare_models() successfully completed......................................
2023-08-07 14:30:13,395:INFO:Initializing save_model()
2023-08-07 14:30:13,395:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=C:\Users\lucazav\OneDrive\MVP\PacktBook\Code\Extending-Power-BI-with-Python-and-R-2nd-edition\Ch17 - Using Machine Learning Without Premium or Embedded Capacity\Python\titanic-model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lucazav\AppData\Local\Temp\5\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('c...
                                                                        {'col': 'Sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-08-07 14:30:13,396:INFO:Adding model into prep_pipe
2023-08-07 14:30:13,412:INFO:C:\Users\lucazav\OneDrive\MVP\PacktBook\Code\Extending-Power-BI-with-Python-and-R-2nd-edition\Ch17 - Using Machine Learning Without Premium or Embedded Capacity\Python\titanic-model.pkl saved in current working directory
2023-08-07 14:30:13,467:INFO:Pipeline(memory=FastMemory(location=C:\Users\lucazav\AppData\Local\Temp\5\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('c...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=5614, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-08-07 14:30:13,469:INFO:save_model() successfully completed......................................
2023-08-07 14:31:03,144:INFO:Initializing predict_model()
2023-08-07 14:31:03,145:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C533D370>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000230C5EE04C0>)
2023-08-07 14:31:03,145:INFO:Checking exceptions
2023-08-07 14:31:03,145:INFO:Preloading libraries
2023-08-07 14:31:03,145:INFO:Set up data.
2023-08-07 14:31:03,153:INFO:Set up index.
2023-08-07 15:16:08,520:INFO:PyCaret ClassificationExperiment
2023-08-07 15:16:08,520:INFO:Logging name: clf-default-name
2023-08-07 15:16:08,520:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-07 15:16:08,520:INFO:version 3.0.4
2023-08-07 15:16:08,520:INFO:Initializing setup()
2023-08-07 15:16:08,520:INFO:self.USI: eb5a
2023-08-07 15:16:08,520:INFO:self._variable_keys: {'idx', 'memory', 'fold_generator', 'log_plots_param', 'X_test', 'html_param', 'X', 'target_param', 'data', '_available_plots', 'fix_imbalance', 'gpu_param', 'X_train', 'exp_id', 'gpu_n_jobs_param', 'pipeline', 'y_test', 'n_jobs_param', 'y', 'exp_name_log', 'fold_groups_param', 'USI', 'y_train', 'fold_shuffle_param', '_ml_usecase', 'seed', 'logging_param', 'is_multiclass'}
2023-08-07 15:16:08,521:INFO:Checking environment
2023-08-07 15:16:08,521:INFO:python_version: 3.9.17
2023-08-07 15:16:08,521:INFO:python_build: ('main', 'Jul  5 2023 20:47:11')
2023-08-07 15:16:08,521:INFO:machine: AMD64
2023-08-07 15:16:08,521:INFO:platform: Windows-10-10.0.20348-SP0
2023-08-07 15:16:08,521:INFO:Memory: svmem(total=34358562816, available=23843528704, percent=30.6, used=10515034112, free=23843528704)
2023-08-07 15:16:08,521:INFO:Physical Core: 8
2023-08-07 15:16:08,521:INFO:Logical Core: 8
2023-08-07 15:16:08,521:INFO:Checking libraries
2023-08-07 15:16:08,521:INFO:System:
2023-08-07 15:16:08,521:INFO:    python: 3.9.17 (main, Jul  5 2023, 20:47:11) [MSC v.1916 64 bit (AMD64)]
2023-08-07 15:16:08,521:INFO:executable: c:\ProgramData\Miniconda3\envs\pycaret_env\python.exe
2023-08-07 15:16:08,521:INFO:   machine: Windows-10-10.0.20348-SP0
2023-08-07 15:16:08,521:INFO:PyCaret required dependencies:
2023-08-07 15:16:08,522:INFO:                 pip: 23.2.1
2023-08-07 15:16:08,522:INFO:          setuptools: 68.0.0
2023-08-07 15:16:08,522:INFO:             pycaret: 3.0.4
2023-08-07 15:16:08,522:INFO:             IPython: 8.12.0
2023-08-07 15:16:08,522:INFO:          ipywidgets: 8.1.0
2023-08-07 15:16:08,522:INFO:                tqdm: 4.65.0
2023-08-07 15:16:08,522:INFO:               numpy: 1.23.5
2023-08-07 15:16:08,522:INFO:              pandas: 1.5.3
2023-08-07 15:16:08,522:INFO:              jinja2: 3.1.2
2023-08-07 15:16:08,522:INFO:               scipy: 1.11.1
2023-08-07 15:16:08,522:INFO:              joblib: 1.3.1
2023-08-07 15:16:08,522:INFO:             sklearn: 1.2.2
2023-08-07 15:16:08,522:INFO:                pyod: 1.1.0
2023-08-07 15:16:08,522:INFO:            imblearn: 0.11.0
2023-08-07 15:16:08,522:INFO:   category_encoders: 2.6.1
2023-08-07 15:16:08,522:INFO:            lightgbm: 4.0.0
2023-08-07 15:16:08,522:INFO:               numba: 0.57.1
2023-08-07 15:16:08,522:INFO:            requests: 2.31.0
2023-08-07 15:16:08,522:INFO:          matplotlib: 3.7.2
2023-08-07 15:16:08,522:INFO:          scikitplot: 0.3.7
2023-08-07 15:16:08,523:INFO:         yellowbrick: 1.5
2023-08-07 15:16:08,523:INFO:              plotly: 5.15.0
2023-08-07 15:16:08,523:INFO:    plotly-resampler: Not installed
2023-08-07 15:16:08,523:INFO:             kaleido: 0.2.1
2023-08-07 15:16:08,523:INFO:           schemdraw: 0.15
2023-08-07 15:16:08,523:INFO:         statsmodels: 0.14.0
2023-08-07 15:16:08,523:INFO:              sktime: 0.21.0
2023-08-07 15:16:08,523:INFO:               tbats: 1.1.3
2023-08-07 15:16:08,523:INFO:            pmdarima: 2.0.3
2023-08-07 15:16:08,523:INFO:              psutil: 5.9.0
2023-08-07 15:16:08,523:INFO:          markupsafe: 2.1.3
2023-08-07 15:16:08,523:INFO:             pickle5: Not installed
2023-08-07 15:16:08,523:INFO:         cloudpickle: 2.2.1
2023-08-07 15:16:08,523:INFO:         deprecation: 2.1.0
2023-08-07 15:16:08,523:INFO:              xxhash: 3.3.0
2023-08-07 15:16:08,523:INFO:           wurlitzer: Not installed
2023-08-07 15:16:08,523:INFO:PyCaret optional dependencies:
2023-08-07 15:16:08,523:INFO:                shap: Not installed
2023-08-07 15:16:08,523:INFO:           interpret: Not installed
2023-08-07 15:16:08,523:INFO:                umap: Not installed
2023-08-07 15:16:08,524:INFO:    pandas_profiling: Not installed
2023-08-07 15:16:08,524:INFO:  explainerdashboard: Not installed
2023-08-07 15:16:08,524:INFO:             autoviz: Not installed
2023-08-07 15:16:08,524:INFO:           fairlearn: Not installed
2023-08-07 15:16:08,524:INFO:          deepchecks: Not installed
2023-08-07 15:16:08,524:INFO:             xgboost: Not installed
2023-08-07 15:16:08,524:INFO:            catboost: Not installed
2023-08-07 15:16:08,524:INFO:              kmodes: Not installed
2023-08-07 15:16:08,524:INFO:             mlxtend: Not installed
2023-08-07 15:16:08,524:INFO:       statsforecast: Not installed
2023-08-07 15:16:08,524:INFO:        tune_sklearn: Not installed
2023-08-07 15:16:08,524:INFO:                 ray: Not installed
2023-08-07 15:16:08,524:INFO:            hyperopt: Not installed
2023-08-07 15:16:08,524:INFO:              optuna: Not installed
2023-08-07 15:16:08,524:INFO:               skopt: Not installed
2023-08-07 15:16:08,524:INFO:              mlflow: Not installed
2023-08-07 15:16:08,524:INFO:              gradio: Not installed
2023-08-07 15:16:08,524:INFO:             fastapi: Not installed
2023-08-07 15:16:08,524:INFO:             uvicorn: Not installed
2023-08-07 15:16:08,524:INFO:              m2cgen: Not installed
2023-08-07 15:16:08,524:INFO:           evidently: Not installed
2023-08-07 15:16:08,524:INFO:               fugue: Not installed
2023-08-07 15:16:08,525:INFO:           streamlit: Not installed
2023-08-07 15:16:08,525:INFO:             prophet: Not installed
2023-08-07 15:16:08,525:INFO:None
2023-08-07 15:16:08,525:INFO:Set up data.
2023-08-07 15:16:08,532:INFO:Set up train/test split.
2023-08-07 15:16:08,544:INFO:Set up index.
2023-08-07 15:16:08,545:INFO:Set up folding strategy.
2023-08-07 15:16:08,545:INFO:Assigning column types.
2023-08-07 15:16:08,550:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-07 15:16:08,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-07 15:16:08,612:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:16:08,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:08,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:08,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-07 15:16:08,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:16:08,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:08,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:08,738:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-07 15:16:08,798:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:16:08,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:08,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:08,892:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:16:08,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:08,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:08,927:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-07 15:16:09,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:09,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:09,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:09,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:09,109:INFO:Preparing preprocessing pipeline...
2023-08-07 15:16:09,111:INFO:Set up simple imputation.
2023-08-07 15:16:09,113:INFO:Set up encoding of ordinal features.
2023-08-07 15:16:09,116:INFO:Set up encoding of categorical features.
2023-08-07 15:16:09,186:INFO:Finished creating preprocessing pipeline.
2023-08-07 15:16:09,241:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lucazav\AppData\Local\Temp\5\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('c...
                                                                        {'col': 'Sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-07 15:16:09,241:INFO:Creating final display dataframe.
2023-08-07 15:16:09,459:INFO:Setup _display_container:                     Description             Value
0                    Session id              5614
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (844, 8)
4        Transformed data shape         (844, 10)
5   Transformed train set shape         (590, 10)
6    Transformed test set shape         (254, 10)
7              Ordinal features                 2
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                 1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              eb5a
2023-08-07 15:16:09,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:09,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:09,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:09,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:16:09,639:INFO:setup() successfully completed in 1.35s...............
2023-08-07 15:16:16,121:INFO:Initializing compare_models()
2023-08-07 15:16:16,122:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-07 15:16:16,122:INFO:Checking exceptions
2023-08-07 15:16:16,127:INFO:Preparing display monitor
2023-08-07 15:16:16,156:INFO:Initializing Logistic Regression
2023-08-07 15:16:16,157:INFO:Total runtime is 1.6717116038004556e-05 minutes
2023-08-07 15:16:16,160:INFO:SubProcess create_model() called ==================================
2023-08-07 15:16:16,161:INFO:Initializing create_model()
2023-08-07 15:16:16,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:16:16,162:INFO:Checking exceptions
2023-08-07 15:16:16,162:INFO:Importing libraries
2023-08-07 15:16:16,162:INFO:Copying training dataset
2023-08-07 15:16:16,166:INFO:Defining folds
2023-08-07 15:16:16,166:INFO:Declaring metric variables
2023-08-07 15:16:16,170:INFO:Importing untrained model
2023-08-07 15:16:16,174:INFO:Logistic Regression Imported successfully
2023-08-07 15:16:16,183:INFO:Starting cross validation
2023-08-07 15:16:16,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:16:20,880:INFO:Calculating mean and std
2023-08-07 15:16:20,882:INFO:Creating metrics dataframe
2023-08-07 15:16:21,112:INFO:Uploading results into container
2023-08-07 15:16:21,113:INFO:Uploading model into container now
2023-08-07 15:16:21,114:INFO:_master_model_container: 1
2023-08-07 15:16:21,114:INFO:_display_container: 2
2023-08-07 15:16:21,115:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5614, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-07 15:16:21,115:INFO:create_model() successfully completed......................................
2023-08-07 15:16:21,290:INFO:SubProcess create_model() end ==================================
2023-08-07 15:16:21,291:INFO:Creating metrics dataframe
2023-08-07 15:16:21,301:INFO:Initializing K Neighbors Classifier
2023-08-07 15:16:21,301:INFO:Total runtime is 0.08573396603266398 minutes
2023-08-07 15:16:21,306:INFO:SubProcess create_model() called ==================================
2023-08-07 15:16:21,306:INFO:Initializing create_model()
2023-08-07 15:16:21,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:16:21,307:INFO:Checking exceptions
2023-08-07 15:16:21,307:INFO:Importing libraries
2023-08-07 15:16:21,307:INFO:Copying training dataset
2023-08-07 15:16:21,313:INFO:Defining folds
2023-08-07 15:16:21,313:INFO:Declaring metric variables
2023-08-07 15:16:21,317:INFO:Importing untrained model
2023-08-07 15:16:21,322:INFO:K Neighbors Classifier Imported successfully
2023-08-07 15:16:21,330:INFO:Starting cross validation
2023-08-07 15:16:21,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:16:25,613:INFO:Calculating mean and std
2023-08-07 15:16:25,614:INFO:Creating metrics dataframe
2023-08-07 15:16:25,847:INFO:Uploading results into container
2023-08-07 15:16:25,849:INFO:Uploading model into container now
2023-08-07 15:16:25,849:INFO:_master_model_container: 2
2023-08-07 15:16:25,849:INFO:_display_container: 2
2023-08-07 15:16:25,849:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-07 15:16:25,849:INFO:create_model() successfully completed......................................
2023-08-07 15:16:26,028:INFO:SubProcess create_model() end ==================================
2023-08-07 15:16:26,028:INFO:Creating metrics dataframe
2023-08-07 15:16:26,042:INFO:Initializing Naive Bayes
2023-08-07 15:16:26,042:INFO:Total runtime is 0.16475133498509725 minutes
2023-08-07 15:16:26,046:INFO:SubProcess create_model() called ==================================
2023-08-07 15:16:26,047:INFO:Initializing create_model()
2023-08-07 15:16:26,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:16:26,047:INFO:Checking exceptions
2023-08-07 15:16:26,047:INFO:Importing libraries
2023-08-07 15:16:26,047:INFO:Copying training dataset
2023-08-07 15:16:26,051:INFO:Defining folds
2023-08-07 15:16:26,051:INFO:Declaring metric variables
2023-08-07 15:16:26,056:INFO:Importing untrained model
2023-08-07 15:16:26,060:INFO:Naive Bayes Imported successfully
2023-08-07 15:16:26,068:INFO:Starting cross validation
2023-08-07 15:16:26,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:16:30,303:INFO:Calculating mean and std
2023-08-07 15:16:30,305:INFO:Creating metrics dataframe
2023-08-07 15:16:30,533:INFO:Uploading results into container
2023-08-07 15:16:30,535:INFO:Uploading model into container now
2023-08-07 15:16:30,535:INFO:_master_model_container: 3
2023-08-07 15:16:30,535:INFO:_display_container: 2
2023-08-07 15:16:30,536:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-07 15:16:30,536:INFO:create_model() successfully completed......................................
2023-08-07 15:16:30,702:INFO:SubProcess create_model() end ==================================
2023-08-07 15:16:30,703:INFO:Creating metrics dataframe
2023-08-07 15:16:30,716:INFO:Initializing Decision Tree Classifier
2023-08-07 15:16:30,716:INFO:Total runtime is 0.24265215396881104 minutes
2023-08-07 15:16:30,720:INFO:SubProcess create_model() called ==================================
2023-08-07 15:16:30,721:INFO:Initializing create_model()
2023-08-07 15:16:30,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:16:30,721:INFO:Checking exceptions
2023-08-07 15:16:30,721:INFO:Importing libraries
2023-08-07 15:16:30,721:INFO:Copying training dataset
2023-08-07 15:16:30,726:INFO:Defining folds
2023-08-07 15:16:30,726:INFO:Declaring metric variables
2023-08-07 15:16:30,730:INFO:Importing untrained model
2023-08-07 15:16:30,734:INFO:Decision Tree Classifier Imported successfully
2023-08-07 15:16:30,743:INFO:Starting cross validation
2023-08-07 15:16:30,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:16:34,945:INFO:Calculating mean and std
2023-08-07 15:16:34,947:INFO:Creating metrics dataframe
2023-08-07 15:16:35,175:INFO:Uploading results into container
2023-08-07 15:16:35,177:INFO:Uploading model into container now
2023-08-07 15:16:35,177:INFO:_master_model_container: 4
2023-08-07 15:16:35,177:INFO:_display_container: 2
2023-08-07 15:16:35,178:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5614, splitter='best')
2023-08-07 15:16:35,178:INFO:create_model() successfully completed......................................
2023-08-07 15:16:35,345:INFO:SubProcess create_model() end ==================================
2023-08-07 15:16:35,345:INFO:Creating metrics dataframe
2023-08-07 15:16:35,358:INFO:Initializing SVM - Linear Kernel
2023-08-07 15:16:35,358:INFO:Total runtime is 0.32001954317092896 minutes
2023-08-07 15:16:35,362:INFO:SubProcess create_model() called ==================================
2023-08-07 15:16:35,363:INFO:Initializing create_model()
2023-08-07 15:16:35,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:16:35,363:INFO:Checking exceptions
2023-08-07 15:16:35,363:INFO:Importing libraries
2023-08-07 15:16:35,363:INFO:Copying training dataset
2023-08-07 15:16:35,369:INFO:Defining folds
2023-08-07 15:16:35,370:INFO:Declaring metric variables
2023-08-07 15:16:35,374:INFO:Importing untrained model
2023-08-07 15:16:35,378:INFO:SVM - Linear Kernel Imported successfully
2023-08-07 15:16:35,386:INFO:Starting cross validation
2023-08-07 15:16:35,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:16:35,527:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:16:35,901:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:16:36,275:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:16:36,279:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:16:36,649:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:16:37,023:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:16:37,388:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:16:37,763:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:16:38,132:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:16:38,503:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:16:38,871:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:16:39,101:INFO:Calculating mean and std
2023-08-07 15:16:39,103:INFO:Creating metrics dataframe
2023-08-07 15:16:39,329:INFO:Uploading results into container
2023-08-07 15:16:39,331:INFO:Uploading model into container now
2023-08-07 15:16:39,331:INFO:_master_model_container: 5
2023-08-07 15:16:39,332:INFO:_display_container: 2
2023-08-07 15:16:39,332:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=5614, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-07 15:16:39,332:INFO:create_model() successfully completed......................................
2023-08-07 15:16:39,505:INFO:SubProcess create_model() end ==================================
2023-08-07 15:16:39,505:INFO:Creating metrics dataframe
2023-08-07 15:16:39,518:INFO:Initializing Ridge Classifier
2023-08-07 15:16:39,518:INFO:Total runtime is 0.3893535335858663 minutes
2023-08-07 15:16:39,523:INFO:SubProcess create_model() called ==================================
2023-08-07 15:16:39,524:INFO:Initializing create_model()
2023-08-07 15:16:39,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:16:39,524:INFO:Checking exceptions
2023-08-07 15:16:39,524:INFO:Importing libraries
2023-08-07 15:16:39,524:INFO:Copying training dataset
2023-08-07 15:16:39,529:INFO:Defining folds
2023-08-07 15:16:39,530:INFO:Declaring metric variables
2023-08-07 15:16:39,534:INFO:Importing untrained model
2023-08-07 15:16:39,538:INFO:Ridge Classifier Imported successfully
2023-08-07 15:16:39,546:INFO:Starting cross validation
2023-08-07 15:16:39,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:16:39,692:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:16:40,075:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:16:40,447:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:16:40,845:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:16:41,219:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:16:41,593:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:16:41,976:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:16:42,357:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:16:42,731:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:16:43,110:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:16:43,346:INFO:Calculating mean and std
2023-08-07 15:16:43,348:INFO:Creating metrics dataframe
2023-08-07 15:16:43,576:INFO:Uploading results into container
2023-08-07 15:16:43,577:INFO:Uploading model into container now
2023-08-07 15:16:43,578:INFO:_master_model_container: 6
2023-08-07 15:16:43,578:INFO:_display_container: 2
2023-08-07 15:16:43,578:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5614, solver='auto',
                tol=0.0001)
2023-08-07 15:16:43,579:INFO:create_model() successfully completed......................................
2023-08-07 15:16:43,751:INFO:SubProcess create_model() end ==================================
2023-08-07 15:16:43,751:INFO:Creating metrics dataframe
2023-08-07 15:16:43,764:INFO:Initializing Random Forest Classifier
2023-08-07 15:16:43,764:INFO:Total runtime is 0.46012086073557534 minutes
2023-08-07 15:16:43,769:INFO:SubProcess create_model() called ==================================
2023-08-07 15:16:43,769:INFO:Initializing create_model()
2023-08-07 15:16:43,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:16:43,769:INFO:Checking exceptions
2023-08-07 15:16:43,769:INFO:Importing libraries
2023-08-07 15:16:43,769:INFO:Copying training dataset
2023-08-07 15:16:43,776:INFO:Defining folds
2023-08-07 15:16:43,776:INFO:Declaring metric variables
2023-08-07 15:16:43,782:INFO:Importing untrained model
2023-08-07 15:16:43,786:INFO:Random Forest Classifier Imported successfully
2023-08-07 15:16:43,798:INFO:Starting cross validation
2023-08-07 15:16:43,800:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:16:49,767:INFO:Calculating mean and std
2023-08-07 15:16:49,769:INFO:Creating metrics dataframe
2023-08-07 15:16:50,012:INFO:Uploading results into container
2023-08-07 15:16:50,013:INFO:Uploading model into container now
2023-08-07 15:16:50,014:INFO:_master_model_container: 7
2023-08-07 15:16:50,014:INFO:_display_container: 2
2023-08-07 15:16:50,015:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=1, oob_score=False,
                       random_state=5614, verbose=0, warm_start=False)
2023-08-07 15:16:50,015:INFO:create_model() successfully completed......................................
2023-08-07 15:16:50,182:INFO:SubProcess create_model() end ==================================
2023-08-07 15:16:50,183:INFO:Creating metrics dataframe
2023-08-07 15:16:50,196:INFO:Initializing Quadratic Discriminant Analysis
2023-08-07 15:16:50,196:INFO:Total runtime is 0.5673218607902527 minutes
2023-08-07 15:16:50,200:INFO:SubProcess create_model() called ==================================
2023-08-07 15:16:50,201:INFO:Initializing create_model()
2023-08-07 15:16:50,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:16:50,201:INFO:Checking exceptions
2023-08-07 15:16:50,201:INFO:Importing libraries
2023-08-07 15:16:50,201:INFO:Copying training dataset
2023-08-07 15:16:50,206:INFO:Defining folds
2023-08-07 15:16:50,206:INFO:Declaring metric variables
2023-08-07 15:16:50,211:INFO:Importing untrained model
2023-08-07 15:16:50,216:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-07 15:16:50,224:INFO:Starting cross validation
2023-08-07 15:16:50,225:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:16:50,315:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:16:50,732:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:16:51,148:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:16:51,560:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:16:51,975:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:16:52,391:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:16:52,811:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:16:53,232:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:16:53,658:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:16:54,090:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:16:54,438:INFO:Calculating mean and std
2023-08-07 15:16:54,440:INFO:Creating metrics dataframe
2023-08-07 15:16:54,670:INFO:Uploading results into container
2023-08-07 15:16:54,671:INFO:Uploading model into container now
2023-08-07 15:16:54,672:INFO:_master_model_container: 8
2023-08-07 15:16:54,672:INFO:_display_container: 2
2023-08-07 15:16:54,673:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-07 15:16:54,673:INFO:create_model() successfully completed......................................
2023-08-07 15:16:54,843:INFO:SubProcess create_model() end ==================================
2023-08-07 15:16:54,843:INFO:Creating metrics dataframe
2023-08-07 15:16:54,856:INFO:Initializing Ada Boost Classifier
2023-08-07 15:16:54,857:INFO:Total runtime is 0.6450059453646342 minutes
2023-08-07 15:16:54,861:INFO:SubProcess create_model() called ==================================
2023-08-07 15:16:54,861:INFO:Initializing create_model()
2023-08-07 15:16:54,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:16:54,861:INFO:Checking exceptions
2023-08-07 15:16:54,861:INFO:Importing libraries
2023-08-07 15:16:54,862:INFO:Copying training dataset
2023-08-07 15:16:54,867:INFO:Defining folds
2023-08-07 15:16:54,867:INFO:Declaring metric variables
2023-08-07 15:16:54,872:INFO:Importing untrained model
2023-08-07 15:16:54,877:INFO:Ada Boost Classifier Imported successfully
2023-08-07 15:16:54,884:INFO:Starting cross validation
2023-08-07 15:16:54,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:17:00,908:INFO:Calculating mean and std
2023-08-07 15:17:00,910:INFO:Creating metrics dataframe
2023-08-07 15:17:01,137:INFO:Uploading results into container
2023-08-07 15:17:01,138:INFO:Uploading model into container now
2023-08-07 15:17:01,139:INFO:_master_model_container: 9
2023-08-07 15:17:01,139:INFO:_display_container: 2
2023-08-07 15:17:01,140:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5614)
2023-08-07 15:17:01,140:INFO:create_model() successfully completed......................................
2023-08-07 15:17:01,305:INFO:SubProcess create_model() end ==================================
2023-08-07 15:17:01,306:INFO:Creating metrics dataframe
2023-08-07 15:17:01,320:INFO:Initializing Gradient Boosting Classifier
2023-08-07 15:17:01,321:INFO:Total runtime is 0.7527417103449503 minutes
2023-08-07 15:17:01,325:INFO:SubProcess create_model() called ==================================
2023-08-07 15:17:01,325:INFO:Initializing create_model()
2023-08-07 15:17:01,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:17:01,326:INFO:Checking exceptions
2023-08-07 15:17:01,326:INFO:Importing libraries
2023-08-07 15:17:01,326:INFO:Copying training dataset
2023-08-07 15:17:01,330:INFO:Defining folds
2023-08-07 15:17:01,331:INFO:Declaring metric variables
2023-08-07 15:17:01,336:INFO:Importing untrained model
2023-08-07 15:17:01,341:INFO:Gradient Boosting Classifier Imported successfully
2023-08-07 15:17:01,350:INFO:Starting cross validation
2023-08-07 15:17:01,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:17:06,564:INFO:Calculating mean and std
2023-08-07 15:17:06,566:INFO:Creating metrics dataframe
2023-08-07 15:17:06,796:INFO:Uploading results into container
2023-08-07 15:17:06,798:INFO:Uploading model into container now
2023-08-07 15:17:06,798:INFO:_master_model_container: 10
2023-08-07 15:17:06,799:INFO:_display_container: 2
2023-08-07 15:17:06,799:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 15:17:06,799:INFO:create_model() successfully completed......................................
2023-08-07 15:17:06,969:INFO:SubProcess create_model() end ==================================
2023-08-07 15:17:06,969:INFO:Creating metrics dataframe
2023-08-07 15:17:06,984:INFO:Initializing Linear Discriminant Analysis
2023-08-07 15:17:06,984:INFO:Total runtime is 0.8471258600552876 minutes
2023-08-07 15:17:06,988:INFO:SubProcess create_model() called ==================================
2023-08-07 15:17:06,989:INFO:Initializing create_model()
2023-08-07 15:17:06,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:17:06,989:INFO:Checking exceptions
2023-08-07 15:17:06,989:INFO:Importing libraries
2023-08-07 15:17:06,989:INFO:Copying training dataset
2023-08-07 15:17:06,994:INFO:Defining folds
2023-08-07 15:17:06,995:INFO:Declaring metric variables
2023-08-07 15:17:06,999:INFO:Importing untrained model
2023-08-07 15:17:07,004:INFO:Linear Discriminant Analysis Imported successfully
2023-08-07 15:17:07,012:INFO:Starting cross validation
2023-08-07 15:17:07,013:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:17:11,201:INFO:Calculating mean and std
2023-08-07 15:17:11,203:INFO:Creating metrics dataframe
2023-08-07 15:17:11,434:INFO:Uploading results into container
2023-08-07 15:17:11,435:INFO:Uploading model into container now
2023-08-07 15:17:11,436:INFO:_master_model_container: 11
2023-08-07 15:17:11,436:INFO:_display_container: 2
2023-08-07 15:17:11,436:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-07 15:17:11,437:INFO:create_model() successfully completed......................................
2023-08-07 15:17:11,600:INFO:SubProcess create_model() end ==================================
2023-08-07 15:17:11,601:INFO:Creating metrics dataframe
2023-08-07 15:17:11,615:INFO:Initializing Extra Trees Classifier
2023-08-07 15:17:11,616:INFO:Total runtime is 0.9243265787760415 minutes
2023-08-07 15:17:11,621:INFO:SubProcess create_model() called ==================================
2023-08-07 15:17:11,621:INFO:Initializing create_model()
2023-08-07 15:17:11,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:17:11,622:INFO:Checking exceptions
2023-08-07 15:17:11,622:INFO:Importing libraries
2023-08-07 15:17:11,622:INFO:Copying training dataset
2023-08-07 15:17:11,627:INFO:Defining folds
2023-08-07 15:17:11,627:INFO:Declaring metric variables
2023-08-07 15:17:11,631:INFO:Importing untrained model
2023-08-07 15:17:11,635:INFO:Extra Trees Classifier Imported successfully
2023-08-07 15:17:11,643:INFO:Starting cross validation
2023-08-07 15:17:11,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:17:17,691:INFO:Calculating mean and std
2023-08-07 15:17:17,692:INFO:Creating metrics dataframe
2023-08-07 15:17:17,922:INFO:Uploading results into container
2023-08-07 15:17:17,924:INFO:Uploading model into container now
2023-08-07 15:17:17,924:INFO:_master_model_container: 12
2023-08-07 15:17:17,925:INFO:_display_container: 2
2023-08-07 15:17:17,925:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=1, oob_score=False,
                     random_state=5614, verbose=0, warm_start=False)
2023-08-07 15:17:17,925:INFO:create_model() successfully completed......................................
2023-08-07 15:17:18,094:INFO:SubProcess create_model() end ==================================
2023-08-07 15:17:18,094:INFO:Creating metrics dataframe
2023-08-07 15:17:18,110:INFO:Initializing Light Gradient Boosting Machine
2023-08-07 15:17:18,110:INFO:Total runtime is 1.0325607856114705 minutes
2023-08-07 15:17:18,114:INFO:SubProcess create_model() called ==================================
2023-08-07 15:17:18,115:INFO:Initializing create_model()
2023-08-07 15:17:18,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:17:18,115:INFO:Checking exceptions
2023-08-07 15:17:18,115:INFO:Importing libraries
2023-08-07 15:17:18,115:INFO:Copying training dataset
2023-08-07 15:17:18,121:INFO:Defining folds
2023-08-07 15:17:18,122:INFO:Declaring metric variables
2023-08-07 15:17:18,126:INFO:Importing untrained model
2023-08-07 15:17:18,131:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-07 15:17:18,138:INFO:Starting cross validation
2023-08-07 15:17:18,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:17:18,230:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 15:17:18,231:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.
2023-08-07 15:17:18,231:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 15:17:18,231:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 15:17:18,231:INFO:[LightGBM] [Info] Total Bins 194
2023-08-07 15:17:18,231:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 15:17:18,231:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 15:17:18,231:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 15:17:18,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,709:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 15:17:18,709:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.
2023-08-07 15:17:18,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 15:17:18,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 15:17:18,710:INFO:[LightGBM] [Info] Total Bins 188
2023-08-07 15:17:18,710:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 15:17:18,710:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 15:17:18,710:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 15:17:18,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:18,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,203:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 15:17:19,203:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.
2023-08-07 15:17:19,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 15:17:19,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 15:17:19,203:INFO:[LightGBM] [Info] Total Bins 192
2023-08-07 15:17:19,204:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 15:17:19,204:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 15:17:19,204:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 15:17:19,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,684:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 15:17:19,684:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.
2023-08-07 15:17:19,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 15:17:19,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 15:17:19,684:INFO:[LightGBM] [Info] Total Bins 193
2023-08-07 15:17:19,685:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 15:17:19,685:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 15:17:19,685:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 15:17:19,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:19,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,167:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 15:17:20,167:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000075 seconds.
2023-08-07 15:17:20,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 15:17:20,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 15:17:20,167:INFO:[LightGBM] [Info] Total Bins 188
2023-08-07 15:17:20,167:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 15:17:20,168:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 15:17:20,168:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 15:17:20,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,645:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 15:17:20,645:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.
2023-08-07 15:17:20,646:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 15:17:20,646:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 15:17:20,646:INFO:[LightGBM] [Info] Total Bins 189
2023-08-07 15:17:20,646:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 15:17:20,646:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 15:17:20,646:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 15:17:20,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:20,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,134:INFO:[LightGBM] [Info] Number of positive: 201, number of negative: 330
2023-08-07 15:17:21,134:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.
2023-08-07 15:17:21,134:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 15:17:21,134:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 15:17:21,134:INFO:[LightGBM] [Info] Total Bins 188
2023-08-07 15:17:21,134:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 15:17:21,135:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378531 -> initscore=-0.495788
2023-08-07 15:17:21,135:INFO:[LightGBM] [Info] Start training from score -0.495788
2023-08-07 15:17:21,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,619:INFO:[LightGBM] [Info] Number of positive: 200, number of negative: 331
2023-08-07 15:17:21,620:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.
2023-08-07 15:17:21,620:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 15:17:21,620:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 15:17:21,620:INFO:[LightGBM] [Info] Total Bins 191
2023-08-07 15:17:21,620:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 15:17:21,620:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376648 -> initscore=-0.503801
2023-08-07 15:17:21,620:INFO:[LightGBM] [Info] Start training from score -0.503801
2023-08-07 15:17:21,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:21,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,114:INFO:[LightGBM] [Info] Number of positive: 200, number of negative: 331
2023-08-07 15:17:22,114:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.
2023-08-07 15:17:22,114:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 15:17:22,114:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 15:17:22,114:INFO:[LightGBM] [Info] Total Bins 192
2023-08-07 15:17:22,114:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 15:17:22,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376648 -> initscore=-0.503801
2023-08-07 15:17:22,115:INFO:[LightGBM] [Info] Start training from score -0.503801
2023-08-07 15:17:22,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,597:INFO:[LightGBM] [Info] Number of positive: 200, number of negative: 331
2023-08-07 15:17:22,598:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000075 seconds.
2023-08-07 15:17:22,598:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-07 15:17:22,598:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-07 15:17:22,598:INFO:[LightGBM] [Info] Total Bins 189
2023-08-07 15:17:22,598:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 9
2023-08-07 15:17:22,598:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376648 -> initscore=-0.503801
2023-08-07 15:17:22,598:INFO:[LightGBM] [Info] Start training from score -0.503801
2023-08-07 15:17:22,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-07 15:17:22,986:INFO:Calculating mean and std
2023-08-07 15:17:22,988:INFO:Creating metrics dataframe
2023-08-07 15:17:23,222:INFO:Uploading results into container
2023-08-07 15:17:23,223:INFO:Uploading model into container now
2023-08-07 15:17:23,224:INFO:_master_model_container: 13
2023-08-07 15:17:23,224:INFO:_display_container: 2
2023-08-07 15:17:23,225:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=5614, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-07 15:17:23,225:INFO:create_model() successfully completed......................................
2023-08-07 15:17:23,393:INFO:SubProcess create_model() end ==================================
2023-08-07 15:17:23,393:INFO:Creating metrics dataframe
2023-08-07 15:17:23,411:INFO:Initializing Dummy Classifier
2023-08-07 15:17:23,412:INFO:Total runtime is 1.1209282199541728 minutes
2023-08-07 15:17:23,416:INFO:SubProcess create_model() called ==================================
2023-08-07 15:17:23,416:INFO:Initializing create_model()
2023-08-07 15:17:23,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C556FBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:17:23,417:INFO:Checking exceptions
2023-08-07 15:17:23,417:INFO:Importing libraries
2023-08-07 15:17:23,417:INFO:Copying training dataset
2023-08-07 15:17:23,422:INFO:Defining folds
2023-08-07 15:17:23,422:INFO:Declaring metric variables
2023-08-07 15:17:23,426:INFO:Importing untrained model
2023-08-07 15:17:23,431:INFO:Dummy Classifier Imported successfully
2023-08-07 15:17:23,442:INFO:Starting cross validation
2023-08-07 15:17:23,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-08-07 15:17:23,639:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:17:24,068:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:17:24,488:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:17:24,911:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:17:25,350:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:17:25,771:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:17:26,177:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:17:26,584:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:17:26,997:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:17:27,407:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:17:27,644:INFO:Calculating mean and std
2023-08-07 15:17:27,646:INFO:Creating metrics dataframe
2023-08-07 15:17:27,875:INFO:Uploading results into container
2023-08-07 15:17:27,876:INFO:Uploading model into container now
2023-08-07 15:17:27,877:INFO:_master_model_container: 14
2023-08-07 15:17:27,877:INFO:_display_container: 2
2023-08-07 15:17:27,878:INFO:DummyClassifier(constant=None, random_state=5614, strategy='prior')
2023-08-07 15:17:27,878:INFO:create_model() successfully completed......................................
2023-08-07 15:17:28,049:INFO:SubProcess create_model() end ==================================
2023-08-07 15:17:28,049:INFO:Creating metrics dataframe
2023-08-07 15:17:28,078:INFO:Initializing create_model()
2023-08-07 15:17:28,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:17:28,079:INFO:Checking exceptions
2023-08-07 15:17:28,081:INFO:Importing libraries
2023-08-07 15:17:28,081:INFO:Copying training dataset
2023-08-07 15:17:28,085:INFO:Defining folds
2023-08-07 15:17:28,085:INFO:Declaring metric variables
2023-08-07 15:17:28,085:INFO:Importing untrained model
2023-08-07 15:17:28,085:INFO:Declaring custom model
2023-08-07 15:17:28,086:INFO:Gradient Boosting Classifier Imported successfully
2023-08-07 15:17:28,088:INFO:Cross validation set to False
2023-08-07 15:17:28,088:INFO:Fitting Model
2023-08-07 15:17:28,415:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 15:17:28,416:INFO:create_model() successfully completed......................................
2023-08-07 15:17:28,625:INFO:_master_model_container: 14
2023-08-07 15:17:28,626:INFO:_display_container: 2
2023-08-07 15:17:28,626:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 15:17:28,626:INFO:compare_models() successfully completed......................................
2023-08-07 15:18:46,257:INFO:PyCaret ClassificationExperiment
2023-08-07 15:18:46,258:INFO:Logging name: clf-default-name
2023-08-07 15:18:46,258:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-07 15:18:46,258:INFO:version 3.0.4
2023-08-07 15:18:46,259:INFO:Initializing setup()
2023-08-07 15:18:46,259:INFO:self.USI: 471b
2023-08-07 15:18:46,259:INFO:self._variable_keys: {'idx', 'memory', 'fold_generator', 'log_plots_param', 'X_test', 'html_param', 'X', 'target_param', 'data', '_available_plots', 'fix_imbalance', 'gpu_param', 'X_train', 'exp_id', 'gpu_n_jobs_param', 'pipeline', 'y_test', 'n_jobs_param', 'y', 'exp_name_log', 'fold_groups_param', 'USI', 'y_train', 'fold_shuffle_param', '_ml_usecase', 'seed', 'logging_param', 'is_multiclass'}
2023-08-07 15:18:46,259:INFO:Checking environment
2023-08-07 15:18:46,259:INFO:python_version: 3.9.17
2023-08-07 15:18:46,260:INFO:python_build: ('main', 'Jul  5 2023 20:47:11')
2023-08-07 15:18:46,260:INFO:machine: AMD64
2023-08-07 15:18:46,260:INFO:platform: Windows-10-10.0.20348-SP0
2023-08-07 15:18:46,260:INFO:Memory: svmem(total=34358562816, available=23804260352, percent=30.7, used=10554302464, free=23804260352)
2023-08-07 15:18:46,261:INFO:Physical Core: 8
2023-08-07 15:18:46,261:INFO:Logical Core: 8
2023-08-07 15:18:46,261:INFO:Checking libraries
2023-08-07 15:18:46,261:INFO:System:
2023-08-07 15:18:46,262:INFO:    python: 3.9.17 (main, Jul  5 2023, 20:47:11) [MSC v.1916 64 bit (AMD64)]
2023-08-07 15:18:46,262:INFO:executable: c:\ProgramData\Miniconda3\envs\pycaret_env\python.exe
2023-08-07 15:18:46,262:INFO:   machine: Windows-10-10.0.20348-SP0
2023-08-07 15:18:46,262:INFO:PyCaret required dependencies:
2023-08-07 15:18:46,263:INFO:                 pip: 23.2.1
2023-08-07 15:18:46,263:INFO:          setuptools: 68.0.0
2023-08-07 15:18:46,263:INFO:             pycaret: 3.0.4
2023-08-07 15:18:46,263:INFO:             IPython: 8.12.0
2023-08-07 15:18:46,263:INFO:          ipywidgets: 8.1.0
2023-08-07 15:18:46,263:INFO:                tqdm: 4.65.0
2023-08-07 15:18:46,263:INFO:               numpy: 1.23.5
2023-08-07 15:18:46,263:INFO:              pandas: 1.5.3
2023-08-07 15:18:46,263:INFO:              jinja2: 3.1.2
2023-08-07 15:18:46,263:INFO:               scipy: 1.11.1
2023-08-07 15:18:46,263:INFO:              joblib: 1.3.1
2023-08-07 15:18:46,263:INFO:             sklearn: 1.2.2
2023-08-07 15:18:46,264:INFO:                pyod: 1.1.0
2023-08-07 15:18:46,264:INFO:            imblearn: 0.11.0
2023-08-07 15:18:46,264:INFO:   category_encoders: 2.6.1
2023-08-07 15:18:46,264:INFO:            lightgbm: 4.0.0
2023-08-07 15:18:46,264:INFO:               numba: 0.57.1
2023-08-07 15:18:46,264:INFO:            requests: 2.31.0
2023-08-07 15:18:46,264:INFO:          matplotlib: 3.7.2
2023-08-07 15:18:46,264:INFO:          scikitplot: 0.3.7
2023-08-07 15:18:46,264:INFO:         yellowbrick: 1.5
2023-08-07 15:18:46,264:INFO:              plotly: 5.15.0
2023-08-07 15:18:46,264:INFO:    plotly-resampler: Not installed
2023-08-07 15:18:46,264:INFO:             kaleido: 0.2.1
2023-08-07 15:18:46,264:INFO:           schemdraw: 0.15
2023-08-07 15:18:46,264:INFO:         statsmodels: 0.14.0
2023-08-07 15:18:46,264:INFO:              sktime: 0.21.0
2023-08-07 15:18:46,264:INFO:               tbats: 1.1.3
2023-08-07 15:18:46,264:INFO:            pmdarima: 2.0.3
2023-08-07 15:18:46,264:INFO:              psutil: 5.9.0
2023-08-07 15:18:46,264:INFO:          markupsafe: 2.1.3
2023-08-07 15:18:46,264:INFO:             pickle5: Not installed
2023-08-07 15:18:46,264:INFO:         cloudpickle: 2.2.1
2023-08-07 15:18:46,264:INFO:         deprecation: 2.1.0
2023-08-07 15:18:46,264:INFO:              xxhash: 3.3.0
2023-08-07 15:18:46,264:INFO:           wurlitzer: Not installed
2023-08-07 15:18:46,265:INFO:PyCaret optional dependencies:
2023-08-07 15:18:46,265:INFO:                shap: Not installed
2023-08-07 15:18:46,265:INFO:           interpret: Not installed
2023-08-07 15:18:46,265:INFO:                umap: Not installed
2023-08-07 15:18:46,265:INFO:    pandas_profiling: Not installed
2023-08-07 15:18:46,265:INFO:  explainerdashboard: Not installed
2023-08-07 15:18:46,265:INFO:             autoviz: Not installed
2023-08-07 15:18:46,265:INFO:           fairlearn: Not installed
2023-08-07 15:18:46,265:INFO:          deepchecks: Not installed
2023-08-07 15:18:46,265:INFO:             xgboost: Not installed
2023-08-07 15:18:46,265:INFO:            catboost: Not installed
2023-08-07 15:18:46,265:INFO:              kmodes: Not installed
2023-08-07 15:18:46,265:INFO:             mlxtend: Not installed
2023-08-07 15:18:46,265:INFO:       statsforecast: Not installed
2023-08-07 15:18:46,265:INFO:        tune_sklearn: Not installed
2023-08-07 15:18:46,265:INFO:                 ray: Not installed
2023-08-07 15:18:46,265:INFO:            hyperopt: Not installed
2023-08-07 15:18:46,265:INFO:              optuna: Not installed
2023-08-07 15:18:46,265:INFO:               skopt: Not installed
2023-08-07 15:18:46,265:INFO:              mlflow: Not installed
2023-08-07 15:18:46,265:INFO:              gradio: Not installed
2023-08-07 15:18:46,265:INFO:             fastapi: Not installed
2023-08-07 15:18:46,265:INFO:             uvicorn: Not installed
2023-08-07 15:18:46,266:INFO:              m2cgen: Not installed
2023-08-07 15:18:46,266:INFO:           evidently: Not installed
2023-08-07 15:18:46,266:INFO:               fugue: Not installed
2023-08-07 15:18:46,266:INFO:           streamlit: Not installed
2023-08-07 15:18:46,266:INFO:             prophet: Not installed
2023-08-07 15:18:46,266:INFO:None
2023-08-07 15:18:46,266:INFO:Set up data.
2023-08-07 15:18:46,272:INFO:Set up train/test split.
2023-08-07 15:18:46,276:INFO:Set up index.
2023-08-07 15:18:46,277:INFO:Set up folding strategy.
2023-08-07 15:18:46,277:INFO:Assigning column types.
2023-08-07 15:18:46,281:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-07 15:18:46,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-07 15:18:46,337:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:18:46,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,423:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-07 15:18:46,424:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:18:46,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,458:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-07 15:18:46,513:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:18:46,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,605:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:18:46,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,640:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-07 15:18:46,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:46,832:INFO:Preparing preprocessing pipeline...
2023-08-07 15:18:46,833:INFO:Set up simple imputation.
2023-08-07 15:18:46,838:INFO:Set up encoding of ordinal features.
2023-08-07 15:18:46,841:INFO:Set up encoding of categorical features.
2023-08-07 15:18:46,911:INFO:Finished creating preprocessing pipeline.
2023-08-07 15:18:46,964:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lucazav\AppData\Local\Temp\5\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('c...
                                                                        {'col': 'Sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-07 15:18:46,965:INFO:Creating final display dataframe.
2023-08-07 15:18:47,191:INFO:Setup _display_container:                     Description             Value
0                    Session id              5614
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (844, 8)
4        Transformed data shape         (844, 10)
5   Transformed train set shape         (590, 10)
6    Transformed test set shape         (254, 10)
7              Ordinal features                 2
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                 8
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              471b
2023-08-07 15:18:47,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:47,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:47,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:47,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:18:47,373:INFO:setup() successfully completed in 1.35s...............
2023-08-07 15:18:49,674:INFO:Initializing compare_models()
2023-08-07 15:18:49,674:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-07 15:18:49,674:INFO:Checking exceptions
2023-08-07 15:18:49,679:INFO:Preparing display monitor
2023-08-07 15:18:49,709:INFO:Initializing Logistic Regression
2023-08-07 15:18:49,709:INFO:Total runtime is 0.0 minutes
2023-08-07 15:18:49,716:INFO:SubProcess create_model() called ==================================
2023-08-07 15:18:49,717:INFO:Initializing create_model()
2023-08-07 15:18:49,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:18:49,717:INFO:Checking exceptions
2023-08-07 15:18:49,717:INFO:Importing libraries
2023-08-07 15:18:49,717:INFO:Copying training dataset
2023-08-07 15:18:49,722:INFO:Defining folds
2023-08-07 15:18:49,722:INFO:Declaring metric variables
2023-08-07 15:18:49,726:INFO:Importing untrained model
2023-08-07 15:18:49,731:INFO:Logistic Regression Imported successfully
2023-08-07 15:18:49,739:INFO:Starting cross validation
2023-08-07 15:18:49,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:18:56,044:INFO:Calculating mean and std
2023-08-07 15:18:56,046:INFO:Creating metrics dataframe
2023-08-07 15:18:56,453:INFO:Uploading results into container
2023-08-07 15:18:56,454:INFO:Uploading model into container now
2023-08-07 15:18:56,455:INFO:_master_model_container: 1
2023-08-07 15:18:56,455:INFO:_display_container: 2
2023-08-07 15:18:56,455:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5614, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-07 15:18:56,455:INFO:create_model() successfully completed......................................
2023-08-07 15:18:56,630:INFO:SubProcess create_model() end ==================================
2023-08-07 15:18:56,631:INFO:Creating metrics dataframe
2023-08-07 15:18:56,642:INFO:Initializing K Neighbors Classifier
2023-08-07 15:18:56,642:INFO:Total runtime is 0.11555096705754599 minutes
2023-08-07 15:18:56,646:INFO:SubProcess create_model() called ==================================
2023-08-07 15:18:56,646:INFO:Initializing create_model()
2023-08-07 15:18:56,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:18:56,647:INFO:Checking exceptions
2023-08-07 15:18:56,647:INFO:Importing libraries
2023-08-07 15:18:56,647:INFO:Copying training dataset
2023-08-07 15:18:56,652:INFO:Defining folds
2023-08-07 15:18:56,653:INFO:Declaring metric variables
2023-08-07 15:18:56,657:INFO:Importing untrained model
2023-08-07 15:18:56,662:INFO:K Neighbors Classifier Imported successfully
2023-08-07 15:18:56,670:INFO:Starting cross validation
2023-08-07 15:18:56,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:18:59,137:INFO:Calculating mean and std
2023-08-07 15:18:59,139:INFO:Creating metrics dataframe
2023-08-07 15:18:59,545:INFO:Uploading results into container
2023-08-07 15:18:59,547:INFO:Uploading model into container now
2023-08-07 15:18:59,547:INFO:_master_model_container: 2
2023-08-07 15:18:59,548:INFO:_display_container: 2
2023-08-07 15:18:59,548:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=8, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-07 15:18:59,548:INFO:create_model() successfully completed......................................
2023-08-07 15:18:59,719:INFO:SubProcess create_model() end ==================================
2023-08-07 15:18:59,719:INFO:Creating metrics dataframe
2023-08-07 15:18:59,732:INFO:Initializing Naive Bayes
2023-08-07 15:18:59,732:INFO:Total runtime is 0.16705140670140584 minutes
2023-08-07 15:18:59,736:INFO:SubProcess create_model() called ==================================
2023-08-07 15:18:59,737:INFO:Initializing create_model()
2023-08-07 15:18:59,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:18:59,737:INFO:Checking exceptions
2023-08-07 15:18:59,737:INFO:Importing libraries
2023-08-07 15:18:59,737:INFO:Copying training dataset
2023-08-07 15:18:59,743:INFO:Defining folds
2023-08-07 15:18:59,744:INFO:Declaring metric variables
2023-08-07 15:18:59,748:INFO:Importing untrained model
2023-08-07 15:18:59,752:INFO:Naive Bayes Imported successfully
2023-08-07 15:18:59,760:INFO:Starting cross validation
2023-08-07 15:18:59,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:02,184:INFO:Calculating mean and std
2023-08-07 15:19:02,186:INFO:Creating metrics dataframe
2023-08-07 15:19:02,598:INFO:Uploading results into container
2023-08-07 15:19:02,600:INFO:Uploading model into container now
2023-08-07 15:19:02,600:INFO:_master_model_container: 3
2023-08-07 15:19:02,600:INFO:_display_container: 2
2023-08-07 15:19:02,601:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-07 15:19:02,601:INFO:create_model() successfully completed......................................
2023-08-07 15:19:02,770:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:02,771:INFO:Creating metrics dataframe
2023-08-07 15:19:02,784:INFO:Initializing Decision Tree Classifier
2023-08-07 15:19:02,784:INFO:Total runtime is 0.21791850328445433 minutes
2023-08-07 15:19:02,788:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:02,788:INFO:Initializing create_model()
2023-08-07 15:19:02,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:02,789:INFO:Checking exceptions
2023-08-07 15:19:02,789:INFO:Importing libraries
2023-08-07 15:19:02,789:INFO:Copying training dataset
2023-08-07 15:19:02,794:INFO:Defining folds
2023-08-07 15:19:02,794:INFO:Declaring metric variables
2023-08-07 15:19:02,798:INFO:Importing untrained model
2023-08-07 15:19:02,803:INFO:Decision Tree Classifier Imported successfully
2023-08-07 15:19:02,812:INFO:Starting cross validation
2023-08-07 15:19:02,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:05,231:INFO:Calculating mean and std
2023-08-07 15:19:05,233:INFO:Creating metrics dataframe
2023-08-07 15:19:05,651:INFO:Uploading results into container
2023-08-07 15:19:05,653:INFO:Uploading model into container now
2023-08-07 15:19:05,654:INFO:_master_model_container: 4
2023-08-07 15:19:05,654:INFO:_display_container: 2
2023-08-07 15:19:05,654:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5614, splitter='best')
2023-08-07 15:19:05,654:INFO:create_model() successfully completed......................................
2023-08-07 15:19:05,828:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:05,829:INFO:Creating metrics dataframe
2023-08-07 15:19:05,842:INFO:Initializing SVM - Linear Kernel
2023-08-07 15:19:05,842:INFO:Total runtime is 0.26888564427693684 minutes
2023-08-07 15:19:05,847:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:05,847:INFO:Initializing create_model()
2023-08-07 15:19:05,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:05,847:INFO:Checking exceptions
2023-08-07 15:19:05,847:INFO:Importing libraries
2023-08-07 15:19:05,848:INFO:Copying training dataset
2023-08-07 15:19:05,852:INFO:Defining folds
2023-08-07 15:19:05,852:INFO:Declaring metric variables
2023-08-07 15:19:05,857:INFO:Importing untrained model
2023-08-07 15:19:05,862:INFO:SVM - Linear Kernel Imported successfully
2023-08-07 15:19:05,870:INFO:Starting cross validation
2023-08-07 15:19:05,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:06,047:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:19:06,052:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:19:06,066:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:19:06,070:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:19:06,075:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:19:06,078:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:06,079:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:19:06,079:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:19:06,100:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:19:06,541:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:19:06,546:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:19:08,229:INFO:Calculating mean and std
2023-08-07 15:19:08,231:INFO:Creating metrics dataframe
2023-08-07 15:19:08,636:INFO:Uploading results into container
2023-08-07 15:19:08,637:INFO:Uploading model into container now
2023-08-07 15:19:08,638:INFO:_master_model_container: 5
2023-08-07 15:19:08,638:INFO:_display_container: 2
2023-08-07 15:19:08,639:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=8, penalty='l2',
              power_t=0.5, random_state=5614, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-07 15:19:08,639:INFO:create_model() successfully completed......................................
2023-08-07 15:19:08,816:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:08,816:INFO:Creating metrics dataframe
2023-08-07 15:19:08,830:INFO:Initializing Ridge Classifier
2023-08-07 15:19:08,830:INFO:Total runtime is 0.318686052163442 minutes
2023-08-07 15:19:08,834:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:08,835:INFO:Initializing create_model()
2023-08-07 15:19:08,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:08,835:INFO:Checking exceptions
2023-08-07 15:19:08,836:INFO:Importing libraries
2023-08-07 15:19:08,836:INFO:Copying training dataset
2023-08-07 15:19:08,840:INFO:Defining folds
2023-08-07 15:19:08,840:INFO:Declaring metric variables
2023-08-07 15:19:08,845:INFO:Importing untrained model
2023-08-07 15:19:08,849:INFO:Ridge Classifier Imported successfully
2023-08-07 15:19:08,857:INFO:Starting cross validation
2023-08-07 15:19:08,859:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:09,031:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:19:09,037:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:19:09,042:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:19:09,045:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:19:09,047:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:19:09,099:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:19:09,113:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:19:09,167:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:19:09,547:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:19:09,556:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:19:11,259:INFO:Calculating mean and std
2023-08-07 15:19:11,261:INFO:Creating metrics dataframe
2023-08-07 15:19:11,678:INFO:Uploading results into container
2023-08-07 15:19:11,681:INFO:Uploading model into container now
2023-08-07 15:19:11,682:INFO:_master_model_container: 6
2023-08-07 15:19:11,682:INFO:_display_container: 2
2023-08-07 15:19:11,682:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5614, solver='auto',
                tol=0.0001)
2023-08-07 15:19:11,683:INFO:create_model() successfully completed......................................
2023-08-07 15:19:11,849:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:11,849:INFO:Creating metrics dataframe
2023-08-07 15:19:11,862:INFO:Initializing Random Forest Classifier
2023-08-07 15:19:11,863:INFO:Total runtime is 0.36923649708429973 minutes
2023-08-07 15:19:11,867:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:11,868:INFO:Initializing create_model()
2023-08-07 15:19:11,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:11,868:INFO:Checking exceptions
2023-08-07 15:19:11,868:INFO:Importing libraries
2023-08-07 15:19:11,868:INFO:Copying training dataset
2023-08-07 15:19:11,873:INFO:Defining folds
2023-08-07 15:19:11,873:INFO:Declaring metric variables
2023-08-07 15:19:11,878:INFO:Importing untrained model
2023-08-07 15:19:11,882:INFO:Random Forest Classifier Imported successfully
2023-08-07 15:19:11,890:INFO:Starting cross validation
2023-08-07 15:19:11,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:14,954:INFO:Calculating mean and std
2023-08-07 15:19:14,956:INFO:Creating metrics dataframe
2023-08-07 15:19:15,375:INFO:Uploading results into container
2023-08-07 15:19:15,377:INFO:Uploading model into container now
2023-08-07 15:19:15,377:INFO:_master_model_container: 7
2023-08-07 15:19:15,377:INFO:_display_container: 2
2023-08-07 15:19:15,378:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=8, oob_score=False,
                       random_state=5614, verbose=0, warm_start=False)
2023-08-07 15:19:15,378:INFO:create_model() successfully completed......................................
2023-08-07 15:19:15,550:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:15,550:INFO:Creating metrics dataframe
2023-08-07 15:19:15,565:INFO:Initializing Quadratic Discriminant Analysis
2023-08-07 15:19:15,565:INFO:Total runtime is 0.4309370319048564 minutes
2023-08-07 15:19:15,571:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:15,571:INFO:Initializing create_model()
2023-08-07 15:19:15,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:15,571:INFO:Checking exceptions
2023-08-07 15:19:15,571:INFO:Importing libraries
2023-08-07 15:19:15,571:INFO:Copying training dataset
2023-08-07 15:19:15,577:INFO:Defining folds
2023-08-07 15:19:15,577:INFO:Declaring metric variables
2023-08-07 15:19:15,582:INFO:Importing untrained model
2023-08-07 15:19:15,586:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-07 15:19:15,595:INFO:Starting cross validation
2023-08-07 15:19:15,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:15,720:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:19:15,725:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:19:15,730:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:19:15,731:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:19:15,731:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:19:15,746:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:19:15,749:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:19:15,828:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:19:16,259:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:19:16,300:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:19:18,078:INFO:Calculating mean and std
2023-08-07 15:19:18,080:INFO:Creating metrics dataframe
2023-08-07 15:19:18,498:INFO:Uploading results into container
2023-08-07 15:19:18,500:INFO:Uploading model into container now
2023-08-07 15:19:18,500:INFO:_master_model_container: 8
2023-08-07 15:19:18,501:INFO:_display_container: 2
2023-08-07 15:19:18,501:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-07 15:19:18,501:INFO:create_model() successfully completed......................................
2023-08-07 15:19:18,672:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:18,673:INFO:Creating metrics dataframe
2023-08-07 15:19:18,689:INFO:Initializing Ada Boost Classifier
2023-08-07 15:19:18,689:INFO:Total runtime is 0.48298747539520265 minutes
2023-08-07 15:19:18,695:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:18,695:INFO:Initializing create_model()
2023-08-07 15:19:18,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:18,696:INFO:Checking exceptions
2023-08-07 15:19:18,696:INFO:Importing libraries
2023-08-07 15:19:18,696:INFO:Copying training dataset
2023-08-07 15:19:18,702:INFO:Defining folds
2023-08-07 15:19:18,702:INFO:Declaring metric variables
2023-08-07 15:19:18,707:INFO:Importing untrained model
2023-08-07 15:19:18,713:INFO:Ada Boost Classifier Imported successfully
2023-08-07 15:19:18,722:INFO:Starting cross validation
2023-08-07 15:19:18,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:21,394:INFO:Calculating mean and std
2023-08-07 15:19:21,396:INFO:Creating metrics dataframe
2023-08-07 15:19:21,819:INFO:Uploading results into container
2023-08-07 15:19:21,820:INFO:Uploading model into container now
2023-08-07 15:19:21,821:INFO:_master_model_container: 9
2023-08-07 15:19:21,821:INFO:_display_container: 2
2023-08-07 15:19:21,821:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5614)
2023-08-07 15:19:21,822:INFO:create_model() successfully completed......................................
2023-08-07 15:19:21,991:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:21,991:INFO:Creating metrics dataframe
2023-08-07 15:19:22,006:INFO:Initializing Gradient Boosting Classifier
2023-08-07 15:19:22,007:INFO:Total runtime is 0.5382879535357158 minutes
2023-08-07 15:19:22,011:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:22,012:INFO:Initializing create_model()
2023-08-07 15:19:22,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:22,012:INFO:Checking exceptions
2023-08-07 15:19:22,012:INFO:Importing libraries
2023-08-07 15:19:22,012:INFO:Copying training dataset
2023-08-07 15:19:22,016:INFO:Defining folds
2023-08-07 15:19:22,017:INFO:Declaring metric variables
2023-08-07 15:19:22,021:INFO:Importing untrained model
2023-08-07 15:19:22,026:INFO:Gradient Boosting Classifier Imported successfully
2023-08-07 15:19:22,034:INFO:Starting cross validation
2023-08-07 15:19:22,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:24,562:INFO:Calculating mean and std
2023-08-07 15:19:24,564:INFO:Creating metrics dataframe
2023-08-07 15:19:24,981:INFO:Uploading results into container
2023-08-07 15:19:24,982:INFO:Uploading model into container now
2023-08-07 15:19:24,983:INFO:_master_model_container: 10
2023-08-07 15:19:24,983:INFO:_display_container: 2
2023-08-07 15:19:24,984:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 15:19:24,984:INFO:create_model() successfully completed......................................
2023-08-07 15:19:25,154:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:25,154:INFO:Creating metrics dataframe
2023-08-07 15:19:25,169:INFO:Initializing Linear Discriminant Analysis
2023-08-07 15:19:25,169:INFO:Total runtime is 0.5909884293874106 minutes
2023-08-07 15:19:25,174:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:25,175:INFO:Initializing create_model()
2023-08-07 15:19:25,175:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:25,175:INFO:Checking exceptions
2023-08-07 15:19:25,175:INFO:Importing libraries
2023-08-07 15:19:25,175:INFO:Copying training dataset
2023-08-07 15:19:25,181:INFO:Defining folds
2023-08-07 15:19:25,182:INFO:Declaring metric variables
2023-08-07 15:19:25,186:INFO:Importing untrained model
2023-08-07 15:19:25,191:INFO:Linear Discriminant Analysis Imported successfully
2023-08-07 15:19:25,199:INFO:Starting cross validation
2023-08-07 15:19:25,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:27,677:INFO:Calculating mean and std
2023-08-07 15:19:27,679:INFO:Creating metrics dataframe
2023-08-07 15:19:28,100:INFO:Uploading results into container
2023-08-07 15:19:28,102:INFO:Uploading model into container now
2023-08-07 15:19:28,102:INFO:_master_model_container: 11
2023-08-07 15:19:28,102:INFO:_display_container: 2
2023-08-07 15:19:28,103:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-07 15:19:28,103:INFO:create_model() successfully completed......................................
2023-08-07 15:19:28,275:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:28,275:INFO:Creating metrics dataframe
2023-08-07 15:19:28,291:INFO:Initializing Extra Trees Classifier
2023-08-07 15:19:28,291:INFO:Total runtime is 0.6430221875508627 minutes
2023-08-07 15:19:28,295:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:28,296:INFO:Initializing create_model()
2023-08-07 15:19:28,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:28,296:INFO:Checking exceptions
2023-08-07 15:19:28,296:INFO:Importing libraries
2023-08-07 15:19:28,296:INFO:Copying training dataset
2023-08-07 15:19:28,301:INFO:Defining folds
2023-08-07 15:19:28,301:INFO:Declaring metric variables
2023-08-07 15:19:28,306:INFO:Importing untrained model
2023-08-07 15:19:28,310:INFO:Extra Trees Classifier Imported successfully
2023-08-07 15:19:28,318:INFO:Starting cross validation
2023-08-07 15:19:28,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:31,320:INFO:Calculating mean and std
2023-08-07 15:19:31,322:INFO:Creating metrics dataframe
2023-08-07 15:19:31,746:INFO:Uploading results into container
2023-08-07 15:19:31,747:INFO:Uploading model into container now
2023-08-07 15:19:31,748:INFO:_master_model_container: 12
2023-08-07 15:19:31,748:INFO:_display_container: 2
2023-08-07 15:19:31,749:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=8, oob_score=False,
                     random_state=5614, verbose=0, warm_start=False)
2023-08-07 15:19:31,749:INFO:create_model() successfully completed......................................
2023-08-07 15:19:31,916:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:31,916:INFO:Creating metrics dataframe
2023-08-07 15:19:31,932:INFO:Initializing Light Gradient Boosting Machine
2023-08-07 15:19:31,932:INFO:Total runtime is 0.7037060777346293 minutes
2023-08-07 15:19:31,936:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:31,937:INFO:Initializing create_model()
2023-08-07 15:19:31,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:31,937:INFO:Checking exceptions
2023-08-07 15:19:31,937:INFO:Importing libraries
2023-08-07 15:19:31,937:INFO:Copying training dataset
2023-08-07 15:19:31,942:INFO:Defining folds
2023-08-07 15:19:31,942:INFO:Declaring metric variables
2023-08-07 15:19:31,946:INFO:Importing untrained model
2023-08-07 15:19:31,950:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-07 15:19:31,958:INFO:Starting cross validation
2023-08-07 15:19:31,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:35,103:INFO:Calculating mean and std
2023-08-07 15:19:35,105:INFO:Creating metrics dataframe
2023-08-07 15:19:35,532:INFO:Uploading results into container
2023-08-07 15:19:35,533:INFO:Uploading model into container now
2023-08-07 15:19:35,534:INFO:_master_model_container: 13
2023-08-07 15:19:35,534:INFO:_display_container: 2
2023-08-07 15:19:35,535:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=8, num_leaves=31, objective=None,
               random_state=5614, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-07 15:19:35,535:INFO:create_model() successfully completed......................................
2023-08-07 15:19:35,705:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:35,706:INFO:Creating metrics dataframe
2023-08-07 15:19:35,722:INFO:Initializing Dummy Classifier
2023-08-07 15:19:35,722:INFO:Total runtime is 0.766873304049174 minutes
2023-08-07 15:19:35,727:INFO:SubProcess create_model() called ==================================
2023-08-07 15:19:35,727:INFO:Initializing create_model()
2023-08-07 15:19:35,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230CB5ABA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:35,728:INFO:Checking exceptions
2023-08-07 15:19:35,728:INFO:Importing libraries
2023-08-07 15:19:35,728:INFO:Copying training dataset
2023-08-07 15:19:35,733:INFO:Defining folds
2023-08-07 15:19:35,734:INFO:Declaring metric variables
2023-08-07 15:19:35,738:INFO:Importing untrained model
2023-08-07 15:19:35,742:INFO:Dummy Classifier Imported successfully
2023-08-07 15:19:35,751:INFO:Starting cross validation
2023-08-07 15:19:35,753:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=8
2023-08-07 15:19:35,968:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:35,971:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:35,971:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:35,987:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:35,989:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:35,993:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:36,025:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:36,111:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:36,531:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:36,553:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:19:38,232:INFO:Calculating mean and std
2023-08-07 15:19:38,234:INFO:Creating metrics dataframe
2023-08-07 15:19:38,667:INFO:Uploading results into container
2023-08-07 15:19:38,668:INFO:Uploading model into container now
2023-08-07 15:19:38,669:INFO:_master_model_container: 14
2023-08-07 15:19:38,669:INFO:_display_container: 2
2023-08-07 15:19:38,669:INFO:DummyClassifier(constant=None, random_state=5614, strategy='prior')
2023-08-07 15:19:38,669:INFO:create_model() successfully completed......................................
2023-08-07 15:19:38,845:INFO:SubProcess create_model() end ==================================
2023-08-07 15:19:38,845:INFO:Creating metrics dataframe
2023-08-07 15:19:38,873:INFO:Initializing create_model()
2023-08-07 15:19:38,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230C5F1E7C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:19:38,873:INFO:Checking exceptions
2023-08-07 15:19:38,875:INFO:Importing libraries
2023-08-07 15:19:38,876:INFO:Copying training dataset
2023-08-07 15:19:38,879:INFO:Defining folds
2023-08-07 15:19:38,880:INFO:Declaring metric variables
2023-08-07 15:19:38,880:INFO:Importing untrained model
2023-08-07 15:19:38,880:INFO:Declaring custom model
2023-08-07 15:19:38,881:INFO:Gradient Boosting Classifier Imported successfully
2023-08-07 15:19:38,882:INFO:Cross validation set to False
2023-08-07 15:19:38,882:INFO:Fitting Model
2023-08-07 15:19:39,214:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 15:19:39,214:INFO:create_model() successfully completed......................................
2023-08-07 15:19:39,432:INFO:_master_model_container: 14
2023-08-07 15:19:39,432:INFO:_display_container: 2
2023-08-07 15:19:39,433:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 15:19:39,433:INFO:compare_models() successfully completed......................................
2023-08-07 15:22:00,788:INFO:PyCaret ClassificationExperiment
2023-08-07 15:22:00,789:INFO:Logging name: clf-default-name
2023-08-07 15:22:00,789:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-07 15:22:00,789:INFO:version 3.0.4
2023-08-07 15:22:00,790:INFO:Initializing setup()
2023-08-07 15:22:00,790:INFO:self.USI: 4fab
2023-08-07 15:22:00,791:INFO:self._variable_keys: {'idx', 'memory', 'fold_generator', 'log_plots_param', 'X_test', 'html_param', 'X', 'target_param', 'data', '_available_plots', 'fix_imbalance', 'gpu_param', 'X_train', 'exp_id', 'gpu_n_jobs_param', 'pipeline', 'y_test', 'n_jobs_param', 'y', 'exp_name_log', 'fold_groups_param', 'USI', 'y_train', 'fold_shuffle_param', '_ml_usecase', 'seed', 'logging_param', 'is_multiclass'}
2023-08-07 15:22:00,791:INFO:Checking environment
2023-08-07 15:22:00,791:INFO:python_version: 3.9.17
2023-08-07 15:22:00,791:INFO:python_build: ('main', 'Jul  5 2023 20:47:11')
2023-08-07 15:22:00,791:INFO:machine: AMD64
2023-08-07 15:22:00,791:INFO:platform: Windows-10-10.0.20348-SP0
2023-08-07 15:22:00,791:INFO:Memory: svmem(total=34358562816, available=22758113280, percent=33.8, used=11600449536, free=22758113280)
2023-08-07 15:22:00,791:INFO:Physical Core: 8
2023-08-07 15:22:00,791:INFO:Logical Core: 8
2023-08-07 15:22:00,791:INFO:Checking libraries
2023-08-07 15:22:00,791:INFO:System:
2023-08-07 15:22:00,791:INFO:    python: 3.9.17 (main, Jul  5 2023, 20:47:11) [MSC v.1916 64 bit (AMD64)]
2023-08-07 15:22:00,791:INFO:executable: c:\ProgramData\Miniconda3\envs\pycaret_env\python.exe
2023-08-07 15:22:00,791:INFO:   machine: Windows-10-10.0.20348-SP0
2023-08-07 15:22:00,791:INFO:PyCaret required dependencies:
2023-08-07 15:22:00,791:INFO:                 pip: 23.2.1
2023-08-07 15:22:00,792:INFO:          setuptools: 68.0.0
2023-08-07 15:22:00,792:INFO:             pycaret: 3.0.4
2023-08-07 15:22:00,792:INFO:             IPython: 8.12.0
2023-08-07 15:22:00,792:INFO:          ipywidgets: 8.1.0
2023-08-07 15:22:00,792:INFO:                tqdm: 4.65.0
2023-08-07 15:22:00,792:INFO:               numpy: 1.23.5
2023-08-07 15:22:00,792:INFO:              pandas: 1.5.3
2023-08-07 15:22:00,792:INFO:              jinja2: 3.1.2
2023-08-07 15:22:00,792:INFO:               scipy: 1.11.1
2023-08-07 15:22:00,792:INFO:              joblib: 1.3.1
2023-08-07 15:22:00,792:INFO:             sklearn: 1.2.2
2023-08-07 15:22:00,792:INFO:                pyod: 1.1.0
2023-08-07 15:22:00,792:INFO:            imblearn: 0.11.0
2023-08-07 15:22:00,792:INFO:   category_encoders: 2.6.1
2023-08-07 15:22:00,792:INFO:            lightgbm: 4.0.0
2023-08-07 15:22:00,792:INFO:               numba: 0.57.1
2023-08-07 15:22:00,792:INFO:            requests: 2.31.0
2023-08-07 15:22:00,792:INFO:          matplotlib: 3.7.2
2023-08-07 15:22:00,792:INFO:          scikitplot: 0.3.7
2023-08-07 15:22:00,792:INFO:         yellowbrick: 1.5
2023-08-07 15:22:00,792:INFO:              plotly: 5.15.0
2023-08-07 15:22:00,793:INFO:    plotly-resampler: Not installed
2023-08-07 15:22:00,793:INFO:             kaleido: 0.2.1
2023-08-07 15:22:00,793:INFO:           schemdraw: 0.15
2023-08-07 15:22:00,793:INFO:         statsmodels: 0.14.0
2023-08-07 15:22:00,793:INFO:              sktime: 0.21.0
2023-08-07 15:22:00,793:INFO:               tbats: 1.1.3
2023-08-07 15:22:00,793:INFO:            pmdarima: 2.0.3
2023-08-07 15:22:00,793:INFO:              psutil: 5.9.0
2023-08-07 15:22:00,793:INFO:          markupsafe: 2.1.3
2023-08-07 15:22:00,793:INFO:             pickle5: Not installed
2023-08-07 15:22:00,793:INFO:         cloudpickle: 2.2.1
2023-08-07 15:22:00,793:INFO:         deprecation: 2.1.0
2023-08-07 15:22:00,793:INFO:              xxhash: 3.3.0
2023-08-07 15:22:00,793:INFO:           wurlitzer: Not installed
2023-08-07 15:22:00,793:INFO:PyCaret optional dependencies:
2023-08-07 15:22:00,793:INFO:                shap: Not installed
2023-08-07 15:22:00,793:INFO:           interpret: Not installed
2023-08-07 15:22:00,793:INFO:                umap: Not installed
2023-08-07 15:22:00,793:INFO:    pandas_profiling: Not installed
2023-08-07 15:22:00,793:INFO:  explainerdashboard: Not installed
2023-08-07 15:22:00,793:INFO:             autoviz: Not installed
2023-08-07 15:22:00,793:INFO:           fairlearn: Not installed
2023-08-07 15:22:00,793:INFO:          deepchecks: Not installed
2023-08-07 15:22:00,794:INFO:             xgboost: Not installed
2023-08-07 15:22:00,794:INFO:            catboost: Not installed
2023-08-07 15:22:00,794:INFO:              kmodes: Not installed
2023-08-07 15:22:00,794:INFO:             mlxtend: Not installed
2023-08-07 15:22:00,794:INFO:       statsforecast: Not installed
2023-08-07 15:22:00,794:INFO:        tune_sklearn: Not installed
2023-08-07 15:22:00,794:INFO:                 ray: Not installed
2023-08-07 15:22:00,794:INFO:            hyperopt: Not installed
2023-08-07 15:22:00,794:INFO:              optuna: Not installed
2023-08-07 15:22:00,794:INFO:               skopt: Not installed
2023-08-07 15:22:00,794:INFO:              mlflow: Not installed
2023-08-07 15:22:00,794:INFO:              gradio: Not installed
2023-08-07 15:22:00,794:INFO:             fastapi: Not installed
2023-08-07 15:22:00,794:INFO:             uvicorn: Not installed
2023-08-07 15:22:00,794:INFO:              m2cgen: Not installed
2023-08-07 15:22:00,794:INFO:           evidently: Not installed
2023-08-07 15:22:00,794:INFO:               fugue: Not installed
2023-08-07 15:22:00,794:INFO:           streamlit: Not installed
2023-08-07 15:22:00,794:INFO:             prophet: Not installed
2023-08-07 15:22:00,794:INFO:None
2023-08-07 15:22:00,794:INFO:Set up data.
2023-08-07 15:22:00,801:INFO:Set up train/test split.
2023-08-07 15:22:00,805:INFO:Set up index.
2023-08-07 15:22:00,805:INFO:Set up folding strategy.
2023-08-07 15:22:00,806:INFO:Assigning column types.
2023-08-07 15:22:00,811:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-07 15:22:00,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-07 15:22:00,866:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:22:00,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:00,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:00,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-07 15:22:00,958:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:22:00,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:00,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:00,998:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-07 15:22:01,054:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:22:01,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,145:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-07 15:22:01,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,186:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-07 15:22:01,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,373:INFO:Preparing preprocessing pipeline...
2023-08-07 15:22:01,374:INFO:Set up simple imputation.
2023-08-07 15:22:01,377:INFO:Set up encoding of ordinal features.
2023-08-07 15:22:01,380:INFO:Set up encoding of categorical features.
2023-08-07 15:22:01,453:INFO:Finished creating preprocessing pipeline.
2023-08-07 15:22:01,503:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lucazav\AppData\Local\Temp\5\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('c...
                                                                        {'col': 'Sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-07 15:22:01,503:INFO:Creating final display dataframe.
2023-08-07 15:22:01,727:INFO:Setup _display_container:                     Description             Value
0                    Session id              5614
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (844, 8)
4        Transformed data shape         (844, 10)
5   Transformed train set shape         (590, 10)
6    Transformed test set shape         (254, 10)
7              Ordinal features                 2
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              4fab
2023-08-07 15:22:01,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-07 15:22:01,911:INFO:setup() successfully completed in 1.37s...............
2023-08-07 15:22:03,010:INFO:Initializing compare_models()
2023-08-07 15:22:03,011:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-07 15:22:03,011:INFO:Checking exceptions
2023-08-07 15:22:03,015:INFO:Preparing display monitor
2023-08-07 15:22:03,045:INFO:Initializing Logistic Regression
2023-08-07 15:22:03,046:INFO:Total runtime is 1.663366953531901e-05 minutes
2023-08-07 15:22:03,050:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:03,051:INFO:Initializing create_model()
2023-08-07 15:22:03,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:03,051:INFO:Checking exceptions
2023-08-07 15:22:03,051:INFO:Importing libraries
2023-08-07 15:22:03,051:INFO:Copying training dataset
2023-08-07 15:22:03,055:INFO:Defining folds
2023-08-07 15:22:03,056:INFO:Declaring metric variables
2023-08-07 15:22:03,060:INFO:Importing untrained model
2023-08-07 15:22:03,065:INFO:Logistic Regression Imported successfully
2023-08-07 15:22:03,072:INFO:Starting cross validation
2023-08-07 15:22:03,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:05,709:INFO:Calculating mean and std
2023-08-07 15:22:05,712:INFO:Creating metrics dataframe
2023-08-07 15:22:06,152:INFO:Uploading results into container
2023-08-07 15:22:06,153:INFO:Uploading model into container now
2023-08-07 15:22:06,154:INFO:_master_model_container: 1
2023-08-07 15:22:06,154:INFO:_display_container: 2
2023-08-07 15:22:06,155:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5614, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-07 15:22:06,155:INFO:create_model() successfully completed......................................
2023-08-07 15:22:06,326:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:06,326:INFO:Creating metrics dataframe
2023-08-07 15:22:06,338:INFO:Initializing K Neighbors Classifier
2023-08-07 15:22:06,338:INFO:Total runtime is 0.054875838756561275 minutes
2023-08-07 15:22:06,343:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:06,343:INFO:Initializing create_model()
2023-08-07 15:22:06,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:06,344:INFO:Checking exceptions
2023-08-07 15:22:06,344:INFO:Importing libraries
2023-08-07 15:22:06,344:INFO:Copying training dataset
2023-08-07 15:22:06,349:INFO:Defining folds
2023-08-07 15:22:06,349:INFO:Declaring metric variables
2023-08-07 15:22:06,355:INFO:Importing untrained model
2023-08-07 15:22:06,360:INFO:K Neighbors Classifier Imported successfully
2023-08-07 15:22:06,369:INFO:Starting cross validation
2023-08-07 15:22:06,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:09,010:INFO:Calculating mean and std
2023-08-07 15:22:09,012:INFO:Creating metrics dataframe
2023-08-07 15:22:09,442:INFO:Uploading results into container
2023-08-07 15:22:09,443:INFO:Uploading model into container now
2023-08-07 15:22:09,444:INFO:_master_model_container: 2
2023-08-07 15:22:09,447:INFO:_display_container: 2
2023-08-07 15:22:09,448:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-07 15:22:09,448:INFO:create_model() successfully completed......................................
2023-08-07 15:22:09,617:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:09,617:INFO:Creating metrics dataframe
2023-08-07 15:22:09,631:INFO:Initializing Naive Bayes
2023-08-07 15:22:09,631:INFO:Total runtime is 0.10975971619288126 minutes
2023-08-07 15:22:09,635:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:09,636:INFO:Initializing create_model()
2023-08-07 15:22:09,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:09,636:INFO:Checking exceptions
2023-08-07 15:22:09,637:INFO:Importing libraries
2023-08-07 15:22:09,637:INFO:Copying training dataset
2023-08-07 15:22:09,641:INFO:Defining folds
2023-08-07 15:22:09,641:INFO:Declaring metric variables
2023-08-07 15:22:09,646:INFO:Importing untrained model
2023-08-07 15:22:09,649:INFO:Naive Bayes Imported successfully
2023-08-07 15:22:09,657:INFO:Starting cross validation
2023-08-07 15:22:09,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:12,190:INFO:Calculating mean and std
2023-08-07 15:22:12,192:INFO:Creating metrics dataframe
2023-08-07 15:22:12,622:INFO:Uploading results into container
2023-08-07 15:22:12,624:INFO:Uploading model into container now
2023-08-07 15:22:12,625:INFO:_master_model_container: 3
2023-08-07 15:22:12,625:INFO:_display_container: 2
2023-08-07 15:22:12,625:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-07 15:22:12,625:INFO:create_model() successfully completed......................................
2023-08-07 15:22:12,792:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:12,792:INFO:Creating metrics dataframe
2023-08-07 15:22:12,805:INFO:Initializing Decision Tree Classifier
2023-08-07 15:22:12,805:INFO:Total runtime is 0.16265226205190023 minutes
2023-08-07 15:22:12,811:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:12,811:INFO:Initializing create_model()
2023-08-07 15:22:12,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:12,812:INFO:Checking exceptions
2023-08-07 15:22:12,812:INFO:Importing libraries
2023-08-07 15:22:12,812:INFO:Copying training dataset
2023-08-07 15:22:12,814:INFO:Defining folds
2023-08-07 15:22:12,814:INFO:Declaring metric variables
2023-08-07 15:22:12,822:INFO:Importing untrained model
2023-08-07 15:22:12,826:INFO:Decision Tree Classifier Imported successfully
2023-08-07 15:22:12,834:INFO:Starting cross validation
2023-08-07 15:22:12,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:15,363:INFO:Calculating mean and std
2023-08-07 15:22:15,364:INFO:Creating metrics dataframe
2023-08-07 15:22:15,799:INFO:Uploading results into container
2023-08-07 15:22:15,801:INFO:Uploading model into container now
2023-08-07 15:22:15,801:INFO:_master_model_container: 4
2023-08-07 15:22:15,802:INFO:_display_container: 2
2023-08-07 15:22:15,802:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5614, splitter='best')
2023-08-07 15:22:15,803:INFO:create_model() successfully completed......................................
2023-08-07 15:22:15,971:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:15,971:INFO:Creating metrics dataframe
2023-08-07 15:22:15,984:INFO:Initializing SVM - Linear Kernel
2023-08-07 15:22:15,985:INFO:Total runtime is 0.21565274794896444 minutes
2023-08-07 15:22:15,989:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:15,989:INFO:Initializing create_model()
2023-08-07 15:22:15,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:15,989:INFO:Checking exceptions
2023-08-07 15:22:15,989:INFO:Importing libraries
2023-08-07 15:22:15,990:INFO:Copying training dataset
2023-08-07 15:22:15,994:INFO:Defining folds
2023-08-07 15:22:15,995:INFO:Declaring metric variables
2023-08-07 15:22:15,999:INFO:Importing untrained model
2023-08-07 15:22:16,003:INFO:SVM - Linear Kernel Imported successfully
2023-08-07 15:22:16,010:INFO:Starting cross validation
2023-08-07 15:22:16,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:16,184:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:22:16,188:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:22:16,193:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:22:16,197:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:16,200:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:22:16,207:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:22:16,208:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:22:16,260:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:22:16,294:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:22:16,682:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:22:16,738:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-07 15:22:18,507:INFO:Calculating mean and std
2023-08-07 15:22:18,509:INFO:Creating metrics dataframe
2023-08-07 15:22:18,947:INFO:Uploading results into container
2023-08-07 15:22:18,948:INFO:Uploading model into container now
2023-08-07 15:22:18,949:INFO:_master_model_container: 5
2023-08-07 15:22:18,949:INFO:_display_container: 2
2023-08-07 15:22:18,950:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5614, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-07 15:22:18,950:INFO:create_model() successfully completed......................................
2023-08-07 15:22:19,121:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:19,122:INFO:Creating metrics dataframe
2023-08-07 15:22:19,134:INFO:Initializing Ridge Classifier
2023-08-07 15:22:19,139:INFO:Total runtime is 0.2682284196217855 minutes
2023-08-07 15:22:19,144:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:19,144:INFO:Initializing create_model()
2023-08-07 15:22:19,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:19,144:INFO:Checking exceptions
2023-08-07 15:22:19,145:INFO:Importing libraries
2023-08-07 15:22:19,145:INFO:Copying training dataset
2023-08-07 15:22:19,149:INFO:Defining folds
2023-08-07 15:22:19,150:INFO:Declaring metric variables
2023-08-07 15:22:19,155:INFO:Importing untrained model
2023-08-07 15:22:19,160:INFO:Ridge Classifier Imported successfully
2023-08-07 15:22:19,167:INFO:Starting cross validation
2023-08-07 15:22:19,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:19,336:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:22:19,342:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:22:19,349:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:22:19,356:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:22:19,360:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:22:19,402:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:22:19,428:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:22:19,468:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:22:19,850:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:22:19,873:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-07 15:22:21,661:INFO:Calculating mean and std
2023-08-07 15:22:21,663:INFO:Creating metrics dataframe
2023-08-07 15:22:22,096:INFO:Uploading results into container
2023-08-07 15:22:22,098:INFO:Uploading model into container now
2023-08-07 15:22:22,098:INFO:_master_model_container: 6
2023-08-07 15:22:22,098:INFO:_display_container: 2
2023-08-07 15:22:22,099:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5614, solver='auto',
                tol=0.0001)
2023-08-07 15:22:22,099:INFO:create_model() successfully completed......................................
2023-08-07 15:22:22,267:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:22,267:INFO:Creating metrics dataframe
2023-08-07 15:22:22,281:INFO:Initializing Random Forest Classifier
2023-08-07 15:22:22,281:INFO:Total runtime is 0.32059545914332077 minutes
2023-08-07 15:22:22,285:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:22,286:INFO:Initializing create_model()
2023-08-07 15:22:22,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:22,286:INFO:Checking exceptions
2023-08-07 15:22:22,286:INFO:Importing libraries
2023-08-07 15:22:22,286:INFO:Copying training dataset
2023-08-07 15:22:22,291:INFO:Defining folds
2023-08-07 15:22:22,291:INFO:Declaring metric variables
2023-08-07 15:22:22,295:INFO:Importing untrained model
2023-08-07 15:22:22,300:INFO:Random Forest Classifier Imported successfully
2023-08-07 15:22:22,308:INFO:Starting cross validation
2023-08-07 15:22:22,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:25,504:INFO:Calculating mean and std
2023-08-07 15:22:25,506:INFO:Creating metrics dataframe
2023-08-07 15:22:25,947:INFO:Uploading results into container
2023-08-07 15:22:25,948:INFO:Uploading model into container now
2023-08-07 15:22:25,949:INFO:_master_model_container: 7
2023-08-07 15:22:25,949:INFO:_display_container: 2
2023-08-07 15:22:25,950:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5614, verbose=0, warm_start=False)
2023-08-07 15:22:25,950:INFO:create_model() successfully completed......................................
2023-08-07 15:22:26,120:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:26,120:INFO:Creating metrics dataframe
2023-08-07 15:22:26,136:INFO:Initializing Quadratic Discriminant Analysis
2023-08-07 15:22:26,136:INFO:Total runtime is 0.3848459323247274 minutes
2023-08-07 15:22:26,141:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:26,141:INFO:Initializing create_model()
2023-08-07 15:22:26,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:26,141:INFO:Checking exceptions
2023-08-07 15:22:26,142:INFO:Importing libraries
2023-08-07 15:22:26,142:INFO:Copying training dataset
2023-08-07 15:22:26,147:INFO:Defining folds
2023-08-07 15:22:26,147:INFO:Declaring metric variables
2023-08-07 15:22:26,152:INFO:Importing untrained model
2023-08-07 15:22:26,157:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-07 15:22:26,166:INFO:Starting cross validation
2023-08-07 15:22:26,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:26,288:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:22:26,288:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:22:26,299:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:22:26,299:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:22:26,302:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:22:26,328:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:22:26,332:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:22:26,395:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:22:26,800:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:22:26,902:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-07 15:22:28,672:INFO:Calculating mean and std
2023-08-07 15:22:28,674:INFO:Creating metrics dataframe
2023-08-07 15:22:29,106:INFO:Uploading results into container
2023-08-07 15:22:29,108:INFO:Uploading model into container now
2023-08-07 15:22:29,108:INFO:_master_model_container: 8
2023-08-07 15:22:29,109:INFO:_display_container: 2
2023-08-07 15:22:29,109:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-07 15:22:29,109:INFO:create_model() successfully completed......................................
2023-08-07 15:22:29,276:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:29,276:INFO:Creating metrics dataframe
2023-08-07 15:22:29,291:INFO:Initializing Ada Boost Classifier
2023-08-07 15:22:29,291:INFO:Total runtime is 0.4374296387036642 minutes
2023-08-07 15:22:29,295:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:29,295:INFO:Initializing create_model()
2023-08-07 15:22:29,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:29,296:INFO:Checking exceptions
2023-08-07 15:22:29,296:INFO:Importing libraries
2023-08-07 15:22:29,296:INFO:Copying training dataset
2023-08-07 15:22:29,300:INFO:Defining folds
2023-08-07 15:22:29,301:INFO:Declaring metric variables
2023-08-07 15:22:29,305:INFO:Importing untrained model
2023-08-07 15:22:29,310:INFO:Ada Boost Classifier Imported successfully
2023-08-07 15:22:29,318:INFO:Starting cross validation
2023-08-07 15:22:29,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:32,003:INFO:Calculating mean and std
2023-08-07 15:22:32,005:INFO:Creating metrics dataframe
2023-08-07 15:22:32,446:INFO:Uploading results into container
2023-08-07 15:22:32,447:INFO:Uploading model into container now
2023-08-07 15:22:32,448:INFO:_master_model_container: 9
2023-08-07 15:22:32,448:INFO:_display_container: 2
2023-08-07 15:22:32,449:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5614)
2023-08-07 15:22:32,449:INFO:create_model() successfully completed......................................
2023-08-07 15:22:32,615:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:32,616:INFO:Creating metrics dataframe
2023-08-07 15:22:32,631:INFO:Initializing Gradient Boosting Classifier
2023-08-07 15:22:32,631:INFO:Total runtime is 0.49309674898783373 minutes
2023-08-07 15:22:32,635:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:32,636:INFO:Initializing create_model()
2023-08-07 15:22:32,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:32,636:INFO:Checking exceptions
2023-08-07 15:22:32,636:INFO:Importing libraries
2023-08-07 15:22:32,636:INFO:Copying training dataset
2023-08-07 15:22:32,641:INFO:Defining folds
2023-08-07 15:22:32,642:INFO:Declaring metric variables
2023-08-07 15:22:32,646:INFO:Importing untrained model
2023-08-07 15:22:32,651:INFO:Gradient Boosting Classifier Imported successfully
2023-08-07 15:22:32,660:INFO:Starting cross validation
2023-08-07 15:22:32,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:35,336:INFO:Calculating mean and std
2023-08-07 15:22:35,338:INFO:Creating metrics dataframe
2023-08-07 15:22:35,783:INFO:Uploading results into container
2023-08-07 15:22:35,784:INFO:Uploading model into container now
2023-08-07 15:22:35,785:INFO:_master_model_container: 10
2023-08-07 15:22:35,785:INFO:_display_container: 2
2023-08-07 15:22:35,786:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 15:22:35,786:INFO:create_model() successfully completed......................................
2023-08-07 15:22:35,965:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:35,965:INFO:Creating metrics dataframe
2023-08-07 15:22:35,980:INFO:Initializing Linear Discriminant Analysis
2023-08-07 15:22:35,980:INFO:Total runtime is 0.5489140232404074 minutes
2023-08-07 15:22:35,985:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:35,985:INFO:Initializing create_model()
2023-08-07 15:22:35,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:35,985:INFO:Checking exceptions
2023-08-07 15:22:35,985:INFO:Importing libraries
2023-08-07 15:22:35,986:INFO:Copying training dataset
2023-08-07 15:22:35,990:INFO:Defining folds
2023-08-07 15:22:35,990:INFO:Declaring metric variables
2023-08-07 15:22:35,995:INFO:Importing untrained model
2023-08-07 15:22:36,000:INFO:Linear Discriminant Analysis Imported successfully
2023-08-07 15:22:36,008:INFO:Starting cross validation
2023-08-07 15:22:36,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:38,600:INFO:Calculating mean and std
2023-08-07 15:22:38,602:INFO:Creating metrics dataframe
2023-08-07 15:22:39,046:INFO:Uploading results into container
2023-08-07 15:22:39,047:INFO:Uploading model into container now
2023-08-07 15:22:39,048:INFO:_master_model_container: 11
2023-08-07 15:22:39,048:INFO:_display_container: 2
2023-08-07 15:22:39,048:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-07 15:22:39,049:INFO:create_model() successfully completed......................................
2023-08-07 15:22:39,219:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:39,219:INFO:Creating metrics dataframe
2023-08-07 15:22:39,234:INFO:Initializing Extra Trees Classifier
2023-08-07 15:22:39,234:INFO:Total runtime is 0.6031478683153789 minutes
2023-08-07 15:22:39,243:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:39,244:INFO:Initializing create_model()
2023-08-07 15:22:39,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:39,244:INFO:Checking exceptions
2023-08-07 15:22:39,244:INFO:Importing libraries
2023-08-07 15:22:39,245:INFO:Copying training dataset
2023-08-07 15:22:39,250:INFO:Defining folds
2023-08-07 15:22:39,251:INFO:Declaring metric variables
2023-08-07 15:22:39,255:INFO:Importing untrained model
2023-08-07 15:22:39,260:INFO:Extra Trees Classifier Imported successfully
2023-08-07 15:22:39,267:INFO:Starting cross validation
2023-08-07 15:22:39,269:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:42,432:INFO:Calculating mean and std
2023-08-07 15:22:42,435:INFO:Creating metrics dataframe
2023-08-07 15:22:42,891:INFO:Uploading results into container
2023-08-07 15:22:42,893:INFO:Uploading model into container now
2023-08-07 15:22:42,893:INFO:_master_model_container: 12
2023-08-07 15:22:42,893:INFO:_display_container: 2
2023-08-07 15:22:42,894:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5614, verbose=0, warm_start=False)
2023-08-07 15:22:42,894:INFO:create_model() successfully completed......................................
2023-08-07 15:22:43,070:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:43,071:INFO:Creating metrics dataframe
2023-08-07 15:22:43,086:INFO:Initializing Light Gradient Boosting Machine
2023-08-07 15:22:43,087:INFO:Total runtime is 0.6673652251561484 minutes
2023-08-07 15:22:43,091:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:43,092:INFO:Initializing create_model()
2023-08-07 15:22:43,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:43,092:INFO:Checking exceptions
2023-08-07 15:22:43,092:INFO:Importing libraries
2023-08-07 15:22:43,092:INFO:Copying training dataset
2023-08-07 15:22:43,098:INFO:Defining folds
2023-08-07 15:22:43,098:INFO:Declaring metric variables
2023-08-07 15:22:43,102:INFO:Importing untrained model
2023-08-07 15:22:43,107:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-07 15:22:43,115:INFO:Starting cross validation
2023-08-07 15:22:43,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:46,535:INFO:Calculating mean and std
2023-08-07 15:22:46,537:INFO:Creating metrics dataframe
2023-08-07 15:22:47,004:INFO:Uploading results into container
2023-08-07 15:22:47,005:INFO:Uploading model into container now
2023-08-07 15:22:47,006:INFO:_master_model_container: 13
2023-08-07 15:22:47,006:INFO:_display_container: 2
2023-08-07 15:22:47,007:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5614, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-07 15:22:47,007:INFO:create_model() successfully completed......................................
2023-08-07 15:22:47,183:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:47,184:INFO:Creating metrics dataframe
2023-08-07 15:22:47,200:INFO:Initializing Dummy Classifier
2023-08-07 15:22:47,201:INFO:Total runtime is 0.7359325170516968 minutes
2023-08-07 15:22:47,205:INFO:SubProcess create_model() called ==================================
2023-08-07 15:22:47,205:INFO:Initializing create_model()
2023-08-07 15:22:47,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230C52DA610>, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:47,206:INFO:Checking exceptions
2023-08-07 15:22:47,206:INFO:Importing libraries
2023-08-07 15:22:47,206:INFO:Copying training dataset
2023-08-07 15:22:47,210:INFO:Defining folds
2023-08-07 15:22:47,211:INFO:Declaring metric variables
2023-08-07 15:22:47,215:INFO:Importing untrained model
2023-08-07 15:22:47,219:INFO:Dummy Classifier Imported successfully
2023-08-07 15:22:47,227:INFO:Starting cross validation
2023-08-07 15:22:47,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-07 15:22:47,447:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:47,451:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:47,463:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:47,465:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:47,495:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:47,521:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:47,541:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:47,567:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:47,996:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:48,033:WARNING:c:\ProgramData\Miniconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-07 15:22:49,880:INFO:Calculating mean and std
2023-08-07 15:22:49,882:INFO:Creating metrics dataframe
2023-08-07 15:22:50,334:INFO:Uploading results into container
2023-08-07 15:22:50,335:INFO:Uploading model into container now
2023-08-07 15:22:50,336:INFO:_master_model_container: 14
2023-08-07 15:22:50,336:INFO:_display_container: 2
2023-08-07 15:22:50,336:INFO:DummyClassifier(constant=None, random_state=5614, strategy='prior')
2023-08-07 15:22:50,336:INFO:create_model() successfully completed......................................
2023-08-07 15:22:50,505:INFO:SubProcess create_model() end ==================================
2023-08-07 15:22:50,506:INFO:Creating metrics dataframe
2023-08-07 15:22:50,534:INFO:Initializing create_model()
2023-08-07 15:22:50,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230CB484E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-07 15:22:50,535:INFO:Checking exceptions
2023-08-07 15:22:50,537:INFO:Importing libraries
2023-08-07 15:22:50,537:INFO:Copying training dataset
2023-08-07 15:22:50,542:INFO:Defining folds
2023-08-07 15:22:50,542:INFO:Declaring metric variables
2023-08-07 15:22:50,542:INFO:Importing untrained model
2023-08-07 15:22:50,543:INFO:Declaring custom model
2023-08-07 15:22:50,543:INFO:Gradient Boosting Classifier Imported successfully
2023-08-07 15:22:50,545:INFO:Cross validation set to False
2023-08-07 15:22:50,545:INFO:Fitting Model
2023-08-07 15:22:50,883:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 15:22:50,883:INFO:create_model() successfully completed......................................
2023-08-07 15:22:51,091:INFO:_master_model_container: 14
2023-08-07 15:22:51,091:INFO:_display_container: 2
2023-08-07 15:22:51,092:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5614, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-07 15:22:51,092:INFO:compare_models() successfully completed......................................
2023-08-09 11:19:28,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:19:28,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:19:28,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:19:28,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:26:12,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:26:12,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:26:12,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:26:12,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:26:42,159:INFO:PyCaret ClassificationExperiment
2023-08-09 11:26:42,161:INFO:Logging name: clf-default-name
2023-08-09 11:26:42,161:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 11:26:42,161:INFO:version 3.0.4
2023-08-09 11:26:42,162:INFO:Initializing setup()
2023-08-09 11:26:42,162:INFO:self.USI: 41f1
2023-08-09 11:26:42,162:INFO:self._variable_keys: {'idx', 'memory', 'fold_groups_param', 'X_test', 'fix_imbalance', 'data', 'logging_param', 'log_plots_param', 'y', 'fold_generator', 'X_train', '_available_plots', 'target_param', 'n_jobs_param', 'exp_id', 'pipeline', 'X', 'seed', 'exp_name_log', 'html_param', 'fold_shuffle_param', '_ml_usecase', 'is_multiclass', 'gpu_n_jobs_param', 'USI', 'y_train', 'y_test', 'gpu_param'}
2023-08-09 11:26:42,163:INFO:Checking environment
2023-08-09 11:26:42,163:INFO:python_version: 3.9.17
2023-08-09 11:26:42,164:INFO:python_build: ('main', 'Jul  5 2023 20:47:11')
2023-08-09 11:26:42,164:INFO:machine: AMD64
2023-08-09 11:26:42,164:INFO:platform: Windows-10-10.0.20348-SP0
2023-08-09 11:26:42,165:INFO:Memory: svmem(total=34358562816, available=26342166528, percent=23.3, used=8016396288, free=26342166528)
2023-08-09 11:26:42,165:INFO:Physical Core: 8
2023-08-09 11:26:42,165:INFO:Logical Core: 8
2023-08-09 11:26:42,166:INFO:Checking libraries
2023-08-09 11:26:42,166:INFO:System:
2023-08-09 11:26:42,167:INFO:    python: 3.9.17 (main, Jul  5 2023, 20:47:11) [MSC v.1916 64 bit (AMD64)]
2023-08-09 11:26:42,167:INFO:executable: c:\ProgramData\Miniconda3\envs\pycaret_env\python.exe
2023-08-09 11:26:42,167:INFO:   machine: Windows-10-10.0.20348-SP0
2023-08-09 11:26:42,168:INFO:PyCaret required dependencies:
2023-08-09 11:26:42,312:INFO:                 pip: 23.2.1
2023-08-09 11:26:42,313:INFO:          setuptools: 68.0.0
2023-08-09 11:26:42,313:INFO:             pycaret: 3.0.4
2023-08-09 11:26:42,314:INFO:             IPython: 8.12.0
2023-08-09 11:26:42,314:INFO:          ipywidgets: 8.1.0
2023-08-09 11:26:42,314:INFO:                tqdm: 4.65.0
2023-08-09 11:26:42,314:INFO:               numpy: 1.23.5
2023-08-09 11:26:42,314:INFO:              pandas: 1.5.3
2023-08-09 11:26:42,314:INFO:              jinja2: 3.1.2
2023-08-09 11:26:42,314:INFO:               scipy: 1.11.1
2023-08-09 11:26:42,314:INFO:              joblib: 1.3.1
2023-08-09 11:26:42,314:INFO:             sklearn: 1.2.2
2023-08-09 11:26:42,314:INFO:                pyod: 1.1.0
2023-08-09 11:26:42,314:INFO:            imblearn: 0.11.0
2023-08-09 11:26:42,314:INFO:   category_encoders: 2.6.1
2023-08-09 11:26:42,315:INFO:            lightgbm: 4.0.0
2023-08-09 11:26:42,315:INFO:               numba: 0.57.1
2023-08-09 11:26:42,315:INFO:            requests: 2.31.0
2023-08-09 11:26:42,315:INFO:          matplotlib: 3.7.2
2023-08-09 11:26:42,315:INFO:          scikitplot: 0.3.7
2023-08-09 11:26:42,315:INFO:         yellowbrick: 1.5
2023-08-09 11:26:42,315:INFO:              plotly: 5.15.0
2023-08-09 11:26:42,315:INFO:    plotly-resampler: Not installed
2023-08-09 11:26:42,315:INFO:             kaleido: 0.2.1
2023-08-09 11:26:42,315:INFO:           schemdraw: 0.15
2023-08-09 11:26:42,315:INFO:         statsmodels: 0.14.0
2023-08-09 11:26:42,315:INFO:              sktime: 0.21.0
2023-08-09 11:26:42,315:INFO:               tbats: 1.1.3
2023-08-09 11:26:42,315:INFO:            pmdarima: 2.0.3
2023-08-09 11:26:42,316:INFO:              psutil: 5.9.0
2023-08-09 11:26:42,316:INFO:          markupsafe: 2.1.3
2023-08-09 11:26:42,316:INFO:             pickle5: Not installed
2023-08-09 11:26:42,316:INFO:         cloudpickle: 2.2.1
2023-08-09 11:26:42,316:INFO:         deprecation: 2.1.0
2023-08-09 11:26:42,316:INFO:              xxhash: 3.3.0
2023-08-09 11:26:42,316:INFO:           wurlitzer: Not installed
2023-08-09 11:26:42,316:INFO:PyCaret optional dependencies:
2023-08-09 11:26:42,340:INFO:                shap: Not installed
2023-08-09 11:26:42,340:INFO:           interpret: Not installed
2023-08-09 11:26:42,340:INFO:                umap: Not installed
2023-08-09 11:26:42,340:INFO:    pandas_profiling: Not installed
2023-08-09 11:26:42,340:INFO:  explainerdashboard: Not installed
2023-08-09 11:26:42,340:INFO:             autoviz: Not installed
2023-08-09 11:26:42,340:INFO:           fairlearn: Not installed
2023-08-09 11:26:42,340:INFO:          deepchecks: Not installed
2023-08-09 11:26:42,340:INFO:             xgboost: Not installed
2023-08-09 11:26:42,341:INFO:            catboost: Not installed
2023-08-09 11:26:42,341:INFO:              kmodes: Not installed
2023-08-09 11:26:42,341:INFO:             mlxtend: Not installed
2023-08-09 11:26:42,341:INFO:       statsforecast: Not installed
2023-08-09 11:26:42,341:INFO:        tune_sklearn: Not installed
2023-08-09 11:26:42,341:INFO:                 ray: Not installed
2023-08-09 11:26:42,341:INFO:            hyperopt: Not installed
2023-08-09 11:26:42,341:INFO:              optuna: Not installed
2023-08-09 11:26:42,342:INFO:               skopt: Not installed
2023-08-09 11:26:42,342:INFO:              mlflow: Not installed
2023-08-09 11:26:42,342:INFO:              gradio: Not installed
2023-08-09 11:26:42,342:INFO:             fastapi: Not installed
2023-08-09 11:26:42,342:INFO:             uvicorn: Not installed
2023-08-09 11:26:42,342:INFO:              m2cgen: Not installed
2023-08-09 11:26:42,342:INFO:           evidently: Not installed
2023-08-09 11:26:42,342:INFO:               fugue: Not installed
2023-08-09 11:26:42,342:INFO:           streamlit: Not installed
2023-08-09 11:26:42,342:INFO:             prophet: Not installed
2023-08-09 11:26:42,342:INFO:None
2023-08-09 11:26:42,343:INFO:Set up data.
2023-08-09 11:26:42,356:INFO:Set up train/test split.
2023-08-09 11:26:42,370:INFO:Set up index.
2023-08-09 11:26:42,381:INFO:Set up folding strategy.
2023-08-09 11:26:42,381:INFO:Assigning column types.
2023-08-09 11:26:42,388:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 11:26:42,453:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 11:26:42,457:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 11:26:42,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:42,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:42,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 11:26:42,592:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 11:26:42,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:42,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:42,637:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 11:26:42,707:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 11:26:42,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:42,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:42,827:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 11:26:42,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:42,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:42,875:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 11:26:42,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:42,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:43,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:43,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:43,105:INFO:Preparing preprocessing pipeline...
2023-08-09 11:26:43,115:INFO:Set up simple imputation.
2023-08-09 11:26:43,123:INFO:Set up encoding of ordinal features.
2023-08-09 11:26:43,127:INFO:Set up encoding of categorical features.
2023-08-09 11:26:43,245:INFO:Finished creating preprocessing pipeline.
2023-08-09 11:26:43,318:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lucazav\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('c...
                                                                        {'col': 'Sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-09 11:26:43,318:INFO:Creating final display dataframe.
2023-08-09 11:26:43,620:INFO:Setup _display_container:                     Description             Value
0                    Session id              5614
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (844, 8)
4        Transformed data shape         (844, 10)
5   Transformed train set shape         (590, 10)
6    Transformed test set shape         (254, 10)
7              Ordinal features                 2
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              41f1
2023-08-09 11:26:43,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:43,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:43,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:43,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-09 11:26:43,859:INFO:setup() successfully completed in 1.7s...............
2023-08-09 11:27:27,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:27:27,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:27:27,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 11:27:27,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 13:32:45,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 13:32:45,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 13:32:45,883:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 13:32:45,883:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
